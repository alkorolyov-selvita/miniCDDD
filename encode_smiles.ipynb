{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:55:52.322320Z",
     "start_time": "2025-03-19T04:55:50.936765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import load_cddd_encoder\n",
    "\n",
    "import torch\n",
    "import _codecs\n",
    "import numpy as np\n",
    "\n",
    "# torch.serialization.add_safe_globals([np.dtypes.Int64DType, _codecs.encode, np.core.multiarray.scalar])\n",
    "\n",
    "\n",
    "# cddd_enc = load_cddd_encoder('1k_test/models/cddd_encoder.pt')\n",
    "cddd_enc = load_cddd_encoder('600k_chembl_float16/models/cddd_encoder.pt', weights_only=False)\n",
    "cddd_enc"
   ],
   "id": "cea57687b696767a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDDDEncoder(\n",
       "  (encoder): Encoder(\n",
       "    (gru1): GRU(56, 512, batch_first=True)\n",
       "    (gru2): GRU(512, 1024, batch_first=True)\n",
       "    (gru3): GRU(1024, 2048, batch_first=True)\n",
       "    (dropout): Dropout(p=0.15, inplace=False)\n",
       "    (latent_projection): Linear(in_features=3584, out_features=512, bias=True)\n",
       "    (gaussian_noise): GaussianNoise()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:55:53.706906Z",
     "start_time": "2025-03-19T04:55:53.703252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k,v in cddd_enc.encoder.state_dict().items():\n",
    "    print(k, v.dtype)\n",
    "# cddd_enc.encoder.to(torch.bfloat16)"
   ],
   "id": "7018e1a336049ff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru1.weight_ih_l0 torch.bfloat16\n",
      "gru1.weight_hh_l0 torch.bfloat16\n",
      "gru1.bias_ih_l0 torch.bfloat16\n",
      "gru1.bias_hh_l0 torch.bfloat16\n",
      "gru2.weight_ih_l0 torch.bfloat16\n",
      "gru2.weight_hh_l0 torch.bfloat16\n",
      "gru2.bias_ih_l0 torch.bfloat16\n",
      "gru2.bias_hh_l0 torch.bfloat16\n",
      "gru3.weight_ih_l0 torch.bfloat16\n",
      "gru3.weight_hh_l0 torch.bfloat16\n",
      "gru3.bias_ih_l0 torch.bfloat16\n",
      "gru3.bias_hh_l0 torch.bfloat16\n",
      "latent_projection.weight torch.bfloat16\n",
      "latent_projection.bias torch.bfloat16\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:56:07.257942Z",
     "start_time": "2025-03-19T04:56:07.248409Z"
    }
   },
   "cell_type": "code",
   "source": "cddd_enc(['CO', 'CN'])",
   "id": "b2bc28a0818e55c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:18:48.070753Z",
     "start_time": "2025-03-19T04:18:48.007625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load(\"600k_chembl_float16/checkpoints/last.ckpt\", map_location=\"cpu\", weights_only=True)\n",
    "for key, val in checkpoint.items():\n",
    "    print(key, val.dtype if hasattr(val, 'dtype') else type(val))\n",
    "    # checkpoint[key] = checkpoint[key].to(torch.bfloat16)\n",
    "# model.load_state_dict(checkpoint)"
   ],
   "id": "dab8546308027acf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch <class 'int'>\n",
      "global_step <class 'int'>\n",
      "pytorch-lightning_version <class 'str'>\n",
      "state_dict <class 'collections.OrderedDict'>\n",
      "loops <class 'dict'>\n",
      "callbacks <class 'dict'>\n",
      "optimizer_states <class 'list'>\n",
      "lr_schedulers <class 'list'>\n",
      "hparams_name <class 'str'>\n",
      "hyper_parameters <class 'dict'>\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:19:55.680486Z",
     "start_time": "2025-03-19T04:19:55.675751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k, v in checkpoint['state_dict'].items():\n",
    "    print(k, v.dtype if hasattr(v, 'dtype') else type(v))"
   ],
   "id": "9cbbd27002c44dc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.gru1.weight_ih_l0 torch.bfloat16\n",
      "model.encoder.gru1.weight_hh_l0 torch.bfloat16\n",
      "model.encoder.gru1.bias_ih_l0 torch.bfloat16\n",
      "model.encoder.gru1.bias_hh_l0 torch.bfloat16\n",
      "model.encoder.gru2.weight_ih_l0 torch.bfloat16\n",
      "model.encoder.gru2.weight_hh_l0 torch.bfloat16\n",
      "model.encoder.gru2.bias_ih_l0 torch.bfloat16\n",
      "model.encoder.gru2.bias_hh_l0 torch.bfloat16\n",
      "model.encoder.gru3.weight_ih_l0 torch.bfloat16\n",
      "model.encoder.gru3.weight_hh_l0 torch.bfloat16\n",
      "model.encoder.gru3.bias_ih_l0 torch.bfloat16\n",
      "model.encoder.gru3.bias_hh_l0 torch.bfloat16\n",
      "model.encoder.latent_projection.weight torch.bfloat16\n",
      "model.encoder.latent_projection.bias torch.bfloat16\n",
      "model.decoder.latent_to_states.weight torch.bfloat16\n",
      "model.decoder.latent_to_states.bias torch.bfloat16\n",
      "model.decoder.gru1.weight_ih_l0 torch.bfloat16\n",
      "model.decoder.gru1.weight_hh_l0 torch.bfloat16\n",
      "model.decoder.gru1.bias_ih_l0 torch.bfloat16\n",
      "model.decoder.gru1.bias_hh_l0 torch.bfloat16\n",
      "model.decoder.gru2.weight_ih_l0 torch.bfloat16\n",
      "model.decoder.gru2.weight_hh_l0 torch.bfloat16\n",
      "model.decoder.gru2.bias_ih_l0 torch.bfloat16\n",
      "model.decoder.gru2.bias_hh_l0 torch.bfloat16\n",
      "model.decoder.gru3.weight_ih_l0 torch.bfloat16\n",
      "model.decoder.gru3.weight_hh_l0 torch.bfloat16\n",
      "model.decoder.gru3.bias_ih_l0 torch.bfloat16\n",
      "model.decoder.gru3.bias_hh_l0 torch.bfloat16\n",
      "model.decoder.output.weight torch.bfloat16\n",
      "model.decoder.output.bias torch.bfloat16\n",
      "model.classifier.mlp.0.weight torch.bfloat16\n",
      "model.classifier.mlp.0.bias torch.bfloat16\n",
      "model.classifier.mlp.2.weight torch.bfloat16\n",
      "model.classifier.mlp.2.bias torch.bfloat16\n",
      "model.classifier.mlp.4.weight torch.bfloat16\n",
      "model.classifier.mlp.4.bias torch.bfloat16\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:17:54.748393Z",
     "start_time": "2025-03-19T04:17:54.610356Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa81d28ec7dbde81",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 27,\n",
       " 'global_step': 110012,\n",
       " 'pytorch-lightning_version': '2.5.0.post0',\n",
       " 'state_dict': OrderedDict([('model.encoder.gru1.weight_ih_l0',\n",
       "               tensor([[ 0.1040,  0.0366, -0.0104,  ...,  0.0332,  0.0347, -0.0410],\n",
       "                       [-0.1016, -0.0008,  0.0347,  ...,  0.0302,  0.0664, -0.0635],\n",
       "                       [ 0.0557, -0.0413, -0.0291,  ..., -0.0292,  0.0312,  0.0461],\n",
       "                       ...,\n",
       "                       [ 0.0771, -0.0264,  0.0267,  ..., -0.0302, -0.0618, -0.0330],\n",
       "                       [-0.0625, -0.0143,  0.0204,  ..., -0.0282, -0.0339,  0.0410],\n",
       "                       [ 0.0840, -0.0090,  0.0287,  ...,  0.0260,  0.0530, -0.0654]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru1.weight_hh_l0',\n",
       "               tensor([[ 0.0308, -0.0153,  0.0381,  ...,  0.0203,  0.0173,  0.0300],\n",
       "                       [ 0.0571, -0.0432,  0.0295,  ..., -0.0615, -0.0515,  0.0493],\n",
       "                       [-0.0170, -0.0272, -0.0262,  ..., -0.0300, -0.0240, -0.0176],\n",
       "                       ...,\n",
       "                       [-0.0320,  0.0294,  0.0077,  ...,  0.0349, -0.0295,  0.0330],\n",
       "                       [ 0.0420, -0.0286, -0.0232,  ...,  0.0247,  0.0156,  0.0413],\n",
       "                       [-0.0327, -0.0437, -0.0198,  ...,  0.0432,  0.0309, -0.0452]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru1.bias_ih_l0',\n",
       "               tensor([ 0.0310, -0.0408,  0.0150,  ...,  0.0077, -0.0175,  0.0425],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru1.bias_hh_l0',\n",
       "               tensor([-0.0359,  0.0291,  0.0150,  ...,  0.0099, -0.0151,  0.0325],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru2.weight_ih_l0',\n",
       "               tensor([[ 0.0199, -0.0126, -0.0055,  ...,  0.0275, -0.0063, -0.0143],\n",
       "                       [-0.0293, -0.0133, -0.0131,  ...,  0.0623, -0.0149,  0.0242],\n",
       "                       [-0.0286,  0.0310,  0.0148,  ..., -0.0078,  0.0306, -0.0508],\n",
       "                       ...,\n",
       "                       [ 0.0111, -0.0146,  0.0121,  ...,  0.0312,  0.0105, -0.0094],\n",
       "                       [ 0.0310,  0.0123,  0.0211,  ..., -0.0299, -0.0223,  0.0233],\n",
       "                       [-0.0308, -0.0300, -0.0093,  ...,  0.0254,  0.0153, -0.0077]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru2.weight_hh_l0',\n",
       "               tensor([[ 0.0205, -0.0139,  0.0244,  ..., -0.0093, -0.0103,  0.0017],\n",
       "                       [-0.0117, -0.0107, -0.0080,  ...,  0.0049, -0.0291,  0.0083],\n",
       "                       [ 0.0052,  0.0167,  0.0113,  ..., -0.0035,  0.0142,  0.0166],\n",
       "                       ...,\n",
       "                       [ 0.0071,  0.0172, -0.0120,  ...,  0.0059, -0.0294, -0.0095],\n",
       "                       [ 0.0029, -0.0128, -0.0138,  ...,  0.0155,  0.0006, -0.0043],\n",
       "                       [ 0.0242,  0.0186,  0.0172,  ...,  0.0135, -0.0292, -0.0063]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru2.bias_ih_l0',\n",
       "               tensor([ 0.0058,  0.0312, -0.0305,  ..., -0.0282,  0.0322,  0.0192],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru2.bias_hh_l0',\n",
       "               tensor([-0.0143,  0.0312, -0.0491,  ..., -0.0148, -0.0072,  0.0330],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru3.weight_ih_l0',\n",
       "               tensor([[ 0.0265, -0.0264,  0.0134,  ..., -0.0066,  0.0364, -0.0164],\n",
       "                       [ 0.0089, -0.0342, -0.0304,  ..., -0.0186, -0.0188, -0.0223],\n",
       "                       [ 0.0168, -0.0262, -0.0147,  ..., -0.0008, -0.0159, -0.0203],\n",
       "                       ...,\n",
       "                       [ 0.0221,  0.0369, -0.0027,  ...,  0.0160,  0.0386, -0.0073],\n",
       "                       [-0.0177, -0.0339, -0.0291,  ..., -0.0089, -0.0537, -0.0098],\n",
       "                       [ 0.0258, -0.0474,  0.0028,  ...,  0.0065, -0.0286,  0.0036]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru3.weight_hh_l0',\n",
       "               tensor([[-0.0145, -0.0046,  0.0205,  ..., -0.0086,  0.0026, -0.0045],\n",
       "                       [-0.0075,  0.0209,  0.0153,  ...,  0.0031, -0.0006,  0.0039],\n",
       "                       [-0.0109,  0.0151, -0.0172,  ...,  0.0085,  0.0208,  0.0087],\n",
       "                       ...,\n",
       "                       [ 0.0047, -0.0183,  0.0119,  ...,  0.0123, -0.0078, -0.0193],\n",
       "                       [-0.0176, -0.0116,  0.0217,  ..., -0.0061,  0.0211,  0.0095],\n",
       "                       [-0.0219, -0.0179,  0.0206,  ...,  0.0040, -0.0045, -0.0090]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru3.bias_ih_l0',\n",
       "               tensor([-0.0305, -0.0625, -0.0378,  ..., -0.0110, -0.0060, -0.0073],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.gru3.bias_hh_l0',\n",
       "               tensor([-0.0305, -0.0625, -0.0354,  ..., -0.0233,  0.0015, -0.0104],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.latent_projection.weight',\n",
       "               tensor([[-0.0181,  0.0151, -0.0275,  ...,  0.0320, -0.0228,  0.0134],\n",
       "                       [ 0.0311, -0.0308,  0.0167,  ..., -0.0276,  0.0267,  0.0369],\n",
       "                       [-0.0079,  0.0099, -0.0178,  ..., -0.0408, -0.0280, -0.0325],\n",
       "                       ...,\n",
       "                       [-0.0160,  0.0312, -0.0183,  ..., -0.0271, -0.0250, -0.0175],\n",
       "                       [ 0.0130, -0.0021, -0.0166,  ...,  0.0090, -0.0258,  0.0339],\n",
       "                       [-0.0049, -0.0034,  0.0136,  ...,  0.0295, -0.0625,  0.0311]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.encoder.latent_projection.bias',\n",
       "               tensor([-1.6235e-02,  3.1250e-02, -9.8267e-03,  3.4424e-02, -1.6602e-02,\n",
       "                        4.9744e-03,  3.2471e-02,  5.2185e-03, -2.1851e-02,  9.6436e-03,\n",
       "                       -3.7842e-02,  3.1281e-03, -2.8076e-02,  1.5503e-02,  1.4343e-02,\n",
       "                        2.0508e-02, -3.8574e-02,  3.0518e-03,  3.1494e-02,  3.1494e-02,\n",
       "                        4.1748e-02,  3.1250e-02, -3.1494e-02, -3.1006e-02,  3.1250e-02,\n",
       "                       -3.8086e-02,  3.1494e-02,  1.0376e-02,  1.0986e-03, -3.1738e-02,\n",
       "                       -4.1260e-02, -3.1250e-02, -3.2471e-02, -2.3926e-02,  3.0884e-02,\n",
       "                        2.4780e-02,  3.1128e-02, -2.1729e-02,  3.0518e-02,  2.5146e-02,\n",
       "                        1.8387e-03, -7.7515e-03, -1.6113e-02, -2.5635e-03,  3.1250e-02,\n",
       "                       -4.7363e-02,  1.7456e-02,  3.0029e-02,  2.7588e-02,  3.1250e-02,\n",
       "                       -3.1250e-02,  3.1982e-02, -2.1973e-02,  3.6621e-02, -4.7363e-02,\n",
       "                       -8.3618e-03, -1.0315e-02, -4.5410e-02,  3.1250e-02,  1.4648e-02,\n",
       "                       -1.7212e-02,  2.6894e-04, -5.2490e-02,  1.5259e-02,  3.4180e-02,\n",
       "                        1.5137e-02, -1.6357e-02, -3.0151e-02,  7.6675e-04,  3.1128e-02,\n",
       "                       -3.1128e-02, -3.3691e-02, -3.1250e-02,  3.5889e-02, -3.1586e-03,\n",
       "                        1.5442e-02,  1.3428e-02,  5.7373e-02, -3.0762e-02,  2.8564e-02,\n",
       "                        2.0874e-02,  5.2734e-02, -3.3691e-02,  3.1128e-02, -2.4902e-02,\n",
       "                       -2.2217e-02, -1.5503e-02,  9.2773e-03, -1.5381e-02,  2.1240e-02,\n",
       "                       -1.9409e-02, -3.0884e-02, -3.1250e-02,  3.1006e-02,  4.8584e-02,\n",
       "                       -4.4556e-03, -3.2227e-02, -1.3794e-02,  3.3691e-02, -1.3062e-02,\n",
       "                        4.1504e-03, -3.1250e-02, -3.2959e-02,  4.1992e-02,  2.0599e-03,\n",
       "                        2.6367e-02, -2.1484e-02,  1.3245e-02,  3.3936e-02,  1.6724e-02,\n",
       "                       -1.9409e-02,  3.3447e-02,  3.1738e-02,  2.1606e-02, -3.1982e-02,\n",
       "                       -3.1128e-02,  1.0605e-03,  3.6865e-02,  2.9419e-02,  3.6133e-02,\n",
       "                       -7.4768e-03,  2.3193e-02, -3.3447e-02,  3.4668e-02, -5.4321e-03,\n",
       "                        3.7109e-02, -2.8809e-02, -2.9541e-02, -1.4832e-02, -1.1047e-02,\n",
       "                        4.3701e-02,  2.4719e-03,  3.3447e-02, -3.1494e-02, -5.3406e-03,\n",
       "                        6.7444e-03,  3.1738e-02, -2.6001e-02, -1.6479e-02,  1.1292e-03,\n",
       "                        1.3672e-02, -8.0566e-03, -3.1128e-02,  5.9082e-02,  1.4587e-02,\n",
       "                        3.0762e-02,  3.1128e-02,  4.6875e-02, -4.3701e-02,  4.5410e-02,\n",
       "                        1.4099e-02,  3.1250e-02, -4.7119e-02,  2.0752e-02,  3.4668e-02,\n",
       "                       -2.7588e-02,  2.0020e-02, -3.2959e-02,  2.9907e-02,  4.6143e-02,\n",
       "                        3.2471e-02,  5.6458e-03,  1.3672e-02,  3.3203e-02,  1.1719e-02,\n",
       "                        3.2227e-02, -1.1292e-03,  3.1128e-02, -5.1498e-04, -1.5747e-02,\n",
       "                        2.8442e-02, -3.1250e-02,  3.8330e-02, -1.0254e-02, -4.0283e-02,\n",
       "                       -1.4160e-02, -3.1250e-02, -3.0640e-02,  3.1250e-02, -3.7231e-03,\n",
       "                        1.8433e-02,  3.1738e-02,  3.9307e-02, -3.1250e-02, -1.5381e-02,\n",
       "                       -2.0874e-02, -6.5918e-03, -1.9165e-02, -3.1250e-02, -6.7139e-03,\n",
       "                       -1.3672e-02, -3.9307e-02,  2.2217e-02, -3.8574e-02, -6.2500e-02,\n",
       "                        2.0386e-02, -1.3809e-03, -3.0884e-02,  4.0283e-02, -1.7700e-02,\n",
       "                       -3.1494e-02, -3.4912e-02, -2.7924e-03,  7.2021e-03,  3.1891e-03,\n",
       "                       -3.5645e-02,  1.7212e-02,  1.0498e-02,  2.1973e-02, -3.9062e-02,\n",
       "                       -4.6631e-02, -4.8828e-03,  3.1250e-02,  2.9419e-02, -4.0527e-02,\n",
       "                       -1.5015e-02,  1.2817e-02, -6.9275e-03, -8.9722e-03, -6.9885e-03,\n",
       "                        3.6377e-02, -1.8555e-02, -3.4424e-02, -3.2806e-04,  3.0273e-02,\n",
       "                       -3.1006e-02, -3.9062e-02,  3.3691e-02, -7.4158e-03,  1.3733e-02,\n",
       "                        3.0518e-02, -7.0496e-03, -3.6621e-03,  1.3611e-02, -2.3682e-02,\n",
       "                        3.1250e-02, -1.4465e-02,  2.8809e-02, -1.6479e-02, -2.4170e-02,\n",
       "                        8.4229e-03,  1.5198e-02, -1.4648e-02,  6.7444e-03, -3.5400e-02,\n",
       "                       -3.6621e-02, -6.1035e-02,  1.6235e-02, -6.5002e-03, -5.5176e-02,\n",
       "                       -8.0490e-04, -1.3885e-03, -4.0527e-02,  1.0376e-02, -2.1210e-03,\n",
       "                        3.1982e-02, -3.2196e-03,  3.1738e-02, -4.7119e-02,  3.1128e-02,\n",
       "                        1.9287e-02, -1.8921e-02, -1.4771e-02,  3.1250e-02, -3.5645e-02,\n",
       "                        2.6733e-02,  2.1729e-02, -3.7598e-02,  2.4170e-02, -3.1494e-02,\n",
       "                        2.3804e-02,  6.5613e-03, -1.2756e-02, -1.6724e-02, -3.3936e-02,\n",
       "                       -3.1250e-02, -4.2725e-03,  3.5400e-02, -3.0884e-02,  1.4526e-02,\n",
       "                        3.1250e-02,  6.7139e-03,  3.5095e-04,  4.1504e-02,  1.0071e-02,\n",
       "                        3.4912e-02, -3.5889e-02,  3.0518e-02,  2.0630e-02,  7.8125e-03,\n",
       "                        4.9316e-02, -2.2278e-03,  3.6621e-03,  1.5869e-02, -7.0801e-03,\n",
       "                        3.3691e-02, -1.3489e-02,  3.2471e-02,  5.0049e-03,  1.2207e-02,\n",
       "                       -2.1515e-03, -1.5869e-02, -3.1250e-02,  1.3062e-02, -5.0537e-02,\n",
       "                        4.0771e-02, -2.4292e-02,  2.4780e-02, -1.4771e-02, -3.1738e-02,\n",
       "                        2.8076e-02,  3.7354e-02,  3.6621e-02,  3.3875e-03,  2.5024e-02,\n",
       "                       -4.1199e-03,  9.4604e-03, -3.1738e-02, -1.8616e-03, -4.1260e-02,\n",
       "                       -1.1536e-02,  6.9275e-03,  3.0029e-02,  3.2959e-02,  1.5991e-02,\n",
       "                        3.1128e-02,  1.5198e-02, -4.1504e-02,  3.0762e-02, -3.1738e-02,\n",
       "                        3.0029e-02,  6.7139e-03,  3.1250e-02,  1.9775e-02, -1.7578e-02,\n",
       "                        3.3691e-02,  3.3447e-02,  1.9043e-02,  3.0396e-02,  1.6113e-02,\n",
       "                       -1.3916e-02,  3.4668e-02,  6.0425e-03, -2.4261e-03,  3.5889e-02,\n",
       "                       -3.0518e-02, -1.4587e-02,  1.7578e-02,  3.1250e-02,  3.1250e-02,\n",
       "                       -1.4343e-02,  1.0315e-02,  3.1250e-02,  2.3438e-02, -4.8523e-03,\n",
       "                       -3.9551e-02, -7.0496e-03, -1.6113e-02,  3.8574e-02,  3.4668e-02,\n",
       "                        3.7109e-02,  6.6833e-03,  4.6631e-02, -1.4160e-02,  6.2500e-02,\n",
       "                       -6.1951e-03,  5.2002e-02,  3.1250e-02, -4.2725e-02, -9.5825e-03,\n",
       "                        3.1250e-02,  3.1128e-02, -4.0283e-02,  4.2725e-02, -3.2471e-02,\n",
       "                        2.5391e-02, -3.0762e-02, -5.9509e-03,  5.0781e-02, -8.3618e-03,\n",
       "                       -1.6968e-02,  3.1250e-02,  6.3782e-03, -3.0396e-02,  4.4678e-02,\n",
       "                        7.5073e-03, -2.0599e-03,  1.6785e-03,  3.7354e-02,  3.3447e-02,\n",
       "                       -4.5471e-03,  2.8931e-02, -3.2959e-02, -5.0049e-02,  1.5198e-02,\n",
       "                       -1.7822e-02,  2.1484e-02, -3.1738e-02,  9.5215e-03, -3.0884e-02,\n",
       "                       -3.1494e-02,  3.1494e-02,  3.1250e-02, -3.0273e-02, -5.8594e-02,\n",
       "                        1.8188e-02,  3.0273e-02,  2.7222e-02,  2.2949e-02,  3.0640e-02,\n",
       "                        4.6875e-02,  2.2583e-02, -1.4404e-02,  3.1738e-02, -5.0659e-03,\n",
       "                        2.4292e-02,  4.2725e-03, -3.0029e-02,  3.3447e-02,  3.4912e-02,\n",
       "                       -3.2715e-02,  3.0151e-02,  1.3367e-02, -4.1723e-05,  3.0273e-02,\n",
       "                       -1.1292e-02, -5.2490e-03,  3.2501e-03, -3.8574e-02, -3.1738e-02,\n",
       "                       -2.5391e-02, -2.8931e-02,  3.3691e-02,  1.1047e-02, -1.5564e-02,\n",
       "                        3.1128e-02,  3.7598e-02, -1.3245e-02, -3.7598e-02, -1.5320e-02,\n",
       "                       -3.7598e-02, -3.3875e-03,  2.6001e-02,  3.1250e-02,  3.7598e-02,\n",
       "                       -3.0762e-02,  1.6479e-02, -3.1128e-02,  9.7656e-03,  3.0884e-02,\n",
       "                        1.5137e-02, -3.1006e-02, -3.3936e-02,  4.4434e-02,  3.3447e-02,\n",
       "                        1.2939e-02, -1.8066e-02, -1.1780e-02,  4.5776e-03, -1.8188e-02,\n",
       "                        7.7820e-03,  3.1982e-02,  3.0762e-02,  2.7710e-02,  1.4893e-02,\n",
       "                        5.4359e-05, -1.8921e-02, -1.4526e-02, -2.8381e-03,  3.1250e-02,\n",
       "                       -3.5095e-03,  1.5564e-02,  3.2715e-02, -3.0762e-02,  3.5706e-03,\n",
       "                       -3.2227e-02,  5.0659e-03, -3.1128e-02,  1.7212e-02, -3.0762e-02,\n",
       "                       -3.4424e-02, -7.9956e-03, -3.1250e-02,  1.8555e-02, -5.4199e-02,\n",
       "                        3.0273e-02,  5.8105e-02,  6.2500e-02,  1.7166e-03,  3.4424e-02,\n",
       "                       -3.8452e-03,  8.9111e-03, -2.3804e-02,  2.6978e-02,  1.5381e-02,\n",
       "                       -3.0029e-02, -3.7109e-02, -3.1006e-02, -3.1494e-02,  1.4832e-02,\n",
       "                       -9.0942e-03,  1.0910e-03,  2.0264e-02, -3.1128e-02,  3.4424e-02,\n",
       "                       -2.5757e-02,  3.0029e-02,  2.8198e-02, -3.2471e-02, -3.1006e-02,\n",
       "                       -3.1494e-02,  2.8809e-02], dtype=torch.bfloat16)),\n",
       "              ('model.decoder.latent_to_states.weight',\n",
       "               tensor([[ 0.0177, -0.0107, -0.0023,  ..., -0.0093,  0.0287,  0.0145],\n",
       "                       [ 0.0272,  0.0303, -0.0187,  ..., -0.0123, -0.0012,  0.0325],\n",
       "                       [-0.0167, -0.0109, -0.0101,  ...,  0.0261,  0.0267,  0.0128],\n",
       "                       ...,\n",
       "                       [-0.0527,  0.0571, -0.0308,  ..., -0.0566,  0.0008,  0.0047],\n",
       "                       [ 0.0327,  0.0095, -0.0620,  ..., -0.0131,  0.0649, -0.0625],\n",
       "                       [ 0.0510,  0.0371,  0.0481,  ..., -0.0130, -0.0286, -0.0258]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.latent_to_states.bias',\n",
       "               tensor([-0.0046, -0.0006,  0.0215,  ..., -0.0525,  0.0127,  0.0125],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru1.weight_ih_l0',\n",
       "               tensor([[ 0.0540,  0.0284, -0.0381,  ..., -0.0264,  0.0231, -0.0312],\n",
       "                       [-0.0894,  0.0106,  0.0090,  ...,  0.0422,  0.0239, -0.0405],\n",
       "                       [-0.0767,  0.0312,  0.0211,  ...,  0.0352, -0.0496, -0.0248],\n",
       "                       ...,\n",
       "                       [-0.0554, -0.0398,  0.0396,  ...,  0.0554,  0.0330,  0.0066],\n",
       "                       [-0.0854,  0.0175,  0.0031,  ..., -0.0237, -0.0037, -0.0894],\n",
       "                       [ 0.0596,  0.0025,  0.0255,  ..., -0.0192,  0.0146, -0.0693]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru1.weight_hh_l0',\n",
       "               tensor([[ 0.0315,  0.0410,  0.0281,  ...,  0.0549, -0.0139,  0.0361],\n",
       "                       [ 0.0311, -0.0142,  0.0018,  ...,  0.0559, -0.0339,  0.0132],\n",
       "                       [ 0.0151,  0.0466,  0.0221,  ..., -0.0139,  0.0083,  0.0291],\n",
       "                       ...,\n",
       "                       [ 0.0137, -0.0286,  0.0320,  ...,  0.0065, -0.0261, -0.0300],\n",
       "                       [ 0.0208,  0.0253, -0.0072,  ..., -0.0420,  0.0220, -0.0179],\n",
       "                       [-0.0292,  0.0337,  0.0369,  ...,  0.0322, -0.0212,  0.0330]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru1.bias_ih_l0',\n",
       "               tensor([-0.0308, -0.0153, -0.0264,  ..., -0.0265,  0.0157, -0.0126],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru1.bias_hh_l0',\n",
       "               tensor([-0.0308, -0.0253, -0.0142,  ...,  0.0442, -0.0374, -0.0369],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru2.weight_ih_l0',\n",
       "               tensor([[ 0.0381, -0.0588, -0.0530,  ...,  0.0305,  0.0688,  0.0299],\n",
       "                       [-0.0640,  0.0623,  0.0532,  ...,  0.0271,  0.0212,  0.0620],\n",
       "                       [-0.0162,  0.0175,  0.0200,  ..., -0.0157, -0.0139,  0.0271],\n",
       "                       ...,\n",
       "                       [ 0.0084,  0.0062,  0.0288,  ..., -0.0277, -0.0190, -0.0134],\n",
       "                       [ 0.0276, -0.0146, -0.0381,  ..., -0.0193,  0.0187,  0.0236],\n",
       "                       [-0.0231, -0.0311,  0.0137,  ...,  0.0081,  0.0383, -0.0240]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru2.weight_hh_l0',\n",
       "               tensor([[-0.0159,  0.0248,  0.0298,  ..., -0.0277,  0.0315, -0.0120],\n",
       "                       [-0.0293,  0.0371, -0.0260,  ..., -0.0381, -0.0300, -0.0452],\n",
       "                       [-0.0138, -0.0299, -0.0016,  ...,  0.0206,  0.0306, -0.0248],\n",
       "                       ...,\n",
       "                       [-0.0251,  0.0145,  0.0085,  ...,  0.0295, -0.0240,  0.0261],\n",
       "                       [ 0.0112,  0.0403, -0.0183,  ..., -0.0298,  0.0217, -0.0146],\n",
       "                       [ 0.0019,  0.0342,  0.0179,  ...,  0.0160,  0.0219, -0.0151]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru2.bias_ih_l0',\n",
       "               tensor([-0.0154, -0.0320, -0.0164,  ...,  0.0258,  0.0079,  0.0045],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru2.bias_hh_l0',\n",
       "               tensor([ 0.0020, -0.0132, -0.0072,  ...,  0.0088,  0.0215, -0.0186],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru3.weight_ih_l0',\n",
       "               tensor([[-0.0684, -0.0679, -0.0464,  ...,  0.0276,  0.0601, -0.0266],\n",
       "                       [ 0.0610,  0.0972,  0.0286,  ...,  0.0415, -0.0610,  0.0245],\n",
       "                       [-0.0060, -0.0240,  0.0315,  ..., -0.0366,  0.0625,  0.0046],\n",
       "                       ...,\n",
       "                       [ 0.0466,  0.0513,  0.0034,  ...,  0.0359,  0.0544,  0.0021],\n",
       "                       [-0.0039,  0.0581, -0.0027,  ..., -0.0310, -0.0179, -0.0111],\n",
       "                       [ 0.0168, -0.0481,  0.0315,  ..., -0.0549, -0.0292,  0.0074]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru3.weight_hh_l0',\n",
       "               tensor([[-0.0620, -0.0588, -0.0518,  ...,  0.0391, -0.0074, -0.0259],\n",
       "                       [-0.0383, -0.0201,  0.0237,  ..., -0.0466, -0.0084, -0.0120],\n",
       "                       [-0.0187, -0.0134, -0.0280,  ..., -0.0255, -0.0273,  0.0238],\n",
       "                       ...,\n",
       "                       [ 0.0579, -0.0161,  0.0276,  ..., -0.0378, -0.0393,  0.0508],\n",
       "                       [-0.0146,  0.0011,  0.0564,  ..., -0.0339, -0.0564,  0.0374],\n",
       "                       [ 0.0393, -0.0011, -0.0413,  ..., -0.0605,  0.0605,  0.0435]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru3.bias_ih_l0',\n",
       "               tensor([-0.0034,  0.0244, -0.0154,  ..., -0.0260,  0.0129,  0.0154],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.gru3.bias_hh_l0',\n",
       "               tensor([ 0.0283,  0.0050, -0.0154,  ...,  0.0029,  0.0013,  0.0248],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.output.weight',\n",
       "               tensor([[ 0.0625, -0.0522,  0.0625,  ...,  0.0623, -0.0544, -0.0199],\n",
       "                       [ 0.0084,  0.0055,  0.0141,  ...,  0.0182, -0.0139, -0.0226],\n",
       "                       [-0.0022,  0.0029, -0.0123,  ...,  0.0011,  0.0077, -0.0033],\n",
       "                       ...,\n",
       "                       [-0.0023,  0.0198, -0.0045,  ..., -0.0120,  0.0036,  0.0090],\n",
       "                       [-0.0155,  0.0101, -0.0012,  ...,  0.0039,  0.0178, -0.0020],\n",
       "                       [-0.0145,  0.0649,  0.0349,  ..., -0.0165,  0.0304,  0.0220]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.decoder.output.bias',\n",
       "               tensor([-0.0253,  0.0068, -0.0064, -0.0204,  0.0214,  0.0128,  0.0106,  0.0070,\n",
       "                        0.0153,  0.0208, -0.0312, -0.0293, -0.0058, -0.0229, -0.0153, -0.0093,\n",
       "                        0.0189, -0.0228,  0.0186,  0.0020, -0.0309, -0.0164,  0.0278,  0.0309,\n",
       "                       -0.0067,  0.0157, -0.0153, -0.0019,  0.0060, -0.0260, -0.0231, -0.0131,\n",
       "                       -0.0262, -0.0043, -0.0131, -0.0019, -0.0090,  0.0063, -0.0236, -0.0261,\n",
       "                       -0.0096, -0.0167,  0.0044,  0.0148,  0.0052, -0.0096, -0.0067, -0.0255,\n",
       "                        0.0211,  0.0142, -0.0299, -0.0099, -0.0208,  0.0033, -0.0228, -0.0197],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.0.weight',\n",
       "               tensor([[-0.0564, -0.0620,  0.0051,  ..., -0.0349, -0.0168,  0.0337],\n",
       "                       [ 0.0354,  0.0356, -0.0297,  ...,  0.0466, -0.0214, -0.0479],\n",
       "                       [ 0.0304,  0.0302,  0.0564,  ...,  0.0237,  0.0085,  0.0393],\n",
       "                       ...,\n",
       "                       [-0.0613,  0.0282,  0.0327,  ...,  0.0170, -0.0393, -0.0118],\n",
       "                       [ 0.0435,  0.0132, -0.0640,  ...,  0.0006,  0.0199, -0.0381],\n",
       "                       [ 0.0378, -0.0623, -0.0374,  ..., -0.0103,  0.0034,  0.0223]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.0.bias',\n",
       "               tensor([ 1.8311e-02, -5.0293e-02,  1.6479e-02,  3.9062e-02,  1.9409e-02,\n",
       "                       -2.8442e-02, -3.0396e-02,  1.3245e-02, -3.4424e-02, -3.1128e-02,\n",
       "                       -2.0508e-02,  1.0376e-02,  1.5625e-02,  1.6846e-02,  1.9043e-02,\n",
       "                        3.7598e-02,  3.4180e-02,  1.5320e-02, -3.9062e-02,  3.5156e-02,\n",
       "                       -5.5542e-03, -5.6152e-02, -1.6928e-05, -2.4658e-02, -8.7280e-03,\n",
       "                        2.1362e-02, -6.2500e-02,  1.6724e-02, -6.2500e-02, -3.1128e-02,\n",
       "                       -2.8839e-03, -7.0801e-02,  2.3071e-02, -6.2500e-02, -3.1006e-02,\n",
       "                       -4.7852e-02,  4.0527e-02, -4.2480e-02,  3.2715e-02, -3.3447e-02,\n",
       "                        3.6621e-02,  2.0630e-02, -1.8555e-02,  1.4099e-02, -4.0283e-02,\n",
       "                        3.0640e-02,  2.8442e-02, -3.0762e-02, -1.8921e-02, -3.0884e-02,\n",
       "                       -2.8320e-02, -4.0039e-02, -3.1494e-02, -1.1414e-02,  2.6123e-02,\n",
       "                       -5.0537e-02, -2.2827e-02,  3.2471e-02,  3.5889e-02, -1.7700e-02,\n",
       "                       -6.2500e-02,  3.3447e-02,  3.9795e-02, -4.9316e-02, -1.4282e-02,\n",
       "                        1.6113e-02,  2.9175e-02, -4.1260e-02, -2.9907e-02,  2.3560e-02,\n",
       "                        4.1260e-02, -1.5625e-02, -1.4038e-02, -4.1992e-02,  4.4434e-02,\n",
       "                        3.2959e-02, -4.7363e-02, -1.7090e-02, -3.1006e-02, -4.5410e-02,\n",
       "                       -2.8564e-02, -3.2715e-02,  2.7100e-02, -4.7607e-02, -3.0640e-02,\n",
       "                       -1.5503e-02, -3.5156e-02,  9.7046e-03, -1.6968e-02,  3.1982e-02,\n",
       "                       -1.8677e-02,  3.5889e-02, -4.9438e-03, -6.2012e-02, -4.3945e-02,\n",
       "                        2.1729e-02,  2.1973e-02, -4.3701e-02, -2.5269e-02, -3.6865e-02,\n",
       "                        1.9287e-02,  4.3945e-02, -1.9409e-02,  1.7334e-02,  8.2397e-03,\n",
       "                       -1.5137e-02, -2.2217e-02,  1.4526e-02,  9.3384e-03, -9.8267e-03,\n",
       "                       -1.9897e-02, -3.0151e-02, -4.6997e-03, -4.7119e-02, -1.5564e-02,\n",
       "                       -8.3008e-03,  5.1025e-02,  1.1658e-02, -4.5410e-02,  1.5015e-02,\n",
       "                       -4.2480e-02,  5.4626e-03, -3.0762e-02, -6.0791e-02, -6.0547e-02,\n",
       "                       -7.0190e-03, -6.0791e-02,  3.5156e-02, -2.1729e-02,  1.9169e-04,\n",
       "                       -4.0527e-02,  3.2227e-02, -1.8921e-02,  2.2583e-02, -3.3447e-02,\n",
       "                       -3.4668e-02, -3.9551e-02, -4.1748e-02,  1.4526e-02,  1.5198e-02,\n",
       "                        1.3062e-02, -1.6113e-02,  1.6479e-02, -3.5645e-02, -3.0640e-02,\n",
       "                        1.3855e-02,  1.3428e-02,  7.9346e-03, -1.5503e-02, -4.9072e-02,\n",
       "                       -3.0273e-02, -5.2002e-02, -5.2979e-02, -3.0884e-02, -4.5898e-02,\n",
       "                       -2.6733e-02,  3.3447e-02, -6.1951e-03, -6.1035e-02, -1.7456e-02,\n",
       "                       -4.1260e-02,  1.5625e-02,  1.5015e-02, -2.6489e-02, -3.0151e-02,\n",
       "                        1.7944e-02, -3.0518e-02, -2.7832e-02,  1.4221e-02,  1.3916e-02,\n",
       "                        8.3618e-03, -3.0029e-02, -2.7466e-02, -2.7954e-02,  3.3203e-02,\n",
       "                       -3.4424e-02,  1.5869e-02, -3.1738e-02, -2.1851e-02, -3.2471e-02,\n",
       "                        4.5898e-02,  3.9795e-02, -3.0884e-02,  9.8877e-03, -3.4424e-02,\n",
       "                       -1.2207e-02,  1.3428e-02,  2.1362e-02, -2.2461e-02, -3.5889e-02,\n",
       "                       -3.2654e-03, -1.4404e-02, -1.1780e-02,  4.2969e-02,  9.5825e-03,\n",
       "                       -2.7588e-02,  4.2725e-02,  2.2217e-02,  7.2021e-03, -3.0396e-02,\n",
       "                       -8.3008e-03,  1.6479e-02, -3.5400e-02, -5.9082e-02,  2.0752e-02,\n",
       "                        2.6367e-02, -6.2500e-02,  2.6245e-02,  1.3489e-02,  1.9287e-02,\n",
       "                       -2.8687e-02, -1.8677e-02, -1.5198e-02,  1.2146e-02,  2.8839e-03,\n",
       "                       -3.6377e-02, -1.2390e-02,  2.1606e-02, -3.7598e-02,  1.9531e-02,\n",
       "                        6.2500e-02,  1.3855e-02, -1.8158e-03,  1.9287e-02, -2.9297e-02,\n",
       "                        1.4832e-02, -2.2095e-02,  2.5635e-02,  1.2695e-02, -5.2002e-02,\n",
       "                       -6.2256e-02,  3.5645e-02,  2.2461e-02, -4.8096e-02, -9.6436e-03,\n",
       "                       -3.5156e-02, -2.9663e-02,  1.8555e-02, -3.5156e-02,  2.6733e-02,\n",
       "                        1.6846e-02, -5.9326e-02,  8.6670e-03, -3.1738e-02, -1.6479e-02,\n",
       "                       -2.2095e-02,  2.2949e-02, -5.2490e-02,  3.6133e-02, -2.8442e-02,\n",
       "                        1.6968e-02,  2.4902e-02,  3.5645e-02, -2.6123e-02, -2.1362e-02,\n",
       "                        3.5889e-02, -2.0142e-02,  2.9053e-02, -2.2705e-02,  9.1553e-03,\n",
       "                        2.2583e-02,  1.8188e-02,  9.9487e-03,  4.2969e-02, -8.1177e-03,\n",
       "                        3.3203e-02, -6.2012e-02, -3.4668e-02, -4.1992e-02, -1.4893e-02,\n",
       "                       -3.5156e-02, -5.6152e-02, -3.0762e-02,  4.1504e-02, -4.3945e-02,\n",
       "                       -2.3071e-02, -1.6968e-02, -5.4443e-02, -2.5513e-02,  3.2959e-02,\n",
       "                       -4.4861e-03, -2.6123e-02,  2.2705e-02, -1.7944e-02, -3.8818e-02,\n",
       "                       -3.5156e-02, -4.7607e-02,  3.9291e-04, -3.4912e-02, -2.3804e-02,\n",
       "                       -3.1250e-02, -3.1250e-02, -2.9785e-02, -3.1128e-02, -3.1494e-02,\n",
       "                       -4.4556e-03, -4.1016e-02, -6.5430e-02,  1.2695e-02, -6.2500e-02,\n",
       "                       -4.9805e-02, -2.9907e-02, -3.5400e-02, -2.8442e-02, -6.1523e-02,\n",
       "                       -2.1118e-02, -1.4038e-02, -3.2959e-02, -7.5195e-02,  8.1177e-03,\n",
       "                       -5.6396e-02, -2.3438e-02, -3.1250e-02,  1.1597e-02,  3.1738e-02,\n",
       "                        2.1606e-02,  2.0142e-02, -2.8809e-02,  3.6133e-02,  2.9907e-02,\n",
       "                       -3.0273e-02, -5.6396e-02, -5.2979e-02, -3.6377e-02,  2.9419e-02,\n",
       "                       -1.6357e-02,  4.7913e-03,  2.3315e-02,  1.6846e-02,  1.2817e-02,\n",
       "                        3.2959e-02,  1.5991e-02,  1.5625e-02, -2.3438e-02,  3.1494e-02,\n",
       "                       -3.0640e-02, -6.2256e-02,  1.3062e-02, -2.5635e-02,  1.4343e-03,\n",
       "                       -2.3956e-03,  1.5442e-02, -3.0029e-02, -2.5513e-02,  1.5198e-02,\n",
       "                       -3.4912e-02, -2.9297e-02, -4.0283e-02, -3.3203e-02,  3.7842e-02,\n",
       "                        3.0273e-02,  1.4709e-02,  2.8534e-03, -1.9043e-02, -2.8198e-02,\n",
       "                        1.8799e-02,  2.9053e-02,  3.1128e-02, -3.0396e-02,  4.4189e-02,\n",
       "                        9.8267e-03, -3.6865e-02,  1.6968e-02,  2.7832e-02, -4.7607e-02,\n",
       "                       -3.1982e-02,  1.7334e-02, -3.6621e-02, -3.1738e-02,  6.6223e-03,\n",
       "                       -4.5898e-02, -3.1738e-02, -6.0120e-03,  3.6377e-02, -5.9570e-02,\n",
       "                        7.9956e-03, -5.5420e-02,  1.5259e-02, -4.6387e-02, -3.0762e-02,\n",
       "                        2.4780e-02, -1.0010e-02, -4.8584e-02,  2.8564e-02,  9.8267e-03,\n",
       "                        1.5198e-02, -4.9561e-02, -3.8086e-02, -1.9897e-02, -8.3008e-03,\n",
       "                        1.9989e-03, -2.3438e-02,  1.5137e-02,  1.4709e-02,  2.4780e-02,\n",
       "                        1.6235e-02,  1.9531e-02, -6.1035e-04, -4.5166e-02,  2.5269e-02,\n",
       "                        1.2451e-02, -7.1106e-03, -1.1414e-02,  4.8584e-02,  1.6357e-02,\n",
       "                       -4.0527e-02,  1.5869e-02, -2.6978e-02, -3.0762e-02,  3.4668e-02,\n",
       "                       -1.6724e-02, -4.6875e-02, -4.1260e-02,  2.8687e-02, -4.1016e-02,\n",
       "                       -2.0264e-02, -4.5166e-02, -4.0039e-02, -3.8086e-02,  3.9062e-02,\n",
       "                        3.4180e-02,  2.7100e-02, -1.5076e-02, -7.2098e-04, -4.8096e-02,\n",
       "                       -3.1128e-03, -5.9082e-02, -1.5320e-02, -2.3682e-02, -4.6143e-02,\n",
       "                        1.6968e-02, -1.7944e-02, -5.1270e-03,  2.0020e-02, -3.1494e-02,\n",
       "                       -3.4180e-02,  2.2583e-02, -4.3701e-02, -4.2725e-02,  3.0029e-02,\n",
       "                       -2.4536e-02,  5.3101e-03, -3.0640e-02,  1.4771e-02, -6.2988e-02,\n",
       "                       -4.9316e-02, -4.6631e-02,  2.0264e-02, -4.1992e-02, -2.2827e-02,\n",
       "                       -4.3457e-02, -3.4668e-02, -3.9307e-02, -1.6846e-02, -2.0508e-02,\n",
       "                       -3.6621e-02, -5.1270e-02,  2.6367e-02,  1.4465e-02, -5.9814e-02,\n",
       "                       -2.5269e-02, -4.6631e-02,  3.9551e-02, -2.7832e-02, -2.1362e-02,\n",
       "                       -2.5482e-03, -3.4180e-02, -2.9541e-02, -5.8350e-02, -2.8442e-02,\n",
       "                       -4.5898e-02, -3.5889e-02, -1.5747e-02,  1.4099e-02,  1.2573e-02,\n",
       "                       -1.5259e-02, -7.8735e-03, -3.1250e-02,  2.0020e-02,  3.0975e-03,\n",
       "                       -3.1128e-02, -2.6245e-02,  6.8359e-03, -6.2988e-02, -5.0293e-02,\n",
       "                       -2.4048e-02, -4.2480e-02, -6.1279e-02,  5.2490e-03, -3.9062e-02,\n",
       "                        1.5137e-02,  3.5400e-03,  1.0254e-02, -1.7822e-02, -2.9419e-02,\n",
       "                       -2.9419e-02, -4.3213e-02,  2.0790e-04, -2.9541e-02, -3.4180e-02,\n",
       "                       -2.3804e-03, -3.8330e-02,  1.8066e-02,  1.6602e-02, -5.1758e-02,\n",
       "                       -4.6387e-02,  4.0039e-02, -3.3447e-02, -3.0884e-02, -2.9663e-02,\n",
       "                       -3.0884e-02,  2.6489e-02], dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.2.weight',\n",
       "               tensor([[ 0.0054,  0.0092, -0.0430,  ..., -0.0114, -0.0079,  0.0366],\n",
       "                       [-0.0378,  0.0325, -0.0099,  ..., -0.0182, -0.0618,  0.0645],\n",
       "                       [-0.0388,  0.0101, -0.0286,  ..., -0.0143, -0.0452,  0.0043],\n",
       "                       ...,\n",
       "                       [-0.0261, -0.0256, -0.0371,  ..., -0.0308,  0.0029,  0.0356],\n",
       "                       [ 0.0206, -0.0417, -0.0364,  ..., -0.0210,  0.0417, -0.0171],\n",
       "                       [ 0.0204, -0.0640,  0.0116,  ...,  0.0282,  0.0288,  0.0284]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.2.bias',\n",
       "               tensor([-0.0117,  0.0225, -0.0084,  0.0101,  0.0208,  0.0150,  0.0271,  0.0237,\n",
       "                        0.0197,  0.0098, -0.0198,  0.0062, -0.0038, -0.0198,  0.0139,  0.0023,\n",
       "                       -0.0304, -0.0315, -0.0127,  0.0080, -0.0525, -0.0062,  0.0153,  0.0156,\n",
       "                        0.0164,  0.0145,  0.0238, -0.0247,  0.0496, -0.0210,  0.0330,  0.0104,\n",
       "                        0.0167, -0.0356, -0.0155, -0.0469,  0.0162,  0.0177, -0.0430,  0.0212,\n",
       "                       -0.0203, -0.0500,  0.0327, -0.0791, -0.0381, -0.0132,  0.0160, -0.0305,\n",
       "                       -0.0515, -0.0187,  0.0493,  0.0143, -0.0064, -0.0119,  0.0060, -0.0253,\n",
       "                       -0.0304, -0.0430,  0.0081, -0.0532, -0.0381, -0.0479, -0.0070,  0.0111,\n",
       "                       -0.0369,  0.0194,  0.0447,  0.0093,  0.0210,  0.0139,  0.0136,  0.0398,\n",
       "                       -0.0096, -0.0356, -0.0225,  0.0430,  0.0070, -0.0625, -0.0325,  0.0153,\n",
       "                       -0.0381,  0.0134,  0.0376,  0.0084, -0.0060, -0.0464,  0.0221,  0.0564,\n",
       "                       -0.0134, -0.0547,  0.0293,  0.0330, -0.0278,  0.0294,  0.0142,  0.0286,\n",
       "                       -0.0508,  0.0119, -0.0327, -0.0452, -0.0454,  0.0145,  0.0164,  0.0381,\n",
       "                        0.0154, -0.0703,  0.0154,  0.0405,  0.0133,  0.0286, -0.0303, -0.0327,\n",
       "                        0.0147, -0.0530,  0.0322,  0.0422, -0.0366, -0.0134, -0.0025, -0.0223,\n",
       "                       -0.0145,  0.0187, -0.0139, -0.0046,  0.0135,  0.0069,  0.0249,  0.0036],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.4.weight',\n",
       "               tensor([[ 0.0791,  0.0096,  0.0234,  0.0481,  0.0287,  0.0747,  0.0275,  0.0408,\n",
       "                         0.0308,  0.0659,  0.0339, -0.0437,  0.0271, -0.0737,  0.0557,  0.0371,\n",
       "                        -0.0325,  0.0505,  0.0356,  0.0208,  0.0332,  0.0613,  0.0148, -0.0591,\n",
       "                         0.0613,  0.0182, -0.0012,  0.0281, -0.0574, -0.0767,  0.0532,  0.0072,\n",
       "                         0.0068, -0.0381, -0.0588,  0.0204,  0.0918,  0.0417, -0.0479, -0.0300,\n",
       "                         0.0249,  0.0869, -0.0167,  0.0640, -0.0679,  0.0208,  0.0256, -0.0147,\n",
       "                        -0.0718,  0.0830,  0.0459,  0.0830,  0.0288, -0.0178,  0.0150,  0.0206,\n",
       "                        -0.0369,  0.0503, -0.0388, -0.0508, -0.0452, -0.0309, -0.0408,  0.0596,\n",
       "                        -0.0522,  0.0106,  0.0452,  0.0042, -0.0376,  0.0457, -0.0181, -0.0181,\n",
       "                         0.0864, -0.0645,  0.0391, -0.0530, -0.0133,  0.0654,  0.0064,  0.0522,\n",
       "                        -0.0283, -0.0522, -0.0092, -0.0306,  0.0175, -0.0669,  0.0361,  0.0850,\n",
       "                         0.0542,  0.0967,  0.0251,  0.0096, -0.0312, -0.0121, -0.0151,  0.0688,\n",
       "                        -0.0381,  0.0139, -0.0280,  0.0278, -0.0166, -0.0557, -0.0309, -0.0781,\n",
       "                        -0.0442,  0.0535, -0.0552, -0.0510, -0.0055, -0.0693, -0.0376, -0.0488,\n",
       "                        -0.0703,  0.0938, -0.0327, -0.0742, -0.0466, -0.0320, -0.0239,  0.0588,\n",
       "                         0.0310, -0.0156, -0.0215,  0.0469,  0.0422,  0.0703,  0.0228,  0.0688],\n",
       "                       [-0.0564,  0.0679,  0.0613,  0.0284,  0.0098,  0.0415,  0.0513,  0.0143,\n",
       "                         0.0630,  0.0391,  0.0491, -0.0093,  0.0320,  0.0654,  0.0840, -0.0461,\n",
       "                        -0.0153,  0.0752,  0.0103,  0.0474,  0.0479,  0.0214,  0.0098,  0.0315,\n",
       "                         0.0292, -0.0369,  0.0374, -0.0030, -0.0498, -0.0483, -0.0176, -0.0859,\n",
       "                        -0.0069,  0.0559,  0.0308, -0.0474, -0.0547,  0.0718, -0.0108,  0.0127,\n",
       "                         0.0129, -0.0562,  0.0055, -0.0205, -0.0630, -0.0201, -0.0366, -0.0796,\n",
       "                         0.0173, -0.0354,  0.0170, -0.0215, -0.0173, -0.0630,  0.0243, -0.0640,\n",
       "                        -0.0413,  0.0304, -0.0518,  0.0099, -0.0214, -0.0167,  0.0303,  0.0302,\n",
       "                        -0.0903, -0.0625,  0.0295,  0.0280,  0.0315,  0.0036,  0.0166,  0.0291,\n",
       "                         0.0334, -0.0320, -0.0015,  0.0405,  0.0026, -0.0369, -0.0126, -0.0469,\n",
       "                         0.0369, -0.0547, -0.0203,  0.0669, -0.0131, -0.0145, -0.0830,  0.0449,\n",
       "                        -0.0461,  0.0679, -0.0005, -0.0203, -0.0129,  0.0471,  0.1021,  0.0630,\n",
       "                         0.0087, -0.0586, -0.0544,  0.0552, -0.0359,  0.0840,  0.0337,  0.0422,\n",
       "                        -0.0139,  0.0177, -0.0815, -0.0053, -0.0630, -0.0466, -0.0337,  0.0302,\n",
       "                        -0.0243, -0.0684,  0.0420, -0.0618,  0.0303,  0.0889, -0.0542, -0.0291,\n",
       "                         0.0544, -0.0786,  0.0454,  0.0037,  0.0776, -0.0233,  0.0569,  0.0427],\n",
       "                       [-0.0086,  0.0146,  0.0586, -0.0398,  0.0327, -0.0454,  0.0522, -0.0332,\n",
       "                        -0.0240, -0.0503, -0.0325, -0.0334,  0.0240, -0.0072, -0.0332, -0.0098,\n",
       "                         0.0742,  0.0283, -0.0464, -0.0649,  0.0381,  0.0801,  0.0244, -0.0232,\n",
       "                         0.0559,  0.0133, -0.0334, -0.0300, -0.0238, -0.0312,  0.0532, -0.0342,\n",
       "                         0.0732,  0.0625,  0.0376,  0.0432,  0.0171,  0.0630,  0.0012, -0.0540,\n",
       "                        -0.0273, -0.0151,  0.0544, -0.0513, -0.0469,  0.0874, -0.0383, -0.0176,\n",
       "                         0.0530,  0.0378, -0.0249, -0.0151,  0.0022, -0.0332, -0.0713, -0.0227,\n",
       "                         0.0297, -0.0264, -0.0557, -0.0242,  0.0422, -0.0510,  0.0596,  0.0364,\n",
       "                        -0.0791, -0.0825,  0.0442,  0.0457,  0.0039, -0.0322, -0.0427, -0.0425,\n",
       "                        -0.0503, -0.0447, -0.0601, -0.0287, -0.0236,  0.0162,  0.0111, -0.0023,\n",
       "                         0.0386,  0.0339,  0.0796,  0.0376,  0.0198, -0.0166,  0.0898, -0.0378,\n",
       "                        -0.0405, -0.0325, -0.0791,  0.0659, -0.0461,  0.0464, -0.0356, -0.0605,\n",
       "                         0.0811,  0.0811,  0.0043, -0.0298, -0.0124,  0.0381, -0.0811,  0.0153,\n",
       "                         0.0579,  0.0525, -0.0177, -0.0151, -0.0227, -0.0505,  0.0518,  0.0219,\n",
       "                        -0.0178, -0.0435, -0.0396,  0.0476, -0.0217, -0.0332,  0.0064,  0.0239,\n",
       "                         0.0371, -0.0195,  0.0635, -0.0513,  0.0923,  0.0486, -0.0259,  0.0757],\n",
       "                       [ 0.0112,  0.0417, -0.0488,  0.0723,  0.0635, -0.0022,  0.0505,  0.0825,\n",
       "                        -0.0439,  0.0571,  0.0830,  0.0698, -0.0275,  0.1338, -0.0374,  0.0569,\n",
       "                         0.0386, -0.0835, -0.0140,  0.0688,  0.0708,  0.0530, -0.0176, -0.0131,\n",
       "                        -0.0684, -0.0649, -0.0006,  0.0608,  0.0294,  0.0625, -0.0811, -0.0405,\n",
       "                        -0.0281, -0.0515,  0.0258, -0.0610, -0.0075, -0.0264,  0.0337, -0.0718,\n",
       "                        -0.0233,  0.0659, -0.0190, -0.0513,  0.0164, -0.0156, -0.0693,  0.0598,\n",
       "                        -0.0270,  0.1030,  0.0297, -0.0347,  0.0659,  0.0417, -0.0160, -0.0361,\n",
       "                         0.0601,  0.0199,  0.0613, -0.0161, -0.0131, -0.0234,  0.0170, -0.0156,\n",
       "                        -0.0898, -0.0825, -0.0198,  0.0311,  0.0265, -0.0732,  0.0149,  0.0518,\n",
       "                         0.0415,  0.0039,  0.0583,  0.0786, -0.0315,  0.0405,  0.0332, -0.0107,\n",
       "                         0.0361, -0.0522,  0.0320, -0.0066, -0.0405, -0.0347, -0.0393, -0.0045,\n",
       "                         0.0432, -0.0693, -0.0449,  0.0525,  0.0562, -0.0259,  0.0703,  0.0996,\n",
       "                        -0.0811,  0.0293, -0.0537,  0.0708, -0.0266, -0.0161,  0.0405,  0.0231,\n",
       "                         0.0403,  0.0303,  0.0151,  0.0605,  0.0635,  0.0806, -0.0879,  0.0781,\n",
       "                         0.0171, -0.0266,  0.0957, -0.0383,  0.0170,  0.0064, -0.0771, -0.0171,\n",
       "                         0.0500, -0.0154, -0.0342, -0.0181,  0.0435,  0.0087,  0.0126,  0.0422],\n",
       "                       [-0.0322, -0.0106, -0.0070,  0.0732,  0.0503,  0.0121, -0.0400, -0.0170,\n",
       "                        -0.0422,  0.0415,  0.0003,  0.0330, -0.0469,  0.1504, -0.0152, -0.0311,\n",
       "                        -0.0398, -0.0265, -0.0167, -0.0344, -0.0166,  0.0693,  0.0830,  0.0023,\n",
       "                        -0.0645, -0.0408, -0.0280, -0.0232,  0.0183,  0.0292,  0.0127, -0.0513,\n",
       "                        -0.0698,  0.0518,  0.0664, -0.0342, -0.0698, -0.0435,  0.0488, -0.0317,\n",
       "                        -0.0081,  0.0471,  0.0425,  0.0742, -0.0269, -0.0150, -0.0243,  0.0104,\n",
       "                        -0.0159, -0.0654, -0.0026,  0.0102, -0.0649,  0.0420,  0.0339, -0.0354,\n",
       "                        -0.0018,  0.0156,  0.0058, -0.0170,  0.0811, -0.0124,  0.0427,  0.0474,\n",
       "                        -0.0255, -0.0309, -0.0289, -0.0057, -0.0165,  0.0476,  0.0400, -0.0182,\n",
       "                        -0.0703,  0.0132,  0.0243,  0.0356,  0.0713, -0.0262, -0.0503, -0.0152,\n",
       "                        -0.0669, -0.0080, -0.1055, -0.0143, -0.0757, -0.0737,  0.0422, -0.0500,\n",
       "                         0.0145, -0.0157, -0.0277,  0.0425, -0.0430,  0.0859, -0.0195, -0.0815,\n",
       "                        -0.0131, -0.0518, -0.0244,  0.0581,  0.0295,  0.0820,  0.0603, -0.0152,\n",
       "                        -0.0483, -0.0077,  0.0649,  0.0525, -0.0732, -0.0693,  0.0801, -0.0074,\n",
       "                        -0.0403,  0.0396,  0.0498, -0.0261,  0.0757,  0.0378, -0.0135,  0.0640,\n",
       "                         0.0476,  0.0361,  0.0525,  0.0688,  0.0356,  0.0598, -0.0469, -0.0674],\n",
       "                       [ 0.0106, -0.0101,  0.0586, -0.0479,  0.0075,  0.0835,  0.0566,  0.0574,\n",
       "                         0.0530,  0.0129, -0.0540, -0.0596, -0.0069,  0.0894,  0.0221, -0.0422,\n",
       "                        -0.0449,  0.0698, -0.0266,  0.0071,  0.0067,  0.0039,  0.0054, -0.0679,\n",
       "                         0.0075, -0.0408, -0.0142, -0.0457, -0.0923,  0.0023, -0.0245, -0.0442,\n",
       "                        -0.0245, -0.0493,  0.0586, -0.0723,  0.0781, -0.0674, -0.0542,  0.0366,\n",
       "                        -0.0574, -0.0253,  0.0728, -0.0096,  0.0056,  0.0293,  0.0361,  0.0645,\n",
       "                        -0.0007, -0.0029, -0.0052, -0.0542,  0.0376, -0.0562,  0.0124,  0.0037,\n",
       "                         0.0815, -0.0059, -0.0654, -0.0723, -0.0339,  0.0041,  0.0703,  0.0535,\n",
       "                        -0.0309,  0.0270,  0.0659,  0.0598, -0.0354,  0.0070,  0.0466,  0.0967,\n",
       "                         0.0879, -0.0791,  0.0532,  0.0674,  0.0540,  0.0596, -0.0233,  0.0093,\n",
       "                        -0.0089, -0.0874, -0.0085,  0.0366, -0.0259,  0.0483, -0.0820, -0.0057,\n",
       "                        -0.0102, -0.0072,  0.0227, -0.0237,  0.0148,  0.0304,  0.0176, -0.0369,\n",
       "                        -0.0510,  0.0231,  0.0508, -0.0393, -0.0535, -0.0146,  0.0835,  0.0250,\n",
       "                        -0.0439, -0.0162, -0.0312, -0.0723,  0.0233, -0.0786, -0.0156, -0.0444,\n",
       "                        -0.0262, -0.0021,  0.0544, -0.0141,  0.0820,  0.0145,  0.0510, -0.0596,\n",
       "                         0.0481, -0.0471, -0.0186,  0.0708, -0.0378,  0.0004,  0.0048,  0.0378],\n",
       "                       [-0.0640,  0.0064, -0.0151,  0.0184, -0.0410,  0.0388, -0.0157,  0.0771,\n",
       "                         0.0669, -0.0767,  0.0303,  0.0153, -0.0055, -0.0052,  0.0422,  0.0840,\n",
       "                         0.0454, -0.0703, -0.0498,  0.0723, -0.0125,  0.0747, -0.0796,  0.0898,\n",
       "                        -0.0613, -0.0155, -0.0664, -0.0312,  0.0752,  0.0181,  0.0112, -0.0576,\n",
       "                         0.0693,  0.0145,  0.0413,  0.0669, -0.0305, -0.0850, -0.0093,  0.0093,\n",
       "                         0.0645, -0.0486,  0.0530,  0.0128, -0.0552, -0.0132, -0.0294,  0.0315,\n",
       "                        -0.0500, -0.0312,  0.0645, -0.0260,  0.0640,  0.0344, -0.0221, -0.0413,\n",
       "                         0.0505, -0.0277, -0.0041,  0.0515,  0.0278,  0.0148, -0.0801,  0.0381,\n",
       "                        -0.0161,  0.0260,  0.0437,  0.0583, -0.0703,  0.0913, -0.0835,  0.0166,\n",
       "                        -0.0374, -0.0522,  0.0079, -0.0112,  0.0544, -0.0610, -0.0304, -0.0315,\n",
       "                         0.0664, -0.0337, -0.0167, -0.0659, -0.0173, -0.1001,  0.0442, -0.0874,\n",
       "                        -0.0043, -0.1006,  0.0061, -0.0361, -0.0208, -0.0312, -0.0302,  0.0059,\n",
       "                         0.0298, -0.0220, -0.0874, -0.0752, -0.0186,  0.0024, -0.0072,  0.0153,\n",
       "                        -0.0603, -0.0078,  0.0032,  0.0659, -0.0145,  0.0767, -0.0145, -0.0413,\n",
       "                        -0.0289, -0.0598, -0.0125, -0.0374, -0.0474,  0.0142,  0.0193, -0.0276,\n",
       "                         0.0544, -0.0304, -0.0471, -0.0238,  0.0515, -0.0732, -0.0337,  0.0439]],\n",
       "                      dtype=torch.bfloat16)),\n",
       "              ('model.classifier.mlp.4.bias',\n",
       "               tensor([ 0.0684,  0.0532, -0.0659, -0.0154,  0.0737, -0.0188, -0.0625],\n",
       "                      dtype=torch.bfloat16))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 110012},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 110012,\n",
       "     'completed': 110012,\n",
       "     'started': 110012,\n",
       "     'processed': 110012},\n",
       "    'current': {'ready': 3929,\n",
       "     'completed': 3929,\n",
       "     'started': 3929,\n",
       "     'processed': 3929},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 2, 'completed': 2},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 110012,\n",
       "       'completed': 110012},\n",
       "      'current': {'ready': 3929, 'completed': 3929}},\n",
       "     'zero_grad': {'total': {'ready': 110012,\n",
       "       'completed': 110012,\n",
       "       'started': 110012},\n",
       "      'current': {'ready': 3929, 'completed': 3929, 'started': 3929}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 983,\n",
       "     'completed': 983,\n",
       "     'started': 983,\n",
       "     'processed': 983},\n",
       "    'current': {'ready': 983,\n",
       "     'completed': 983,\n",
       "     'started': 983,\n",
       "     'processed': 983},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 28,\n",
       "     'completed': 27,\n",
       "     'started': 28,\n",
       "     'processed': 28},\n",
       "    'current': {'ready': 28,\n",
       "     'completed': 27,\n",
       "     'started': 28,\n",
       "     'processed': 28}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"EarlyStopping{'monitor': 'val_total_loss', 'mode': 'min'}\": {'wait_count': 5,\n",
       "   'stopped_epoch': 27,\n",
       "   'best_score': tensor(0.2521),\n",
       "   'patience': 5},\n",
       "  \"ModelCheckpoint{'monitor': 'val_total_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'val_total_loss',\n",
       "   'best_model_score': tensor(0.2521),\n",
       "   'best_model_path': '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/minicddd-epoch=22-val_total_loss=0.2521.ckpt',\n",
       "   'current_score': tensor(0.2578),\n",
       "   'dirpath': '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints',\n",
       "   'best_k_models': {'/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/minicddd-epoch=22-val_total_loss=0.2521.ckpt': tensor(0.2521),\n",
       "    '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/minicddd-epoch=23-val_total_loss=0.2543.ckpt': tensor(0.2543),\n",
       "    '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/minicddd-epoch=25-val_total_loss=0.2578.ckpt': tensor(0.2578)},\n",
       "   'kth_best_model_path': '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/minicddd-epoch=25-val_total_loss=0.2578.ckpt',\n",
       "   'kth_value': tensor(0.2578),\n",
       "   'last_model_path': '/home/ergot/projects/miniCDDD/600k_chembl_float16/checkpoints/last.ckpt'}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 1.4976e-06,  0.0000e+00,  0.0000e+00,  ..., -2.3544e-06,\n",
       "               9.0804e-08,  1.1846e-06],\n",
       "             [ 4.2915e-06,  0.0000e+00,  0.0000e+00,  ...,  6.0081e-05,\n",
       "              -6.2957e-07,  1.1861e-05],\n",
       "             [ 1.1399e-06,  0.0000e+00,  0.0000e+00,  ..., -3.1292e-06,\n",
       "              -2.6450e-07, -2.5183e-06],\n",
       "             ...,\n",
       "             [-3.6240e-05,  0.0000e+00,  0.0000e+00,  ...,  2.1973e-03,\n",
       "              -3.6716e-05, -6.0797e-05],\n",
       "             [ 8.6308e-05,  0.0000e+00,  0.0000e+00,  ...,  3.2425e-04,\n",
       "              -1.5163e-04, -3.3677e-06],\n",
       "             [-3.2663e-05,  0.0000e+00,  0.0000e+00,  ..., -1.2436e-03,\n",
       "               2.8968e-05, -2.0313e-04]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.3006e-10, 0.0000e+00, 0.0000e+00,  ..., 1.5050e-06, 2.3647e-10,\n",
       "              3.9872e-09],\n",
       "             [1.3097e-09, 0.0000e+00, 0.0000e+00,  ..., 3.8445e-06, 1.4115e-09,\n",
       "              1.5367e-08],\n",
       "             [2.0100e-10, 0.0000e+00, 0.0000e+00,  ..., 9.5367e-07, 1.1823e-10,\n",
       "              6.1409e-09],\n",
       "             ...,\n",
       "             [3.8184e-07, 0.0000e+00, 0.0000e+00,  ..., 9.8419e-04, 4.7982e-06,\n",
       "              3.4124e-06],\n",
       "             [1.4342e-07, 0.0000e+00, 0.0000e+00,  ..., 1.1139e-03, 7.7486e-06,\n",
       "              1.4231e-06],\n",
       "             [2.6450e-07, 0.0000e+00, 0.0000e+00,  ..., 4.9591e-04, 4.2319e-06,\n",
       "              3.9041e-06]], dtype=torch.bfloat16)},\n",
       "    1: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 5.0962e-06, -2.4438e-05, -2.3097e-06,  ...,  3.2336e-06,\n",
       "              -1.8626e-06, -1.0252e-05],\n",
       "             [ 1.4722e-05, -5.2452e-06,  6.1393e-06,  ...,  9.1791e-06,\n",
       "              -2.4289e-06,  2.3246e-06],\n",
       "             [ 5.9903e-06, -4.9770e-06, -8.9407e-06,  ..., -7.6890e-06,\n",
       "              -5.7220e-06, -1.2200e-07],\n",
       "             ...,\n",
       "             [ 2.4986e-04, -4.9591e-04, -2.2316e-04,  ..., -2.2697e-04,\n",
       "              -1.2493e-04,  2.1935e-04],\n",
       "             [ 1.0920e-04, -1.8311e-04, -1.0300e-04,  ..., -1.6499e-04,\n",
       "              -1.1587e-04,  3.0398e-05],\n",
       "             [-4.6492e-05,  1.9550e-04, -2.7847e-04,  ...,  1.2589e-04,\n",
       "              -2.0027e-05, -7.9632e-05]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[5.6578e-08, 1.1921e-07, 3.0966e-08,  ..., 1.0012e-08, 1.6997e-08,\n",
       "              8.8476e-09],\n",
       "             [8.4285e-08, 5.4389e-07, 2.7753e-07,  ..., 4.7497e-08, 3.0035e-08,\n",
       "              6.0536e-08],\n",
       "             [7.4506e-08, 3.1665e-08, 1.6950e-07,  ..., 3.8184e-08, 7.7765e-08,\n",
       "              2.9104e-08],\n",
       "             ...,\n",
       "             [5.9903e-06, 1.7405e-05, 3.1471e-05,  ..., 2.2948e-06, 1.1995e-06,\n",
       "              2.7269e-06],\n",
       "             [2.3991e-06, 3.8445e-06, 8.1658e-06,  ..., 1.2815e-06, 1.2219e-06,\n",
       "              2.0266e-06],\n",
       "             [2.3693e-06, 4.2617e-06, 2.1458e-05,  ..., 2.8163e-06, 7.4133e-07,\n",
       "              2.6822e-06]], dtype=torch.bfloat16)},\n",
       "    2: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 5.2929e-05,  2.0695e-04, -6.7711e-05,  ..., -7.7438e-04,\n",
       "             -1.9073e-03, -7.5684e-03], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([3.5912e-06, 2.6226e-05, 7.8082e-06,  ..., 1.1230e-02, 8.6670e-03,\n",
       "             9.4604e-03], dtype=torch.bfloat16)},\n",
       "    3: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 5.2929e-05,  2.0695e-04, -6.7711e-05,  ..., -2.8801e-04,\n",
       "             -5.1880e-04, -3.9978e-03], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([3.5912e-06, 2.6226e-05, 7.8082e-06,  ..., 3.9368e-03, 1.9531e-03,\n",
       "             2.4719e-03], dtype=torch.bfloat16)},\n",
       "    4: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-6.6939e-09,  2.9395e-09,  2.7358e-09,  ...,  4.9768e-09,\n",
       "               2.8813e-09, -1.0652e-08],\n",
       "             [ 7.4506e-08, -2.0489e-08,  4.3074e-08,  ...,  4.1211e-08,\n",
       "              -1.7229e-08,  2.9802e-08],\n",
       "             [-5.3318e-08,  1.0664e-07, -8.5565e-09,  ...,  2.2352e-08,\n",
       "               2.6892e-08, -3.4459e-08],\n",
       "             ...,\n",
       "             [-6.1691e-06,  5.0664e-06, -5.2154e-06,  ..., -4.6194e-06,\n",
       "              -7.8231e-07, -4.1164e-07],\n",
       "             [-1.4246e-05,  7.1526e-05,  5.5134e-06,  ...,  1.4424e-05,\n",
       "               1.3053e-05, -1.9073e-05],\n",
       "             [ 4.4405e-06, -4.7088e-06,  1.7360e-06,  ..., -3.5912e-06,\n",
       "              -1.3039e-06,  2.3842e-06]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.1902e-13, 9.0949e-13, 1.3500e-13,  ..., 3.2641e-14, 2.6290e-13,\n",
       "              1.9273e-13],\n",
       "             [1.9895e-12, 7.8444e-12, 4.6185e-13,  ..., 4.5830e-13, 1.8741e-13,\n",
       "              6.0041e-13],\n",
       "             [6.2528e-13, 4.5475e-12, 5.7288e-14,  ..., 5.9508e-14, 2.5757e-13,\n",
       "              4.7606e-13],\n",
       "             ...,\n",
       "             [1.2922e-08, 6.8918e-08, 1.7390e-09,  ..., 1.9645e-09, 3.7544e-09,\n",
       "              7.4506e-09],\n",
       "             [3.2131e-08, 4.8801e-07, 1.4901e-08,  ..., 7.9162e-09, 3.5390e-08,\n",
       "              4.4936e-08],\n",
       "             [9.0222e-09, 3.5157e-08, 5.5006e-09,  ..., 2.3429e-09, 1.0710e-08,\n",
       "              1.5018e-08]], dtype=torch.bfloat16)},\n",
       "    5: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)},\n",
       "    6: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-5.1688e-08,  4.3400e-07, -3.0175e-07,  ..., -3.3140e-05,\n",
       "             -1.3542e-04,  8.1658e-06], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([1.5916e-11, 6.4119e-11, 3.7971e-11,  ..., 5.2527e-07, 2.3991e-06,\n",
       "             9.5367e-07], dtype=torch.bfloat16)},\n",
       "    7: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-5.1688e-08,  4.3400e-07, -3.0175e-07,  ..., -9.1195e-06,\n",
       "             -2.4319e-05,  4.0829e-06], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([1.5916e-11, 6.4119e-11, 3.7971e-11,  ..., 5.9139e-08, 1.5739e-07,\n",
       "             2.4587e-07], dtype=torch.bfloat16)},\n",
       "    8: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-9.5497e-11,  2.3138e-09, -2.8813e-09,  ...,  1.4334e-09,\n",
       "               4.4020e-10, -2.7103e-10],\n",
       "             [-6.9849e-10, -1.4043e-09, -9.7207e-09,  ...,  2.0082e-09,\n",
       "              -1.5862e-09, -7.5670e-10],\n",
       "             [ 3.4106e-11, -1.8917e-10, -6.0754e-10,  ...,  1.2824e-10,\n",
       "              -4.1109e-10,  1.1596e-10],\n",
       "             ...,\n",
       "             [-3.7951e-08, -1.5795e-06,  2.7940e-07,  ..., -9.0338e-08,\n",
       "              -3.6955e-06, -4.7311e-07],\n",
       "             [ 5.3318e-08, -2.7567e-07, -6.2957e-07,  ...,  5.4017e-08,\n",
       "               1.3113e-06, -2.8685e-07],\n",
       "             [-2.0210e-07, -1.1697e-06, -7.0035e-07,  ..., -2.4587e-07,\n",
       "              -5.1409e-07, -8.0094e-07]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.9255e-16, 7.7161e-15, 3.7748e-15,  ..., 4.0072e-16, 1.1602e-14,\n",
       "              8.6736e-16],\n",
       "             [5.6379e-17, 1.9290e-15, 1.4988e-15,  ..., 6.9389e-17, 7.6050e-15,\n",
       "              1.4138e-16],\n",
       "             [3.3177e-17, 4.7531e-16, 4.4756e-16,  ..., 3.1008e-17, 1.8475e-16,\n",
       "              3.0705e-16],\n",
       "             ...,\n",
       "             [2.2965e-11, 1.7371e-10, 1.3097e-10,  ..., 1.9327e-11, 3.1832e-10,\n",
       "              3.5243e-11],\n",
       "             [8.8676e-12, 2.0736e-10, 1.3915e-10,  ..., 1.3870e-11, 6.6939e-10,\n",
       "              4.3656e-11],\n",
       "             [7.7307e-12, 1.6007e-10, 1.1732e-10,  ..., 8.8107e-12, 2.7103e-10,\n",
       "              5.5024e-11]], dtype=torch.bfloat16)},\n",
       "    9: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)},\n",
       "    10: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-5.0291e-08,  9.4587e-10, -1.4144e-08,  ..., -3.0756e-05,\n",
       "             -1.3888e-05, -2.7940e-07], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([7.3328e-12, 2.2595e-12, 9.9476e-13,  ..., 1.4901e-07, 2.3842e-07,\n",
       "             2.1979e-07], dtype=torch.bfloat16)},\n",
       "    11: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-5.0291e-08,  9.4587e-10, -1.4144e-08,  ..., -1.4067e-05,\n",
       "             -6.6757e-06, -2.9057e-07], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([7.3328e-12, 2.2595e-12, 9.9476e-13,  ..., 3.2363e-08, 4.1910e-08,\n",
       "             3.9814e-08], dtype=torch.bfloat16)},\n",
       "    12: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-5.5432e-06, -1.5616e-05, -7.2420e-06,  ..., -3.5018e-06,\n",
       "               4.5896e-06, -4.6939e-07],\n",
       "             [ 8.4639e-06, -1.9431e-05, -5.5730e-06,  ..., -2.1756e-06,\n",
       "               5.3346e-06, -2.1756e-06],\n",
       "             [ 3.0845e-06, -1.0133e-05,  1.9372e-06,  ..., -8.0466e-07,\n",
       "               2.4587e-06, -1.1921e-06],\n",
       "             ...,\n",
       "             [-9.5963e-06,  2.7657e-05,  6.6459e-06,  ...,  1.5199e-06,\n",
       "              -4.5300e-06,  2.5779e-06],\n",
       "             [-2.2411e-05,  4.2439e-05, -3.0696e-06,  ...,  5.6811e-08,\n",
       "              -5.3048e-06, -2.8312e-06],\n",
       "             [ 1.6332e-05, -2.0385e-05,  4.9472e-06,  ..., -3.4720e-06,\n",
       "               5.0366e-06, -1.1036e-07]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.1921e-07, 6.9663e-07, 1.9674e-08,  ..., 8.2946e-10, 1.3752e-09,\n",
       "              9.5315e-10],\n",
       "             [3.3062e-08, 2.3842e-07, 2.1420e-08,  ..., 2.7467e-10, 5.3842e-10,\n",
       "              3.1832e-10],\n",
       "             [3.0966e-08, 2.4214e-07, 8.9058e-09,  ..., 2.0464e-10, 6.8758e-10,\n",
       "              2.4738e-10],\n",
       "             ...,\n",
       "             [6.0070e-08, 1.5087e-07, 2.2585e-08,  ..., 2.8558e-10, 1.4697e-09,\n",
       "              5.8571e-10],\n",
       "             [3.6322e-08, 2.4587e-07, 1.7346e-08,  ..., 2.8194e-10, 1.0114e-09,\n",
       "              3.7471e-10],\n",
       "             [6.1467e-08, 2.0862e-07, 2.5728e-08,  ..., 3.8017e-10, 1.0550e-09,\n",
       "              5.3842e-10]], dtype=torch.bfloat16)},\n",
       "    13: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 4.2200e-05,  3.9577e-05,  1.5080e-05, -3.9861e-07, -3.3855e-05,\n",
       "              3.5524e-05,  3.5614e-06, -2.2769e-05, -2.5392e-05,  3.5763e-05,\n",
       "             -9.3132e-07,  5.9366e-05,  8.4639e-06, -9.7275e-05, -8.2850e-06,\n",
       "             -2.3007e-05,  1.2755e-05, -6.0201e-06, -1.5736e-04,  4.4823e-05,\n",
       "              5.7220e-06,  3.9816e-05,  2.7299e-05, -2.6107e-05, -7.9632e-05,\n",
       "              3.0994e-06,  3.0041e-05, -1.6212e-05,  4.4703e-06,  3.3528e-06,\n",
       "             -1.0610e-05,  1.6913e-06, -9.2506e-05, -6.9618e-05,  7.3433e-05,\n",
       "              2.1577e-05,  3.9816e-05, -9.9659e-05,  6.8665e-05,  7.9632e-05,\n",
       "              1.8001e-05, -3.7432e-05, -4.5300e-05,  3.9302e-07,  1.1349e-04,\n",
       "              1.0431e-05,  2.1577e-05,  9.6798e-05, -5.9843e-05, -1.4752e-06,\n",
       "             -3.4809e-05,  3.2902e-05, -2.8729e-05,  1.8120e-05,  9.5844e-05,\n",
       "             -6.8188e-05,  5.0545e-05, -3.5018e-06,  1.1253e-04, -3.4094e-05,\n",
       "             -3.7998e-06, -1.5974e-05, -2.3842e-06,  6.7711e-05,  4.5538e-05,\n",
       "              2.8849e-05, -8.2016e-05, -1.9073e-05,  1.4603e-05,  7.4506e-06,\n",
       "             -4.8876e-05,  4.1723e-06, -6.8665e-05,  8.2254e-06,  6.1989e-05,\n",
       "              5.2214e-05,  6.0558e-05, -6.8843e-06,  2.3365e-05,  4.9591e-05,\n",
       "              8.5235e-06, -3.3677e-06, -5.1260e-05,  8.3447e-05, -5.3644e-05,\n",
       "             -4.9591e-05, -8.2970e-05,  2.0385e-05, -2.1815e-05,  5.0783e-05,\n",
       "             -2.6464e-05, -9.7752e-06, -5.9843e-05, -5.7697e-05,  2.7299e-05,\n",
       "             -1.0920e-04,  6.6310e-07, -6.5327e-05,  8.5831e-05, -4.1246e-05,\n",
       "             -9.0122e-05, -4.9353e-05,  3.0398e-05,  3.3379e-05,  2.7299e-05,\n",
       "              2.8729e-05, -1.2589e-04, -7.2002e-05, -1.1995e-06,  6.5565e-06,\n",
       "             -7.5340e-05,  2.7567e-06,  4.4584e-05,  1.3784e-06,  4.0293e-05,\n",
       "             -7.9155e-05,  1.5140e-05,  4.3392e-05,  3.1233e-05,  2.8372e-05,\n",
       "             -6.4969e-06,  3.8624e-05,  8.0109e-05,  3.3081e-06, -4.8399e-05,\n",
       "              7.1526e-05,  4.1485e-05,  2.0623e-05, -6.4373e-06,  1.6451e-05,\n",
       "              4.6492e-05, -1.1861e-05,  2.2531e-05, -7.0572e-05,  1.3638e-04,\n",
       "              1.4961e-05,  4.1425e-06, -5.6744e-05, -5.1260e-05,  1.6332e-05,\n",
       "             -7.4387e-05,  2.6107e-05, -1.4529e-06,  2.8491e-05, -4.8161e-05,\n",
       "              7.6294e-05,  4.0770e-05,  1.4961e-05, -1.8716e-05,  5.6267e-05,\n",
       "              2.4915e-05,  5.9307e-06,  5.1260e-05,  8.8692e-05, -1.2040e-05,\n",
       "             -1.0610e-05,  9.1553e-05, -5.7697e-05,  1.0586e-04, -4.2319e-06,\n",
       "              2.8849e-05, -1.0777e-04, -5.1260e-05,  1.0967e-04, -8.8215e-06,\n",
       "             -5.0783e-05,  1.6212e-04,  1.2112e-04, -4.4107e-06, -4.1485e-05,\n",
       "              7.0095e-05, -2.1338e-05, -6.9737e-06, -1.9312e-05,  2.3842e-07,\n",
       "              3.7909e-05, -8.0109e-05, -2.7657e-05,  2.4676e-05,  1.3733e-04,\n",
       "             -1.7762e-05,  4.0054e-05,  5.2691e-05, -9.1553e-05, -8.8215e-06,\n",
       "             -2.6524e-06, -9.4771e-06, -9.1076e-05, -4.1008e-05, -7.0095e-05,\n",
       "             -5.1975e-05,  2.8372e-05,  9.7275e-05, -3.0920e-07,  1.0347e-04,\n",
       "             -3.5286e-05,  1.1176e-06, -3.3379e-06, -1.5497e-05, -1.0061e-04,\n",
       "             -3.1471e-05, -2.8968e-05,  7.7248e-05,  7.7724e-05,  1.8024e-04,\n",
       "             -1.8835e-05,  7.0572e-05,  8.6427e-06,  4.3392e-05, -1.4305e-05,\n",
       "             -4.5538e-05,  9.6560e-06,  2.4557e-05,  1.2684e-04, -5.3883e-05,\n",
       "             -1.2302e-04,  1.1444e-05, -5.1498e-05, -7.2718e-06, -3.1233e-05,\n",
       "              1.0490e-04,  7.1049e-05, -4.8876e-05,  1.1349e-04,  6.4850e-05,\n",
       "              1.2875e-04, -3.5524e-05, -1.3530e-05,  5.5075e-05,  4.5896e-06,\n",
       "             -2.5034e-05,  7.9274e-06, -6.1035e-05, -8.5831e-05, -9.0599e-05,\n",
       "              5.3167e-05,  4.8161e-05,  3.1292e-06,  4.2915e-05,  5.5313e-05,\n",
       "              5.5432e-06,  4.8399e-05, -2.7895e-05,  3.8147e-05, -3.0279e-05,\n",
       "             -1.5140e-05,  5.9605e-05,  1.4114e-04, -7.6294e-05,  3.2187e-05,\n",
       "              1.1349e-04,  6.1095e-06, -6.2943e-05, -1.1826e-04,  6.8665e-05,\n",
       "              4.3631e-05, -6.0081e-05, -4.6968e-05, -9.2387e-06,  4.4823e-05,\n",
       "             -6.6757e-06,  4.9174e-06,  1.6809e-05,  3.4273e-06,  1.8001e-05,\n",
       "             -2.9087e-05,  6.1512e-05, -5.6744e-05, -1.8105e-06,  2.6971e-06,\n",
       "              5.8651e-05,  1.3709e-05,  8.7023e-06,  1.5378e-05, -3.5524e-05,\n",
       "             -6.5804e-05, -4.8161e-05,  1.3053e-05,  3.5286e-05, -1.0777e-04,\n",
       "              4.9829e-05, -1.3638e-04,  9.1076e-05,  2.5868e-05,  4.9472e-06,\n",
       "              3.4720e-06, -1.2338e-05,  4.5300e-05,  7.4863e-05, -9.8705e-05,\n",
       "             -1.9550e-05, -3.9577e-05, -1.7405e-05,  5.9843e-05,  5.7220e-05,\n",
       "             -6.9141e-06,  2.7061e-05, -2.5630e-06, -1.4687e-04,  3.4094e-05,\n",
       "              5.2929e-05, -5.3048e-06, -1.6451e-05,  6.7234e-05,  4.8637e-05,\n",
       "             -8.5831e-06, -2.1100e-05,  2.9922e-05, -3.3855e-05, -3.4332e-05,\n",
       "              2.0385e-05,  2.1756e-06,  3.9816e-05, -8.5354e-05,  3.0398e-05,\n",
       "             -2.2602e-04, -7.7248e-05, -7.2956e-05,  5.8413e-06, -7.6294e-06,\n",
       "             -1.9819e-06, -1.1921e-05,  2.5511e-05,  5.6505e-05,  1.7166e-05,\n",
       "             -3.9101e-05,  1.1206e-04, -3.6716e-05,  3.9816e-05, -7.1526e-06,\n",
       "             -5.2691e-05, -2.5749e-05,  2.7895e-05, -5.5552e-05, -3.3379e-05,\n",
       "              5.4836e-05,  6.7353e-06,  4.1485e-05,  1.9550e-05, -1.1250e-06,\n",
       "              2.3961e-05,  6.3479e-06,  5.7936e-05, -1.6117e-04, -2.8491e-05,\n",
       "             -2.4796e-05,  1.0669e-05, -3.8862e-05,  1.3590e-05,  6.2943e-05,\n",
       "             -3.9816e-05,  1.5736e-04,  4.6492e-05,  9.4175e-06, -1.5736e-05,\n",
       "              1.0347e-04, -4.3869e-05,  5.4836e-05, -9.8944e-06,  2.1607e-06,\n",
       "             -4.9591e-05, -5.6267e-05,  1.5736e-05, -6.2943e-05, -3.8147e-05,\n",
       "              5.1260e-05, -8.1658e-06,  3.2902e-05, -3.9101e-05, -2.5392e-05,\n",
       "              3.9816e-05,  2.1815e-05, -6.9141e-06,  3.0756e-05, -2.3484e-05,\n",
       "              8.6784e-05, -8.7261e-05, -6.2466e-05, -4.7922e-05, -4.2439e-05,\n",
       "              2.8372e-05,  8.0109e-05,  9.4414e-05,  5.7936e-05,  2.3603e-05,\n",
       "              1.4305e-04, -2.5153e-05,  4.8161e-05,  1.8954e-05,  5.8889e-05,\n",
       "              3.1948e-05, -1.3173e-05,  1.4454e-06,  4.6790e-06,  4.5538e-05,\n",
       "             -3.6716e-05, -5.9605e-05, -1.1325e-05,  1.3351e-04, -1.4842e-05,\n",
       "             -7.0095e-05, -1.1772e-06,  7.6771e-05, -1.3828e-05, -1.8924e-06,\n",
       "              3.6240e-05,  6.5804e-05,  3.0279e-05,  1.0967e-05,  9.1076e-05,\n",
       "              2.4676e-05,  9.1195e-06, -3.0398e-05,  9.8348e-06,  9.1553e-05,\n",
       "              3.2425e-05,  1.3065e-04, -4.3392e-05, -1.0550e-05,  3.9577e-05,\n",
       "              1.2144e-06,  3.3379e-05, -9.1076e-05, -7.6294e-05, -2.1100e-05,\n",
       "              6.3896e-05,  6.6757e-05, -6.0499e-06,  1.4782e-05,  5.3167e-05,\n",
       "             -6.5327e-05, -9.1076e-05,  2.5630e-05,  6.6757e-05, -4.0293e-05,\n",
       "              2.8372e-05,  5.8115e-06, -1.4496e-04, -5.9009e-06, -3.0756e-05,\n",
       "             -3.0100e-06,  3.9339e-06,  3.0398e-05, -4.1008e-05,  6.8665e-05,\n",
       "             -3.5286e-05,  1.0505e-06,  1.2589e-04, -1.8024e-04,  4.5538e-05,\n",
       "             -1.8120e-04, -5.3644e-05, -2.0742e-05,  1.8954e-05,  8.6308e-05,\n",
       "             -9.4414e-05,  1.5068e-04, -4.4107e-05,  9.2506e-05, -2.0742e-05,\n",
       "             -2.3603e-05, -6.8188e-05,  5.4121e-05,  2.6107e-05,  5.6624e-06,\n",
       "              5.4598e-05, -3.0920e-07,  2.9325e-05,  2.6584e-05,  9.9659e-05,\n",
       "              5.0068e-06,  7.3910e-05, -8.4877e-05,  1.2100e-05,  8.6784e-05,\n",
       "             -3.5286e-05, -2.9802e-05, -7.8201e-05,  5.0545e-05, -7.0095e-05,\n",
       "              8.2850e-06,  7.0572e-05, -1.4484e-05, -1.1587e-04,  1.6451e-05,\n",
       "             -1.7524e-05, -6.2943e-05, -1.4752e-06, -9.4414e-05,  1.0431e-05,\n",
       "              3.2425e-05, -2.1309e-06,  5.4836e-05,  1.1158e-04,  8.1062e-05,\n",
       "             -6.5327e-05, -5.2214e-05, -2.1696e-05, -1.4424e-05,  4.8637e-05,\n",
       "              1.4591e-04,  1.1873e-04, -3.2425e-05, -9.2983e-06,  3.0398e-05,\n",
       "              4.3869e-05,  2.9325e-05, -5.2452e-05, -7.6294e-05, -6.9141e-05,\n",
       "             -1.1301e-04,  6.3419e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([7.6294e-06, 1.9968e-06, 2.0862e-06, 1.0654e-06, 3.8743e-06, 2.1905e-06,\n",
       "             1.2282e-08, 3.9339e-06, 3.9041e-06, 3.1292e-06, 1.2442e-06, 3.6955e-06,\n",
       "             1.9222e-06, 8.7023e-06, 3.8743e-06, 2.6971e-06, 1.7136e-06, 4.7386e-06,\n",
       "             3.8445e-06, 2.4885e-06, 8.9779e-07, 1.2890e-06, 1.0580e-06, 5.2527e-07,\n",
       "             5.2452e-06, 7.6741e-07, 2.0564e-06, 7.6294e-06, 4.0829e-06, 3.1432e-08,\n",
       "             1.7807e-06, 9.6858e-07, 1.6764e-06, 2.6822e-06, 2.5034e-06, 3.9637e-06,\n",
       "             1.4231e-06, 3.8743e-06, 2.5481e-06, 2.8759e-06, 3.4720e-06, 1.0282e-06,\n",
       "             5.6028e-06, 3.8147e-06, 2.1160e-06, 4.8056e-07, 2.6226e-06, 3.8147e-06,\n",
       "             3.9041e-06, 2.5332e-06, 1.8701e-06, 9.9838e-07, 3.4422e-06, 1.9222e-06,\n",
       "             5.4762e-07, 3.3379e-06, 2.0564e-06, 8.3447e-07, 3.6508e-06, 1.1250e-06,\n",
       "             2.1458e-06, 7.6890e-06, 9.7789e-08, 7.4506e-06, 9.7603e-07, 3.9041e-06,\n",
       "             3.1292e-06, 1.9372e-06, 2.7269e-06, 4.2021e-06, 3.8147e-06, 4.8662e-08,\n",
       "             1.9222e-06, 3.4459e-07, 1.9372e-06, 3.6061e-06, 3.9041e-06, 4.3958e-07,\n",
       "             1.9819e-06, 1.1027e-06, 3.9935e-06, 1.2200e-07, 1.9521e-06, 2.6375e-06,\n",
       "             1.8626e-06, 1.0729e-06, 1.9521e-06, 4.0531e-06, 6.3181e-06, 3.8147e-06,\n",
       "             5.8115e-06, 1.9222e-06, 1.9073e-06, 1.6764e-06, 3.5763e-07, 2.3544e-06,\n",
       "             2.0713e-06, 2.4587e-06, 1.3188e-06, 3.7402e-06, 6.5565e-06, 8.5682e-07,\n",
       "             1.9968e-06, 4.8056e-07, 2.2203e-06, 3.9637e-06, 4.9770e-06, 3.9935e-06,\n",
       "             5.8906e-08, 3.8147e-06, 4.0233e-06, 4.0513e-08, 2.6971e-06, 1.9222e-06,\n",
       "             1.9073e-06, 1.9670e-06, 4.0829e-06, 1.5125e-06, 2.2501e-06, 8.9034e-07,\n",
       "             4.0531e-06, 5.0664e-06, 2.5630e-06, 1.2480e-07, 3.8147e-06, 1.3337e-06,\n",
       "             1.0505e-06, 2.3246e-06, 4.8280e-06, 2.4140e-06, 4.5262e-07, 3.8147e-06,\n",
       "             1.7583e-06, 2.9206e-06, 5.7817e-06, 2.6375e-06, 3.3993e-08, 3.4571e-06,\n",
       "             5.1782e-07, 3.4571e-06, 3.5018e-06, 1.9073e-06, 2.2054e-06, 2.4587e-07,\n",
       "             9.8348e-07, 1.2368e-06, 4.7088e-06, 5.3272e-07, 3.7253e-07, 9.6112e-07,\n",
       "             3.8743e-06, 4.4703e-08, 3.9041e-06, 3.2634e-06, 5.2853e-08, 1.0014e-05,\n",
       "             1.1697e-06, 1.3933e-06, 3.9041e-06, 1.8720e-07, 9.1642e-07, 2.1458e-06,\n",
       "             4.1127e-06, 2.7269e-06, 2.2948e-06, 3.8445e-06, 5.2154e-06, 3.9935e-06,\n",
       "             1.3784e-06, 3.8147e-06, 3.8147e-06, 1.4901e-06, 1.7881e-07, 3.9339e-06,\n",
       "             4.1677e-08, 3.3081e-06, 2.1756e-06, 1.9521e-06, 1.9073e-06, 5.1260e-06,\n",
       "             1.9670e-06, 2.1160e-06, 1.1846e-06, 3.7104e-06, 3.8147e-06, 2.3693e-06,\n",
       "             2.3693e-06, 4.7386e-06, 3.8445e-06, 7.8082e-06, 3.8743e-06, 1.0058e-06,\n",
       "             3.9041e-06, 1.9073e-06, 4.7311e-07, 8.8811e-06, 2.1309e-06, 6.0070e-08,\n",
       "             3.1898e-08, 2.4438e-06, 2.4885e-06, 1.4976e-06, 2.1905e-06, 2.7418e-06,\n",
       "             9.1195e-06, 1.2890e-06, 4.9770e-06, 1.9968e-06, 2.7269e-06, 3.9116e-07,\n",
       "             1.3411e-06, 3.8147e-06, 2.2948e-06, 1.9819e-06, 8.7172e-07, 4.8876e-06,\n",
       "             2.7269e-06, 2.3693e-06, 1.9073e-06, 1.9968e-06, 1.9073e-06, 8.5831e-06,\n",
       "             6.2585e-07, 4.3213e-06, 2.3246e-06, 2.1160e-06, 7.8604e-07, 4.3213e-07,\n",
       "             1.9372e-06, 3.6359e-06, 1.9521e-06, 1.9670e-06, 3.0100e-06, 6.7651e-06,\n",
       "             3.4422e-06, 1.9073e-06, 4.1425e-06, 3.8147e-06, 2.3246e-06, 7.6294e-06,\n",
       "             1.9073e-06, 3.8147e-06, 7.6294e-06, 4.0531e-06, 6.8173e-07, 4.8801e-07,\n",
       "             9.6112e-07, 4.5598e-06, 2.5481e-06, 4.7684e-07, 5.3346e-06, 3.9339e-06,\n",
       "             1.9372e-06, 4.6194e-06, 5.0962e-06, 2.0117e-06, 2.1458e-06, 1.6913e-06,\n",
       "             2.6263e-07, 3.9041e-06, 2.4140e-06, 7.7486e-06, 9.4175e-06, 3.0966e-08,\n",
       "             1.8105e-06, 3.5316e-06, 6.0722e-07, 2.0415e-06, 5.6624e-06, 2.9104e-08,\n",
       "             2.5481e-06, 3.9339e-06, 3.9041e-06, 3.8743e-06, 1.2666e-06, 3.9935e-06,\n",
       "             7.6294e-06, 4.6100e-08, 1.7211e-06, 3.8147e-06, 2.0862e-06, 4.1425e-06,\n",
       "             4.0233e-06, 8.7079e-08, 3.8743e-06, 2.0140e-08, 3.4226e-08, 3.8147e-06,\n",
       "             1.9819e-06, 4.8280e-06, 3.7812e-07, 6.5863e-06, 1.2517e-06, 3.6061e-06,\n",
       "             3.8147e-06, 3.6322e-08, 3.8445e-06, 1.9819e-06, 3.9935e-06, 5.1558e-06,\n",
       "             3.8743e-06, 3.9637e-06, 3.8445e-06, 1.9521e-06, 2.5332e-07, 9.6858e-07,\n",
       "             1.3709e-06, 3.8147e-06, 3.8147e-06, 1.9819e-06, 1.0133e-06, 4.2375e-08,\n",
       "             1.9372e-06, 6.9141e-06, 3.8147e-06, 4.4107e-06, 3.8743e-06, 1.9819e-06,\n",
       "             1.6317e-06, 1.2293e-06, 3.9041e-06, 2.2948e-06, 5.8487e-07, 2.2501e-06,\n",
       "             3.5018e-06, 3.2336e-06, 1.1325e-06, 4.1910e-08, 3.5614e-06, 2.1905e-06,\n",
       "             2.4587e-06, 3.8445e-06, 3.0547e-06, 4.8280e-06, 3.3826e-06, 1.9521e-06,\n",
       "             2.0564e-06, 3.8147e-06, 3.8445e-06, 1.7881e-06, 4.8429e-07, 1.5348e-06,\n",
       "             3.8445e-06, 7.2718e-06, 1.3709e-06, 2.2501e-06, 2.3991e-06, 1.9222e-06,\n",
       "             5.8673e-08, 2.9504e-06, 1.7732e-06, 5.8115e-06, 1.9521e-06, 1.0654e-06,\n",
       "             3.0249e-06, 1.7062e-06, 3.9339e-06, 3.2485e-06, 1.0878e-06, 1.8859e-08,\n",
       "             1.1399e-06, 3.8147e-06, 2.8126e-07, 1.1474e-06, 7.7765e-08, 1.9968e-06,\n",
       "             6.0070e-08, 1.9222e-06, 5.7369e-07, 3.0249e-06, 4.0233e-06, 1.9521e-06,\n",
       "             6.9849e-08, 1.3113e-06, 1.3411e-06, 2.6226e-06, 4.9174e-06, 3.9637e-06,\n",
       "             6.7800e-07, 6.9141e-06, 4.1425e-06, 1.9819e-06, 3.9935e-06, 1.9968e-06,\n",
       "             1.9744e-07, 1.6689e-06, 2.8014e-06, 7.7486e-06, 1.2293e-07, 1.0207e-06,\n",
       "             2.5481e-06, 1.9222e-06, 6.0536e-08, 4.1537e-07, 2.1011e-06, 3.7849e-06,\n",
       "             9.1195e-06, 2.2235e-08, 2.0564e-06, 3.1441e-06, 2.4885e-06, 2.8289e-08,\n",
       "             2.0713e-06, 4.2617e-06, 2.4214e-07, 2.4289e-06, 1.2144e-06, 1.1697e-06,\n",
       "             3.1441e-06, 3.9339e-06, 2.9616e-07, 3.8445e-06, 2.2352e-06, 1.9222e-06,\n",
       "             2.1458e-06, 3.8147e-06, 3.5018e-06, 2.1905e-06, 6.0536e-08, 9.9093e-07,\n",
       "             9.6858e-07, 1.9819e-06, 2.9802e-06, 3.9637e-06, 1.8552e-06, 1.9670e-06,\n",
       "             3.0398e-06, 3.8743e-06, 5.0664e-07, 3.9041e-06, 1.9968e-06, 2.0415e-06,\n",
       "             8.0466e-07, 1.0431e-06, 3.8147e-06, 3.8147e-06, 2.0266e-06, 2.7418e-06,\n",
       "             1.5018e-08, 1.9073e-06, 1.9558e-08, 3.9339e-06, 1.9222e-06, 4.1127e-06,\n",
       "             1.8626e-06, 2.1160e-06, 2.1309e-06, 2.5928e-06, 3.8147e-06, 1.8328e-06,\n",
       "             4.0531e-06, 1.9968e-06, 1.2293e-06, 1.2573e-07, 2.1160e-06, 4.5300e-06,\n",
       "             4.7684e-06, 3.5316e-06, 8.4639e-06, 4.5598e-06, 3.8147e-06, 3.4720e-06,\n",
       "             3.7700e-06, 2.2948e-06, 2.5630e-06, 7.2718e-06, 7.6890e-06, 2.1458e-06,\n",
       "             3.8743e-06, 2.2501e-06, 3.8147e-06, 1.9521e-06, 4.8056e-07, 1.9670e-06,\n",
       "             3.8147e-06, 1.1176e-06, 3.8743e-06, 1.9968e-06, 1.9372e-06, 2.1607e-06,\n",
       "             2.0955e-08, 7.6294e-06, 3.5614e-06, 2.1011e-06, 1.4901e-07, 1.0505e-06,\n",
       "             3.5763e-07, 2.2650e-06, 3.8147e-06, 1.4901e-07, 9.1195e-06, 4.0829e-06,\n",
       "             4.9770e-06, 3.9935e-06, 3.8147e-06, 8.0094e-07, 1.3411e-06, 2.6822e-06,\n",
       "             3.0734e-08, 2.8908e-06, 4.4107e-06, 4.0233e-06, 2.6226e-06, 3.1441e-06,\n",
       "             2.2054e-06, 3.1292e-06, 1.2219e-06, 3.6061e-06, 1.9670e-06, 1.5944e-06,\n",
       "             1.9521e-06, 1.9670e-06], dtype=torch.bfloat16)},\n",
       "    14: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-3.7481e-20,  3.0281e-20,  3.4305e-20,  ..., -3.0917e-20,\n",
       "              -3.7481e-20,  2.7317e-20],\n",
       "             [ 3.8370e-07, -1.3690e-07,  7.4878e-07,  ...,  6.9849e-08,\n",
       "              -3.4086e-07,  4.4145e-07],\n",
       "             [ 1.7788e-07, -4.3400e-07,  7.5996e-07,  ...,  2.5928e-06,\n",
       "               3.4422e-06, -3.7104e-06],\n",
       "             ...,\n",
       "             [ 2.9802e-07, -1.2964e-06, -5.0664e-07,  ...,  3.9116e-07,\n",
       "              -1.3113e-06,  2.8871e-07],\n",
       "             [-2.0266e-06,  1.8161e-07, -3.4226e-08,  ...,  2.4140e-06,\n",
       "               3.8929e-07, -1.3933e-06],\n",
       "             [-4.6752e-07, -8.6613e-08, -1.1027e-06,  ...,  1.5721e-06,\n",
       "               1.1325e-06, -1.0133e-06]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[3.5470e-11, 1.1653e-11, 2.2510e-11,  ..., 1.4552e-11, 7.5033e-12,\n",
       "              2.1600e-11],\n",
       "             [1.0623e-09, 1.6153e-09, 1.4188e-09,  ..., 8.4401e-10, 1.6553e-10,\n",
       "              7.3851e-10],\n",
       "             [7.6398e-10, 1.8626e-09, 1.0477e-09,  ..., 1.3461e-09, 5.6389e-10,\n",
       "              1.1350e-09],\n",
       "             ...,\n",
       "             [3.2969e-11, 3.0923e-11, 3.0241e-11,  ..., 5.8208e-11, 3.0241e-11,\n",
       "              2.9786e-11],\n",
       "             [1.5280e-10, 2.2737e-10, 1.4825e-10,  ..., 2.4738e-10, 9.4133e-11,\n",
       "              1.8099e-10],\n",
       "             [2.9286e-10, 9.6770e-10, 9.1313e-10,  ..., 1.0914e-09, 3.6380e-10,\n",
       "              9.5315e-10]], dtype=torch.bfloat16)},\n",
       "    15: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-3.1552e-20,  1.2070e-06, -2.6450e-07,  ..., -3.5390e-07,\n",
       "             -2.6524e-06, -3.0845e-06], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([1.8917e-09, 2.1653e-08, 2.2934e-08,  ..., 1.1005e-10, 7.9672e-10,\n",
       "             1.7681e-09], dtype=torch.bfloat16)},\n",
       "    16: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 8.0559e-08,  0.0000e+00,  0.0000e+00,  ...,  6.2864e-09,\n",
       "              -9.1270e-08,  2.0023e-08],\n",
       "             [-2.8126e-07,  0.0000e+00,  0.0000e+00,  ..., -4.1036e-09,\n",
       "               3.6694e-07,  1.0987e-09],\n",
       "             [ 3.9116e-07,  0.0000e+00,  0.0000e+00,  ..., -8.5856e-10,\n",
       "               1.5832e-07,  2.7823e-08],\n",
       "             ...,\n",
       "             [ 1.0729e-05,  0.0000e+00,  0.0000e+00,  ..., -4.0606e-07,\n",
       "              -1.4231e-06, -1.3262e-06],\n",
       "             [-4.7386e-06,  0.0000e+00,  0.0000e+00,  ...,  6.2585e-07,\n",
       "               2.5630e-05,  2.3544e-06],\n",
       "             [ 7.1228e-06,  0.0000e+00,  0.0000e+00,  ...,  1.7323e-07,\n",
       "               4.4107e-05,  9.4250e-07]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.8332e-12, 0.0000e+00, 0.0000e+00,  ..., 2.0646e-10, 3.9790e-12,\n",
       "              2.5402e-13],\n",
       "             [4.7748e-12, 0.0000e+00, 0.0000e+00,  ..., 4.0927e-10, 4.1382e-11,\n",
       "              2.5722e-12],\n",
       "             [5.8208e-11, 0.0000e+00, 0.0000e+00,  ..., 2.7285e-10, 6.6848e-11,\n",
       "              4.9795e-11],\n",
       "             ...,\n",
       "             [2.0722e-08, 0.0000e+00, 0.0000e+00,  ..., 1.4544e-05, 8.7544e-08,\n",
       "              4.9919e-07],\n",
       "             [1.0384e-07, 0.0000e+00, 0.0000e+00,  ..., 9.1791e-06, 1.1874e-07,\n",
       "              4.1164e-07],\n",
       "             [9.8371e-09, 0.0000e+00, 0.0000e+00,  ..., 1.1697e-06, 3.0035e-08,\n",
       "              1.3213e-08]], dtype=torch.bfloat16)},\n",
       "    17: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-1.3262e-06,  1.0338e-07, -5.1036e-07,  ..., -7.1526e-07,\n",
       "              -2.9244e-07, -1.2517e-06],\n",
       "             [-2.9057e-07, -1.6484e-07,  7.5251e-07,  ..., -2.6636e-07,\n",
       "              -6.3330e-08, -1.0505e-06],\n",
       "             [ 2.4140e-06, -2.1607e-07,  2.2501e-06,  ...,  1.5646e-06,\n",
       "               1.9558e-07,  6.0201e-06],\n",
       "             ...,\n",
       "             [-2.3603e-05, -8.7619e-06, -2.2411e-05,  ..., -3.9577e-05,\n",
       "               9.0599e-06, -9.6321e-05],\n",
       "             [ 8.7738e-05,  1.5050e-06,  7.2002e-05,  ...,  7.3433e-05,\n",
       "              -5.5432e-06,  1.7548e-04],\n",
       "             [ 2.8014e-06,  4.7982e-06,  9.0599e-06,  ...,  2.6077e-06,\n",
       "              -1.3053e-05,  2.1815e-05]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[5.1841e-11, 3.8654e-12, 2.9331e-11,  ..., 1.8076e-11, 7.3328e-12,\n",
       "              2.1009e-10],\n",
       "             [5.0022e-11, 3.9790e-11, 9.0495e-11,  ..., 1.0687e-10, 6.9122e-11,\n",
       "              3.9108e-10],\n",
       "             [7.6398e-10, 3.8017e-10, 1.1132e-09,  ..., 1.2878e-09, 5.2387e-10,\n",
       "              5.4715e-09],\n",
       "             ...,\n",
       "             [6.8545e-07, 1.9837e-07, 5.6252e-07,  ..., 1.0282e-06, 2.2817e-07,\n",
       "              3.7402e-06],\n",
       "             [8.9407e-07, 2.5146e-07, 7.6368e-07,  ..., 1.2740e-06, 3.1851e-07,\n",
       "              4.7386e-06],\n",
       "             [2.3865e-08, 2.9395e-09, 8.0327e-09,  ..., 1.2747e-08, 3.3906e-09,\n",
       "              9.5926e-08]], dtype=torch.bfloat16)},\n",
       "    18: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 9.9540e-06,  6.0797e-06, -3.0041e-05,  ...,  1.3428e-03,\n",
       "             -2.6703e-03, -1.9932e-04], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([8.4401e-09, 3.8184e-08, 4.3772e-07,  ..., 1.7548e-03, 1.9531e-03,\n",
       "             3.0518e-05], dtype=torch.bfloat16)},\n",
       "    19: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 9.9540e-06,  6.0797e-06, -3.0041e-05,  ...,  6.1417e-04,\n",
       "             -1.2283e-03, -1.0204e-04], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([8.4401e-09, 3.8184e-08, 4.3772e-07,  ..., 4.0817e-04, 4.7302e-04,\n",
       "             7.9870e-06], dtype=torch.bfloat16)},\n",
       "    20: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-2.0955e-07, -3.4273e-07, -7.7486e-07,  ..., -4.5262e-07,\n",
       "               6.0350e-07, -3.9302e-07],\n",
       "             [-7.8604e-07, -1.9968e-06, -1.3262e-06,  ..., -6.6683e-07,\n",
       "               3.9861e-07, -8.1658e-06],\n",
       "             [ 4.4703e-08, -6.1002e-08, -2.0862e-07,  ...,  3.5390e-08,\n",
       "               5.7044e-08, -3.1898e-08],\n",
       "             ...,\n",
       "             [ 4.2319e-06,  9.5367e-07,  5.6326e-06,  ...,  8.7023e-06,\n",
       "              -5.5507e-07,  1.5497e-05],\n",
       "             [-1.1772e-06, -3.8445e-06, -5.6624e-06,  ..., -1.8403e-06,\n",
       "               3.0398e-06, -9.5963e-06],\n",
       "             [ 7.0781e-07,  1.8254e-06,  2.5928e-06,  ...,  8.8662e-07,\n",
       "              -5.5134e-07,  4.5896e-06]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.2824e-10, 1.7394e-11, 6.0936e-11,  ..., 2.0191e-10, 1.5007e-11,\n",
       "              8.6220e-10],\n",
       "             [4.6930e-10, 1.2460e-10, 2.5466e-10,  ..., 4.8021e-10, 1.4461e-10,\n",
       "              2.4884e-09],\n",
       "             [1.7280e-11, 4.4622e-12, 8.2991e-12,  ..., 1.4552e-11, 4.4338e-12,\n",
       "              7.1850e-11],\n",
       "             ...,\n",
       "             [2.6193e-08, 4.2783e-09, 2.4884e-09,  ..., 6.1700e-09, 2.1828e-09,\n",
       "              6.7521e-08],\n",
       "             [1.5949e-08, 4.7730e-09, 1.9936e-09,  ..., 4.9768e-09, 1.9791e-09,\n",
       "              4.1444e-08],\n",
       "             [1.7695e-08, 4.5111e-09, 1.6662e-09,  ..., 5.2096e-09, 1.8772e-09,\n",
       "              4.4471e-08]], dtype=torch.bfloat16)},\n",
       "    21: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 1.3709e-06, -1.8477e-06,  1.0133e-06,  ...,  5.5507e-07,\n",
       "              -3.0398e-06,  2.3693e-06],\n",
       "             [ 7.9274e-06,  1.4365e-05,  8.8662e-07,  ...,  3.9339e-06,\n",
       "               1.8030e-06, -2.9206e-06],\n",
       "             [-1.2864e-08,  1.5572e-06, -5.0664e-07,  ..., -2.1793e-07,\n",
       "              -3.4273e-07,  4.4517e-07],\n",
       "             ...,\n",
       "             [ 6.7353e-06,  3.0100e-06,  1.4342e-07,  ..., -1.2219e-05,\n",
       "               1.5199e-06,  5.2154e-06],\n",
       "             [ 1.2815e-06,  3.7625e-07, -4.8801e-07,  ..., -2.2650e-06,\n",
       "              -1.8328e-06,  1.9465e-07],\n",
       "             [-1.4305e-06,  3.2187e-06,  3.9935e-06,  ...,  3.6359e-06,\n",
       "              -3.9339e-06, -9.7603e-07]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.8772e-09, 9.3860e-10, 1.4479e-09,  ..., 2.3829e-10, 4.6930e-10,\n",
       "              6.0754e-10],\n",
       "             [7.6252e-09, 1.4901e-08, 8.5129e-10,  ..., 7.9162e-09, 4.2201e-09,\n",
       "              1.2806e-09],\n",
       "             [2.9286e-10, 6.1846e-11, 1.7735e-10,  ..., 6.0027e-11, 4.1382e-11,\n",
       "              6.5029e-11],\n",
       "             ...,\n",
       "             [6.7521e-09, 3.8417e-09, 1.7346e-08,  ..., 7.0140e-09, 3.0559e-09,\n",
       "              5.7917e-09],\n",
       "             [6.0245e-09, 1.6080e-09, 1.2864e-08,  ..., 4.9768e-09, 3.3324e-09,\n",
       "              5.3260e-09],\n",
       "             [7.5088e-09, 1.9936e-09, 1.5018e-08,  ..., 5.4715e-09, 3.7835e-09,\n",
       "              5.9954e-09]], dtype=torch.bfloat16)},\n",
       "    22: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 5.4240e-06,  4.4107e-05,  9.4250e-07,  ..., -9.9182e-05,\n",
       "              9.1553e-05, -5.1737e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([6.0070e-08, 1.1083e-07, 9.1968e-09,  ..., 1.3292e-05, 7.6890e-06,\n",
       "             8.1062e-06], dtype=torch.bfloat16)},\n",
       "    23: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 5.4240e-06,  4.4107e-05,  9.4250e-07,  ..., -2.0385e-05,\n",
       "             -7.5698e-06, -1.9789e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([6.0070e-08, 1.1083e-07, 9.1968e-09,  ..., 3.0249e-06, 1.8403e-06,\n",
       "             2.0564e-06], dtype=torch.bfloat16)},\n",
       "    24: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-9.9838e-07, -7.9870e-06, -2.3842e-06,  ...,  1.1101e-06,\n",
       "               3.9041e-06, -3.2485e-06],\n",
       "             [-1.0431e-05,  5.5507e-07,  3.9488e-07,  ...,  1.6019e-06,\n",
       "              -6.1095e-06,  2.2352e-06],\n",
       "             [-1.6578e-07,  3.6694e-07,  5.2527e-07,  ..., -2.9430e-07,\n",
       "              -7.2271e-07,  4.0792e-07],\n",
       "             ...,\n",
       "             [-9.2387e-06, -1.4529e-06, -2.2203e-06,  ..., -8.4937e-07,\n",
       "               3.3528e-06,  4.2468e-07],\n",
       "             [-1.3649e-05, -4.1723e-06, -8.9407e-08,  ..., -5.0366e-06,\n",
       "              -7.5996e-06,  2.1756e-06],\n",
       "             [ 3.6210e-06, -6.5565e-06, -2.1458e-06,  ...,  3.8147e-06,\n",
       "              -3.3677e-06, -8.0839e-07]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[4.5402e-09, 2.2555e-09, 1.1914e-10,  ..., 2.9831e-10, 1.0041e-09,\n",
       "              1.9372e-10],\n",
       "             [9.3132e-10, 3.2887e-09, 1.1096e-10,  ..., 3.0195e-10, 3.9836e-10,\n",
       "              1.2551e-10],\n",
       "             [2.4556e-10, 2.3829e-10, 3.2287e-11,  ..., 1.1732e-10, 1.0368e-10,\n",
       "              4.6839e-11],\n",
       "             ...,\n",
       "             [7.4506e-09, 7.9162e-09, 4.4529e-09,  ..., 1.8626e-09, 2.4593e-09,\n",
       "              1.5280e-09],\n",
       "             [4.9768e-09, 3.8708e-09, 4.3365e-09,  ..., 1.2878e-09, 1.9209e-09,\n",
       "              1.8772e-09],\n",
       "             [1.1205e-09, 1.2442e-09, 1.5552e-10,  ..., 4.5293e-10, 4.9113e-10,\n",
       "              7.4124e-11]], dtype=torch.bfloat16)},\n",
       "    25: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-8.2701e-07,  1.2398e-05,  1.5616e-05,  ...,  8.3447e-06,\n",
       "              -2.2173e-05, -3.1948e-05],\n",
       "             [-9.9540e-06,  9.4771e-06,  1.5140e-05,  ..., -2.3365e-05,\n",
       "               8.7619e-06, -3.9339e-05],\n",
       "             [ 1.9819e-06,  2.2352e-06,  1.0431e-06,  ...,  2.9504e-06,\n",
       "              -7.8604e-07,  5.5432e-06],\n",
       "             ...,\n",
       "             [ 2.6226e-05,  3.7670e-05, -9.1791e-06,  ..., -1.1086e-05,\n",
       "               1.7762e-05, -4.2200e-05],\n",
       "             [-7.3388e-07, -9.1642e-07, -7.5698e-06,  ...,  2.6345e-05,\n",
       "              -2.3723e-05,  2.8491e-05],\n",
       "             [-8.8215e-06, -1.9372e-06, -4.7684e-06,  ...,  1.5348e-06,\n",
       "              -6.3702e-07,  2.4557e-05]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.7462e-08, 1.4901e-08, 1.5600e-08,  ..., 1.5367e-08, 1.5250e-08,\n",
       "              2.0256e-08],\n",
       "             [1.2573e-08, 6.8103e-09, 9.0804e-09,  ..., 7.5088e-09, 7.8580e-09,\n",
       "              1.5018e-08],\n",
       "             [1.9791e-09, 1.4261e-09, 1.5789e-09,  ..., 1.7099e-09, 1.8772e-09,\n",
       "              2.1100e-09],\n",
       "             ...,\n",
       "             [3.0734e-08, 2.0955e-08, 3.0268e-08,  ..., 3.0035e-08, 3.1199e-08,\n",
       "              4.5402e-08],\n",
       "             [3.0501e-08, 2.9337e-08, 3.0035e-08,  ..., 2.9802e-08, 3.0268e-08,\n",
       "              8.6613e-08],\n",
       "             [5.9081e-09, 5.8208e-09, 7.4506e-09,  ..., 7.4506e-09, 7.5088e-09,\n",
       "              8.7894e-09]], dtype=torch.bfloat16)},\n",
       "    26: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-2.3127e-05, -3.9816e-05, -2.3097e-06,  ..., -7.7724e-05,\n",
       "              1.1861e-05,  2.3007e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([3.0501e-08, 1.5949e-08, 4.3656e-09,  ..., 8.1956e-07, 4.6939e-07,\n",
       "             4.1211e-08], dtype=torch.bfloat16)},\n",
       "    27: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-2.3127e-05, -3.9816e-05, -2.3097e-06,  ..., -7.3433e-05,\n",
       "              1.2279e-05,  2.1577e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([3.0501e-08, 1.5949e-08, 4.3656e-09,  ..., 2.6636e-07, 1.6484e-07,\n",
       "             1.5250e-08], dtype=torch.bfloat16)},\n",
       "    28: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 7.6294e-05, -6.0797e-06,  4.3631e-05,  ...,  2.3007e-05,\n",
       "               5.0545e-05,  3.6716e-05],\n",
       "             [-6.3446e-09, -9.1735e-08,  5.7276e-08,  ...,  5.0059e-08,\n",
       "               5.7044e-08,  3.6508e-07],\n",
       "             [ 1.6182e-08, -1.1921e-07, -4.0745e-09,  ...,  6.8452e-08,\n",
       "               3.2596e-08,  4.3213e-07],\n",
       "             ...,\n",
       "             [ 1.7928e-08, -9.7603e-07, -4.4703e-06,  ..., -1.3970e-07,\n",
       "              -3.1441e-06,  7.6294e-06],\n",
       "             [ 1.2922e-08, -1.0990e-07,  2.0606e-08,  ...,  5.7509e-08,\n",
       "               6.2399e-08,  3.8929e-07],\n",
       "             [ 1.6332e-05,  2.8253e-05,  5.9605e-07,  ...,  5.5134e-07,\n",
       "              -3.2663e-05,  1.4186e-05]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.0803e-06, 2.2817e-07, 1.4994e-07,  ..., 1.2107e-07, 2.4401e-07,\n",
       "              3.5204e-07],\n",
       "             [5.3478e-10, 2.4156e-09, 3.1869e-09,  ..., 1.3388e-08, 6.9849e-09,\n",
       "              3.4692e-08],\n",
       "             [5.9299e-10, 2.7503e-09, 3.6962e-09,  ..., 1.5716e-08, 8.0909e-09,\n",
       "              4.2608e-08],\n",
       "             ...,\n",
       "             [1.2815e-05, 3.3379e-05, 4.2200e-05,  ..., 1.2398e-04, 8.9169e-05,\n",
       "              2.0504e-04],\n",
       "             [4.4383e-10, 1.9354e-09, 2.5466e-09,  ..., 1.0652e-08, 5.5297e-09,\n",
       "              2.7474e-08],\n",
       "             [7.3016e-07, 9.4064e-08, 2.6822e-07,  ..., 1.7285e-06, 4.0233e-07,\n",
       "              5.6922e-06]], dtype=torch.bfloat16)},\n",
       "    29: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 3.3140e-05,  4.9174e-07,  5.6997e-07,  5.8860e-07, -1.7548e-04,\n",
       "              2.2888e-05, -6.9618e-05, -4.4584e-05, -3.7909e-05,  5.7459e-05,\n",
       "             -2.2650e-06,  2.8372e-05, -8.2254e-06,  2.6226e-06,  3.9637e-06,\n",
       "              5.2527e-07, -4.1485e-05,  6.2883e-06, -1.9646e-04, -1.5199e-05,\n",
       "             -1.0777e-04, -2.4676e-05,  5.2643e-04,  6.1512e-05, -1.5736e-05,\n",
       "             -7.0095e-05,  3.3975e-06,  6.6161e-06,  1.9819e-06,  1.0505e-06,\n",
       "             -9.4771e-06,  6.5565e-06,  2.2501e-06,  1.6540e-06,  1.7807e-06,\n",
       "              7.0781e-07,  1.7434e-06,  3.3677e-06,  2.7865e-06,  1.4722e-05,\n",
       "             -1.8701e-06, -8.4564e-07,  1.0654e-06, -4.9829e-05,  3.0398e-06,\n",
       "             -6.4373e-05,  2.1309e-06,  2.1905e-06,  4.4060e-04, -2.7275e-04,\n",
       "             -5.5552e-05, -5.5432e-06,  5.6624e-07,  1.0490e-05,  5.1036e-07,\n",
       "              1.9312e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([1.0282e-06, 1.3188e-06, 1.3933e-06, 1.2368e-06, 6.2466e-05, 3.3379e-05,\n",
       "             2.4289e-06, 1.4484e-05, 1.0192e-05, 5.4240e-06, 1.9372e-06, 1.1176e-06,\n",
       "             1.3113e-06, 1.2740e-06, 1.3560e-06, 1.1623e-06, 5.0068e-06, 1.0878e-06,\n",
       "             9.4891e-05, 1.5572e-06, 2.3246e-06, 1.1325e-06, 1.6212e-05, 1.1563e-05,\n",
       "             1.2740e-06, 1.6689e-06, 1.1921e-06, 1.1623e-06, 1.2144e-06, 1.3560e-06,\n",
       "             1.1325e-06, 1.2368e-06, 1.3337e-06, 1.3337e-06, 1.1921e-06, 1.3784e-06,\n",
       "             1.3858e-06, 1.4156e-06, 1.2144e-06, 1.2144e-06, 1.2890e-06, 1.4082e-06,\n",
       "             1.3039e-06, 1.1995e-06, 1.4082e-06, 9.8348e-07, 1.2666e-06, 1.2964e-06,\n",
       "             1.5831e-04, 1.6093e-05, 1.0058e-06, 1.0654e-06, 1.2442e-06, 9.6893e-04,\n",
       "             1.1548e-06, 5.9009e-06], dtype=torch.bfloat16)},\n",
       "    30: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[-3.4869e-06, -8.7619e-06, -2.0146e-05,  ...,  2.3842e-05,\n",
       "               1.3947e-05, -2.0862e-05],\n",
       "             [ 1.6689e-05, -1.8775e-06, -2.5272e-05,  ...,  1.6689e-05,\n",
       "               3.6955e-06, -8.1062e-06],\n",
       "             [-6.6161e-06,  6.6459e-06,  4.9472e-06,  ..., -6.4671e-06,\n",
       "               4.4703e-06, -5.9605e-06],\n",
       "             ...,\n",
       "             [ 2.8729e-05, -6.9737e-06, -1.5259e-05,  ...,  3.8862e-05,\n",
       "              -3.2037e-06, -5.7817e-06],\n",
       "             [-1.9185e-07,  2.4028e-07, -6.5938e-07,  ...,  1.3262e-06,\n",
       "              -5.8115e-07, -1.0207e-06],\n",
       "             [-3.1471e-05,  5.1558e-06,  3.9339e-05,  ..., -3.4571e-05,\n",
       "              -1.1683e-05,  1.2040e-05]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[4.4703e-08, 6.1002e-08, 6.7987e-08,  ..., 6.5658e-08, 6.3330e-08,\n",
       "              5.9605e-08],\n",
       "             [3.0501e-08, 3.6787e-08, 6.1002e-08,  ..., 2.9802e-08, 4.5868e-08,\n",
       "              3.3062e-08],\n",
       "             [9.8953e-10, 5.3478e-10, 5.8935e-10,  ..., 5.9299e-10, 5.7480e-10,\n",
       "              4.4383e-10],\n",
       "             ...,\n",
       "             [6.8452e-08, 4.9127e-08, 4.7265e-08,  ..., 7.0781e-08, 6.0536e-08,\n",
       "              4.2841e-08],\n",
       "             [1.1569e-09, 9.3860e-10, 1.0623e-09,  ..., 1.1933e-09, 7.4579e-10,\n",
       "              7.3123e-10],\n",
       "             [4.1444e-08, 6.2864e-08, 3.7719e-08,  ..., 9.1270e-08, 4.0513e-08,\n",
       "              6.0070e-08]], dtype=torch.bfloat16)},\n",
       "    31: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([-2.2292e-05,  1.7762e-05,  6.4075e-06, -1.0908e-05,  3.4094e-05,\n",
       "             -3.6734e-40, -1.5974e-05, -1.7405e-05,  8.9407e-06,  4.5061e-05,\n",
       "              8.2850e-06,  9.0003e-06,  5.6267e-05, -5.5075e-05, -1.8954e-05,\n",
       "              2.1577e-05, -3.8385e-05,  8.3447e-07, -3.6734e-40, -3.8385e-05,\n",
       "              8.1211e-07, -4.6253e-05,  2.7895e-05, -7.0930e-06, -2.8796e-16,\n",
       "             -4.3869e-05,  5.3644e-06, -8.2850e-06,  2.9504e-06,  9.8228e-05,\n",
       "              9.7156e-06, -6.9141e-06, -3.6734e-40, -4.3154e-05,  5.5075e-05,\n",
       "              7.8082e-06, -1.1265e-05,  6.0558e-05, -2.3097e-06,  1.0252e-04,\n",
       "             -7.1526e-05,  1.8716e-05,  6.7353e-06,  3.5048e-05,  4.3201e-12,\n",
       "              4.5538e-05,  3.6734e-40, -1.8358e-05,  3.2663e-05,  1.4484e-05,\n",
       "              3.6734e-40,  9.4414e-05, -4.8399e-05, -1.1504e-05, -1.3292e-05,\n",
       "             -3.8862e-05, -3.6734e-40, -3.3855e-05,  1.0729e-05,  8.7675e-10,\n",
       "              2.0742e-05,  3.6734e-40,  3.6734e-40,  2.1011e-06, -1.3411e-05,\n",
       "             -1.8954e-05, -7.5698e-06,  3.4332e-05,  6.6161e-06, -5.3942e-06,\n",
       "             -1.8120e-05, -4.9770e-06,  3.6734e-40, -4.8280e-06, -1.2875e-04,\n",
       "             -4.8399e-05, -2.8014e-05, -2.9564e-05,  6.1840e-07, -9.4175e-06,\n",
       "              2.8610e-06, -9.8348e-06,  6.1467e-07,  3.6734e-40,  1.6332e-05,\n",
       "             -1.0300e-04, -5.0068e-05, -5.9903e-06,  3.6734e-40,  4.7445e-05,\n",
       "             -1.4186e-05, -8.5235e-06, -2.6941e-05, -7.3612e-06, -6.7949e-06,\n",
       "              9.2983e-05,  7.5318e-13, -3.3379e-05,  1.0282e-06, -2.8014e-05,\n",
       "              3.6734e-40, -1.5259e-04, -1.9789e-05,  4.1246e-05, -3.6734e-40,\n",
       "             -5.9366e-05, -1.9789e-05,  1.5736e-04,  7.3016e-06, -2.1815e-05,\n",
       "              4.3809e-06,  8.7023e-06, -1.0431e-05, -2.1338e-05, -6.1989e-05,\n",
       "              4.5538e-05, -7.6294e-06, -2.0713e-06, -4.7684e-05,  4.9591e-05,\n",
       "              1.8358e-05,  4.9174e-06, -2.8968e-05,  6.3777e-06,  1.3828e-05,\n",
       "             -2.0027e-05, -1.2398e-05, -1.0431e-05,  9.8348e-06, -3.6734e-40,\n",
       "             -8.2423e-13, -1.2070e-06,  1.7732e-06,  5.7220e-05, -3.1471e-05,\n",
       "             -2.2650e-05,  3.6734e-40, -8.4043e-06,  8.3923e-05,  7.5340e-05,\n",
       "              1.1826e-04,  2.3484e-05,  2.3007e-05,  2.7418e-06,  1.1146e-05,\n",
       "              2.3749e-08, -4.0531e-06, -1.7062e-06,  1.7732e-06,  2.4915e-05,\n",
       "              5.6624e-06, -2.4796e-05,  3.6734e-40,  3.9816e-05,  1.4380e-06,\n",
       "             -9.4771e-06, -1.1015e-04, -2.7269e-06, -1.4424e-05,  3.6734e-40,\n",
       "              5.3644e-06,  1.9908e-05, -9.7275e-05,  7.1228e-06,  1.9968e-06,\n",
       "              3.6734e-40, -3.4571e-06,  1.0014e-05,  3.0756e-05, -5.1260e-05,\n",
       "              2.0623e-05, -2.3484e-05, -3.8385e-05, -3.6734e-40,  5.4389e-07,\n",
       "              3.6734e-40,  4.6253e-05, -1.1563e-05,  3.6734e-40, -1.0908e-05,\n",
       "             -2.4438e-05,  8.5354e-05, -1.8954e-05,  4.0054e-05, -2.2204e-14,\n",
       "             -1.1563e-05, -1.2107e-07,  3.2187e-05,  2.0266e-06, -3.4124e-06,\n",
       "              3.6734e-40, -8.4639e-06,  3.6734e-40, -2.0623e-05,  9.6560e-06,\n",
       "              3.6734e-40,  4.4405e-06, -2.2203e-06, -5.7220e-05, -8.7619e-06,\n",
       "             -7.5817e-05, -6.3777e-06,  1.7762e-05, -6.7651e-06,  1.1623e-05,\n",
       "              4.5061e-05,  3.3140e-05,  4.7684e-05, -5.2214e-05, -7.7300e-08,\n",
       "              3.6734e-40,  1.7285e-05, -2.9445e-05,  2.5034e-05, -9.7752e-06,\n",
       "             -2.6584e-05, -2.0742e-05, -5.6744e-05, -1.3933e-06, -3.8385e-05,\n",
       "              6.4969e-06, -6.3896e-05,  1.9431e-05, -1.8626e-06, -2.8908e-06,\n",
       "              7.9155e-05, -4.7684e-05,  1.0073e-05,  3.5763e-05, -1.8716e-05,\n",
       "             -1.4305e-05, -4.7088e-06, -1.0073e-05, -3.6734e-40, -4.6074e-15,\n",
       "             -3.6734e-40, -1.7881e-05,  3.6734e-40,  2.7418e-06, -3.6880e-07,\n",
       "             -2.5749e-05, -2.4199e-05, -1.7285e-05, -3.7998e-06,  3.8147e-06,\n",
       "             -1.2517e-05, -2.5928e-06, -3.0994e-05, -3.7432e-05, -1.0550e-05,\n",
       "             -1.0292e-30, -1.9073e-04, -3.8557e-07, -1.7285e-05, -1.0014e-05,\n",
       "              7.1049e-05, -2.4080e-05, -2.2054e-05, -2.4438e-05, -2.5034e-05,\n",
       "              8.0839e-07, -5.5134e-06, -7.0035e-07, -1.6689e-05,  1.8597e-05,\n",
       "              2.8729e-05, -9.5367e-06, -8.3447e-07,  3.6734e-40, -8.5354e-05,\n",
       "             -6.1989e-05,  5.6982e-05, -2.5392e-05,  8.1584e-07, -1.7732e-06,\n",
       "             -4.2439e-05, -3.6734e-40,  1.2398e-05,  1.5259e-05,  1.1563e-05,\n",
       "              9.4133e-11, -9.0122e-05, -1.2755e-05, -1.8954e-05, -7.1828e-19,\n",
       "             -1.4454e-06,  3.6734e-40, -3.3617e-05,  1.2636e-05, -3.0041e-05,\n",
       "              1.8120e-05, -1.9819e-06, -5.6326e-06,  7.0095e-05,  6.3479e-06,\n",
       "             -7.8082e-06,  3.1888e-06, -2.5511e-05, -2.5153e-05,  2.2173e-05,\n",
       "              2.1815e-05,  4.2200e-05,  2.6703e-05,  1.5460e-07,  3.2902e-05,\n",
       "              6.2585e-06,  3.3528e-06,  3.6734e-40,  1.0952e-06, -3.8624e-05,\n",
       "              3.6734e-40,  1.1735e-07,  1.4365e-05,  4.9770e-06, -3.1441e-06,\n",
       "              1.0729e-04,  7.5817e-05, -1.7405e-05, -6.4075e-06,  3.9577e-05,\n",
       "              8.9407e-06,  2.2888e-05, -3.6734e-40,  3.6734e-40,  3.1590e-06,\n",
       "              6.3096e-12,  2.5272e-05,  4.1485e-05, -4.2200e-05, -4.4584e-05,\n",
       "             -3.6734e-40, -2.3365e-05,  1.1826e-04, -2.5928e-06, -2.4676e-05,\n",
       "              2.4557e-05,  1.0788e-05,  6.2957e-07, -8.1584e-07,  1.0872e-04,\n",
       "             -3.6734e-40,  8.2016e-05, -2.0266e-05, -8.6427e-06, -1.3292e-05,\n",
       "              5.2154e-06,  1.6809e-05, -7.0930e-06,  7.8231e-07,  7.7248e-05,\n",
       "             -3.8385e-05, -5.4359e-05,  3.6734e-40,  3.6734e-40,  3.3617e-05,\n",
       "              3.6734e-40,  2.6941e-05,  4.8876e-05,  5.6578e-08,  1.1563e-05,\n",
       "              3.6734e-40, -2.4557e-05, -1.1086e-05,  3.5763e-05,  3.0160e-05,\n",
       "              3.8883e-08,  2.6822e-06,  8.1647e-29, -1.3828e-05, -3.8743e-06,\n",
       "              2.8610e-05, -3.9816e-05, -7.9632e-05, -7.8082e-06, -7.9274e-06,\n",
       "             -8.4639e-06,  1.2279e-05, -7.2002e-05, -1.5140e-05,  6.3419e-05,\n",
       "              3.6734e-40, -1.9073e-05,  3.6734e-40,  5.9605e-05, -8.1539e-05,\n",
       "              5.5075e-05,  3.3975e-06,  9.5367e-06, -1.8954e-05, -4.6730e-05,\n",
       "              1.3649e-05, -1.6653e-14, -2.3246e-06, -1.1563e-05, -1.1981e-05,\n",
       "              2.0191e-10, -1.4496e-04,  8.2254e-06,  3.6734e-40, -6.3777e-06,\n",
       "              5.1558e-06,  7.8617e-35, -3.4571e-06,  8.8215e-06,  1.7807e-06,\n",
       "              3.6734e-40,  9.3579e-06,  5.4121e-05,  6.6161e-06,  7.1526e-05,\n",
       "             -1.8597e-05,  4.4584e-05, -1.5080e-05, -4.0829e-06, -9.0599e-06,\n",
       "              2.3484e-05, -1.8477e-05,  3.5465e-06,  2.1577e-05, -5.0306e-05,\n",
       "             -1.5378e-05,  3.7193e-05,  1.2040e-05, -6.5863e-06, -3.6734e-40,\n",
       "              1.1325e-05,  7.4208e-06, -5.8413e-06,  1.0061e-11, -4.6492e-06,\n",
       "              6.9141e-05, -1.2070e-06, -5.5790e-05,  1.6809e-05,  6.5863e-06,\n",
       "              3.1292e-06,  1.6809e-05, -1.5020e-05, -1.0848e-05, -1.1027e-06,\n",
       "             -3.5524e-05,  1.0323e-10, -1.5125e-06,  1.5068e-04,  1.9670e-05,\n",
       "             -1.0371e-05,  5.0545e-05,  1.2016e-04,  6.1989e-06, -1.3053e-05,\n",
       "             -8.7917e-07,  1.2064e-04, -4.2319e-06, -7.6294e-06, -4.9353e-05,\n",
       "             -2.5262e-08,  7.1526e-05,  6.4850e-05, -3.1143e-06,  3.6955e-05,\n",
       "              3.5614e-06, -2.5034e-05,  3.6734e-40, -1.1176e-06, -5.8115e-06,\n",
       "              3.6734e-40, -1.4377e-08,  1.3351e-05,  1.1146e-05, -2.6584e-05,\n",
       "             -8.7544e-07, -2.8372e-05, -3.1948e-05,  4.5776e-05, -2.0504e-05,\n",
       "             -2.8372e-05, -9.2983e-05, -1.3590e-05,  1.0109e-04,  3.8743e-07,\n",
       "              7.3016e-06,  2.5202e-14,  2.1853e-19,  4.0293e-05,  3.3617e-05,\n",
       "              1.8716e-05, -2.3127e-05, -4.8876e-05,  3.6734e-40,  3.2634e-06,\n",
       "             -2.7716e-06,  1.4067e-05, -2.3603e-05, -1.4484e-05, -2.9087e-05,\n",
       "              2.4199e-05, -5.8276e-19, -3.5286e-05, -1.3947e-05, -1.3649e-05,\n",
       "             -4.9472e-06, -2.3603e-05,  2.1309e-06,  3.6240e-05, -3.8370e-07,\n",
       "             -8.2850e-06, -6.3838e-15,  1.5974e-05,  7.8976e-07, -3.3617e-05,\n",
       "             -9.5367e-07,  2.9922e-05], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([1.5274e-07, 9.6392e-08, 3.9290e-09, 2.0564e-06, 6.0070e-08, 4.4529e-09,\n",
       "             6.0070e-08, 4.9919e-07, 1.2014e-07, 1.6764e-07, 2.5146e-07, 8.8476e-08,\n",
       "             4.9770e-06, 9.6858e-07, 6.0722e-07, 1.5460e-07, 4.8056e-07, 1.0282e-06,\n",
       "             4.6275e-09, 9.7603e-07, 3.8147e-06, 2.3190e-07, 1.6689e-06, 2.0023e-08,\n",
       "             6.6648e-09, 2.5891e-07, 1.5553e-07, 6.5658e-08, 2.3842e-07, 1.4678e-06,\n",
       "             8.2422e-08, 4.9174e-07, 2.5902e-09, 6.3796e-08, 4.7684e-07, 1.0885e-08,\n",
       "             1.2480e-07, 1.9521e-06, 1.6317e-06, 9.6112e-07, 6.7651e-06, 4.8429e-07,\n",
       "             2.8755e-08, 7.5903e-08, 1.2631e-08, 4.8801e-07, 1.8190e-09, 9.5367e-07,\n",
       "             7.7300e-08, 4.7684e-07, 9.6770e-10, 1.5646e-06, 3.4692e-08, 4.7730e-08,\n",
       "             2.5728e-08, 1.8347e-07, 3.4051e-09, 1.9465e-07, 1.5250e-08, 1.5832e-08,\n",
       "             3.6322e-07, 6.4611e-09, 4.4820e-09, 2.3842e-07, 3.3295e-08, 1.7416e-07,\n",
       "             1.2107e-07, 9.2667e-08, 2.1071e-08, 1.8044e-08, 3.1292e-07, 3.2131e-08,\n",
       "             7.2177e-09, 6.9849e-08, 4.8280e-06, 6.1840e-07, 5.2154e-07, 1.3225e-07,\n",
       "             1.3411e-07, 3.1143e-06, 5.5181e-08, 9.5461e-08, 8.7079e-08, 8.3674e-11,\n",
       "             9.5367e-07, 4.8429e-07, 1.9222e-06, 1.3504e-07, 2.0227e-09, 5.8115e-07,\n",
       "             1.4901e-07, 7.1712e-08, 2.6263e-07, 1.8044e-08, 3.5157e-08, 6.8545e-06,\n",
       "             6.2864e-09, 4.7125e-07, 3.5157e-08, 4.8801e-07, 8.4401e-09, 8.5235e-06,\n",
       "             1.2759e-07, 8.3353e-08, 1.7826e-09, 3.3528e-07, 4.3772e-07, 6.1095e-06,\n",
       "             1.1781e-07, 1.5274e-07, 1.4785e-08, 1.3132e-07, 1.0477e-08, 3.3528e-07,\n",
       "             2.3693e-06, 9.9838e-07, 2.2445e-07, 5.4482e-08, 1.1269e-07, 1.1697e-06,\n",
       "             2.9430e-07, 1.4086e-08, 7.7486e-07, 9.4995e-08, 5.7742e-07, 8.0094e-07,\n",
       "             1.2224e-08, 1.8976e-08, 2.0768e-07, 4.5293e-10, 1.8743e-08, 8.8476e-08,\n",
       "             3.6380e-09, 2.0266e-06, 4.8429e-07, 1.7323e-07, 3.3469e-10, 3.0547e-07,\n",
       "             2.0117e-06, 4.8429e-07, 2.1458e-06, 8.4285e-08, 1.6540e-06, 1.9930e-07,\n",
       "             1.2759e-07, 9.3714e-09, 1.8254e-07, 8.3819e-09, 8.0327e-09, 2.4156e-09,\n",
       "             2.2468e-08, 3.7812e-07, 3.0268e-09, 1.5721e-06, 1.7113e-08, 1.2200e-07,\n",
       "             1.9521e-06, 1.6880e-08, 3.7719e-08, 6.4392e-10, 1.2573e-08, 1.6298e-07,\n",
       "             5.5879e-07, 5.6170e-09, 1.4994e-07, 6.0827e-09, 2.5961e-08, 3.2969e-07,\n",
       "             2.9802e-07, 4.2915e-06, 2.3842e-07, 8.6147e-08, 1.9278e-07, 1.1642e-08,\n",
       "             8.7311e-09, 5.3660e-11, 9.1642e-07, 1.4342e-07, 2.4302e-09, 9.6858e-08,\n",
       "             1.2293e-06, 1.9073e-06, 2.5705e-07, 3.7253e-08, 4.3656e-09, 6.4261e-08,\n",
       "             1.4086e-08, 7.2177e-08, 8.7544e-08, 7.3109e-08, 6.6939e-09, 7.1304e-09,\n",
       "             7.1595e-09, 6.6590e-08, 4.5821e-07, 1.9209e-09, 2.4214e-07, 1.2815e-06,\n",
       "             5.7975e-08, 9.4529e-08, 2.3562e-07, 5.5879e-08, 9.6112e-07, 5.9605e-08,\n",
       "             1.1846e-06, 2.5146e-07, 3.8557e-07, 3.9861e-07, 5.8115e-07, 2.1537e-08,\n",
       "             1.5571e-09, 9.4529e-08, 6.9849e-08, 3.9339e-06, 1.9465e-07, 4.7684e-07,\n",
       "             2.0675e-07, 2.2650e-06, 1.5553e-07, 8.1658e-06, 6.6757e-06, 3.8147e-06,\n",
       "             7.5623e-07, 3.3906e-09, 1.3225e-07, 2.5183e-06, 4.1723e-07, 7.2177e-08,\n",
       "             3.3081e-06, 3.2363e-08, 3.5157e-08, 3.8929e-07, 1.6415e-08, 4.0563e-10,\n",
       "             9.6625e-09, 4.0454e-09, 1.6671e-07, 9.6043e-09, 5.0664e-07, 2.0489e-08,\n",
       "             1.5739e-07, 1.3132e-07, 2.3842e-07, 5.4389e-07, 3.3528e-08, 1.6415e-08,\n",
       "             1.7043e-07, 8.4285e-08, 1.5050e-06, 7.2177e-08, 4.3656e-09, 7.6890e-06,\n",
       "             1.7812e-08, 8.0559e-08, 7.5903e-08, 3.2037e-06, 1.4007e-06, 4.7963e-08,\n",
       "             1.6764e-07, 1.0431e-06, 8.1491e-09, 7.9162e-09, 8.2073e-09, 5.3644e-06,\n",
       "             1.8347e-07, 3.8147e-06, 2.9244e-07, 4.9127e-08, 4.6857e-09, 9.9093e-07,\n",
       "             2.5146e-07, 9.3132e-08, 4.7684e-07, 8.3819e-09, 2.5175e-09, 4.0047e-08,\n",
       "             6.0245e-09, 1.4715e-07, 1.8440e-07, 6.4820e-07, 3.0559e-09, 1.0952e-06,\n",
       "             6.4261e-08, 1.2014e-07, 4.7439e-09, 1.1688e-07, 5.7844e-10, 1.2387e-07,\n",
       "             4.2375e-08, 1.6019e-07, 5.5507e-07, 8.8941e-08, 1.9185e-07, 2.8908e-06,\n",
       "             2.2352e-08, 4.9185e-09, 1.2387e-07, 1.0198e-07, 1.2740e-06, 2.8312e-07,\n",
       "             1.5832e-07, 1.2014e-07, 9.5367e-07, 1.8161e-08, 1.6112e-07, 5.6112e-08,\n",
       "             6.5193e-09, 3.0195e-10, 2.2072e-07, 1.1772e-06, 1.2824e-10, 1.6516e-09,\n",
       "             3.4459e-07, 1.3504e-07, 3.2363e-08, 1.3597e-07, 5.2527e-07, 3.8929e-07,\n",
       "             9.7603e-07, 4.4145e-07, 2.1979e-07, 6.8918e-08, 2.8231e-09, 5.2387e-10,\n",
       "             9.5461e-08, 9.8953e-09, 1.0757e-07, 1.1548e-07, 2.7418e-06, 9.5461e-08,\n",
       "             2.8958e-09, 9.2201e-08, 3.9339e-06, 2.2235e-08, 6.1933e-08, 2.0415e-06,\n",
       "             1.3039e-07, 2.3632e-08, 1.2293e-07, 1.9073e-06, 5.5006e-09, 9.9093e-07,\n",
       "             1.2387e-07, 1.1874e-07, 1.4603e-06, 2.8405e-08, 6.6310e-07, 1.8068e-07,\n",
       "             8.9407e-08, 1.1861e-05, 4.0829e-06, 1.9670e-06, 4.5293e-10, 1.5643e-09,\n",
       "             3.7439e-07, 2.7067e-09, 3.0035e-08, 2.5705e-07, 4.8662e-08, 5.0664e-07,\n",
       "             7.0431e-09, 2.9057e-07, 3.2829e-08, 4.8801e-07, 1.9372e-07, 3.0035e-08,\n",
       "             1.7462e-09, 2.7212e-09, 7.3574e-08, 2.6822e-06, 2.6636e-07, 4.6194e-06,\n",
       "             9.9093e-07, 1.0431e-07, 1.4808e-07, 3.7951e-08, 3.7020e-08, 1.4529e-07,\n",
       "             1.2852e-07, 9.7603e-07, 1.1874e-08, 6.7521e-08, 2.1188e-08, 1.2852e-07,\n",
       "             7.6294e-06, 1.2014e-07, 1.5926e-07, 1.2107e-07, 2.3842e-07, 2.4773e-07,\n",
       "             1.5716e-08, 1.5483e-08, 6.1467e-08, 1.7956e-06, 1.2014e-07, 8.3819e-09,\n",
       "             7.6294e-06, 2.2410e-09, 4.3656e-10, 1.5646e-07, 6.5775e-09, 3.2596e-09,\n",
       "             5.6345e-08, 3.4273e-07, 5.4482e-08, 8.9130e-10, 1.3225e-07, 4.0047e-07,\n",
       "             9.5367e-07, 9.5367e-07, 2.7474e-08, 6.8452e-08, 4.6566e-08, 6.2399e-08,\n",
       "             8.8941e-08, 9.4064e-08, 3.3528e-08, 1.4156e-07, 4.7684e-07, 1.7881e-06,\n",
       "             1.0419e-08, 2.1793e-07, 5.3318e-08, 8.8476e-08, 3.0923e-10, 3.0734e-08,\n",
       "             3.1898e-08, 1.5134e-08, 3.0035e-08, 2.7381e-07, 9.6858e-07, 2.0722e-08,\n",
       "             4.3958e-07, 4.8801e-07, 1.3411e-07, 6.3796e-08, 1.2387e-07, 6.0722e-07,\n",
       "             2.9802e-08, 7.5437e-08, 1.3784e-07, 1.1583e-08, 6.8918e-08, 1.9819e-06,\n",
       "             5.9605e-08, 8.5216e-08, 2.4028e-07, 4.8056e-07, 1.8161e-08, 6.4261e-08,\n",
       "             2.0722e-08, 6.5267e-06, 3.4925e-08, 2.7567e-07, 1.3039e-07, 4.0163e-09,\n",
       "             1.9372e-06, 4.7684e-07, 6.0827e-09, 1.8999e-07, 1.1921e-07, 4.8056e-07,\n",
       "             3.5216e-09, 2.4447e-08, 2.4773e-07, 2.6048e-09, 3.3178e-09, 6.8452e-08,\n",
       "             2.8871e-07, 2.6636e-07, 2.0396e-07, 2.2817e-07, 2.3004e-07, 9.5367e-07,\n",
       "             3.0268e-08, 9.4995e-08, 9.6112e-07, 1.2293e-07, 2.5518e-07, 1.7602e-07,\n",
       "             2.9430e-07, 6.3155e-09, 3.7253e-09, 3.5390e-08, 1.2014e-07, 1.3132e-07,\n",
       "             6.2957e-07, 1.6391e-07, 6.6066e-09, 1.3039e-08, 3.9339e-06, 1.3411e-07,\n",
       "             8.9407e-08, 3.3295e-08, 1.7602e-07, 4.3400e-07, 4.9185e-09, 2.4214e-07,\n",
       "             1.8161e-07, 7.4971e-08, 2.7195e-07, 8.5682e-08, 9.5367e-07, 3.7998e-06,\n",
       "             1.4808e-07, 5.9605e-08, 1.5949e-08, 1.5926e-07, 1.2293e-07, 1.2480e-07,\n",
       "             3.4197e-09, 2.4401e-07], dtype=torch.bfloat16)},\n",
       "    32: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 3.6734e-40,  3.6734e-40,  3.6734e-40,  ...,  3.6734e-40,\n",
       "              -3.6734e-40,  3.6734e-40],\n",
       "             [ 7.9870e-06,  1.9550e-05,  4.1822e-21,  ..., -2.2119e-09,\n",
       "              -1.5959e-16, -5.5134e-06],\n",
       "             [ 3.6734e-40,  3.6734e-40,  3.6734e-40,  ..., -3.6734e-40,\n",
       "               3.6734e-40,  3.6734e-40],\n",
       "             ...,\n",
       "             [ 3.6734e-40,  3.6734e-40,  3.6734e-40,  ...,  3.6734e-40,\n",
       "               3.6734e-40,  3.6734e-40],\n",
       "             [ 3.6734e-40,  3.6734e-40,  3.6734e-40,  ..., -3.6734e-40,\n",
       "              -3.6734e-40,  3.6734e-40],\n",
       "             [ 3.6734e-40,  3.6734e-40,  3.6734e-40,  ...,  3.6734e-40,\n",
       "               3.6734e-40, -3.6734e-40]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[2.5518e-07, 8.8941e-08, 4.1382e-11,  ..., 5.4133e-09, 1.2903e-11,\n",
       "              3.2117e-12],\n",
       "             [1.0291e-07, 6.1002e-08, 2.2646e-10,  ..., 8.0909e-09, 2.3283e-10,\n",
       "              1.0384e-07],\n",
       "             [4.7294e-10, 5.6389e-11, 3.2742e-10,  ..., 2.0037e-12, 1.3856e-13,\n",
       "              1.9554e-11],\n",
       "             ...,\n",
       "             [6.8667e-11, 4.5475e-12, 4.6612e-11,  ..., 7.3669e-11, 3.7126e-13,\n",
       "              4.4906e-12],\n",
       "             [2.3647e-10, 7.3669e-11, 2.1464e-10,  ..., 2.3448e-12, 3.5350e-13,\n",
       "              2.0577e-11],\n",
       "             [2.4098e-08, 2.5757e-09, 7.0577e-10,  ..., 3.7517e-12, 1.9895e-13,\n",
       "              1.1255e-11]], dtype=torch.bfloat16)},\n",
       "    33: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 3.6734e-40, -7.0408e-07,  3.6734e-40, -1.5354e-04, -5.0366e-06,\n",
       "             -7.3433e-05,  3.6734e-40, -2.7847e-04,  8.6784e-05,  2.1219e-05,\n",
       "              3.6734e-40, -3.9577e-05,  3.6734e-40, -4.2677e-05, -5.3883e-05,\n",
       "             -1.4591e-04, -3.1471e-05,  3.7956e-04,  5.1022e-05, -2.5940e-04,\n",
       "             -3.4809e-05,  3.6734e-40,  1.7834e-04,  1.9092e-07, -9.3460e-05,\n",
       "              1.0347e-04,  3.6734e-40,  3.6734e-40,  3.9101e-05,  5.9903e-06,\n",
       "              3.6734e-40,  2.5558e-04, -5.3644e-05,  3.6734e-40, -2.4080e-05,\n",
       "             -3.4332e-05,  1.7834e-04,  3.5477e-04,  3.6734e-40,  1.5163e-04,\n",
       "             -9.5367e-06,  3.6734e-40, -1.1015e-04, -8.8692e-05,  3.6734e-40,\n",
       "              5.6267e-05,  1.8215e-04,  1.9264e-04, -4.3392e-05, -4.2319e-06,\n",
       "             -6.1989e-05, -6.9618e-05,  3.6734e-40,  2.3842e-05,  3.6734e-40,\n",
       "              3.6734e-40, -1.1206e-05,  3.6734e-40,  1.0967e-05,  3.6734e-40,\n",
       "             -6.9618e-05,  1.0633e-04, -3.6734e-40,  8.8215e-06,  3.9864e-04,\n",
       "              3.6734e-40, -2.4915e-05,  3.6734e-40,  8.2254e-06,  4.2439e-05,\n",
       "              8.5831e-06, -1.2875e-04,  3.6734e-40,  3.6734e-40,  3.6734e-40,\n",
       "             -1.2493e-04,  2.7180e-05,  5.3883e-05,  3.6734e-40, -2.0981e-05,\n",
       "              3.6734e-40, -1.1301e-04,  7.9274e-06, -5.4538e-06,  3.6734e-40,\n",
       "             -4.0047e-08,  9.4891e-05, -8.8215e-05,  3.6734e-40,  3.7384e-04,\n",
       "              3.6734e-40, -1.3828e-04,  1.0710e-07,  3.6734e-40, -1.3638e-04,\n",
       "              3.6734e-40,  3.6734e-40,  3.6734e-40,  3.6734e-40,  3.6734e-40,\n",
       "              3.6734e-40, -4.1485e-05,  3.6734e-40, -9.4414e-05, -1.0157e-04,\n",
       "              9.2387e-06,  1.4591e-04,  3.6734e-40, -1.8311e-04,  3.6734e-40,\n",
       "              3.3855e-05,  3.6734e-40,  8.5831e-05,  2.8014e-06,  3.6734e-40,\n",
       "             -9.0599e-05,  6.7711e-05,  6.8188e-05,  3.6734e-40,  3.6734e-40,\n",
       "              4.3869e-05,  7.5817e-05,  3.6734e-40,  6.4373e-05, -8.2016e-05,\n",
       "              3.6734e-40,  3.6734e-40,  3.6734e-40], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([4.6492e-06, 6.7987e-08, 6.4261e-08, 1.6928e-05, 2.6226e-06, 1.6689e-05,\n",
       "             8.7544e-08, 3.1471e-05, 1.5497e-05, 1.6764e-07, 1.2387e-07, 3.0518e-05,\n",
       "             3.5949e-07, 5.5134e-07, 1.9312e-05, 1.6093e-05, 1.0729e-05, 3.0518e-05,\n",
       "             1.7043e-07, 2.9087e-05, 5.2527e-07, 1.6950e-07, 1.5259e-05, 1.7166e-05,\n",
       "             9.9093e-07, 1.8358e-05, 2.6636e-07, 1.7899e-09, 1.6689e-05, 2.2352e-07,\n",
       "             2.4773e-07, 3.2187e-05, 8.1062e-06, 2.6921e-09, 2.3842e-07, 8.5235e-06,\n",
       "             1.3828e-05, 2.6941e-05, 4.5693e-09, 2.1905e-06, 1.2852e-07, 1.6647e-08,\n",
       "             2.0146e-05, 7.3016e-07, 7.8697e-08, 3.9339e-06, 2.4438e-05, 4.4107e-06,\n",
       "             4.8578e-06, 1.7136e-07, 4.8280e-06, 8.9407e-06, 4.1127e-06, 1.5553e-07,\n",
       "             7.5437e-08, 4.9546e-07, 1.6093e-05, 6.5193e-08, 9.8348e-07, 7.4506e-08,\n",
       "             2.9802e-05, 1.9372e-06, 3.0501e-08, 7.7486e-06, 3.2663e-05, 5.7276e-08,\n",
       "             8.8811e-06, 2.0862e-07, 1.0490e-05, 3.9339e-06, 6.3702e-07, 2.1577e-05,\n",
       "             2.3190e-07, 9.9838e-07, 1.3784e-07, 1.8239e-05, 1.9073e-05, 2.0564e-06,\n",
       "             3.7067e-07, 1.6764e-07, 2.1514e-07, 1.5974e-05, 3.0756e-05, 7.1246e-08,\n",
       "             4.3074e-09, 1.1409e-07, 3.0518e-05, 5.6028e-05, 1.9791e-09, 3.0756e-05,\n",
       "             1.6671e-07, 9.1195e-06, 1.2107e-07, 1.1176e-07, 2.6584e-05, 2.0675e-07,\n",
       "             6.5775e-09, 9.7603e-07, 3.8557e-07, 4.7032e-08, 2.4214e-07, 1.5378e-05,\n",
       "             3.8370e-07, 1.0908e-05, 1.6093e-05, 5.8115e-07, 5.7518e-06, 5.9605e-07,\n",
       "             1.4722e-05, 5.4389e-07, 1.7285e-05, 2.0350e-11, 3.7625e-07, 5.2154e-08,\n",
       "             3.8370e-07, 1.6928e-05, 8.2850e-06, 1.7047e-05, 6.7428e-07, 2.2165e-07,\n",
       "             7.3761e-07, 9.2983e-06, 4.1211e-08, 1.4305e-05, 1.5378e-05, 6.7987e-08,\n",
       "             7.0781e-08, 1.4622e-07], dtype=torch.bfloat16)},\n",
       "    34: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([[ 3.6734e-40,  6.0654e-04,  3.6734e-40, -2.6703e-04,  3.0975e-03,\n",
       "              -3.0670e-03,  3.6734e-40, -1.5030e-03, -4.5471e-03, -4.2915e-05,\n",
       "              -3.6734e-40,  8.0872e-04,  3.6734e-40, -3.3855e-05, -3.1433e-03,\n",
       "               1.6937e-03,  6.4392e-03, -3.3188e-04,  2.3937e-04, -1.0452e-03,\n",
       "               4.0817e-04,  3.6734e-40,  2.8992e-03,  1.7776e-03,  1.3924e-04,\n",
       "               1.9531e-03,  3.6734e-40, -3.6734e-40,  3.2654e-03, -4.6253e-05,\n",
       "              -3.6734e-40,  4.6082e-03,  4.9438e-03, -3.6734e-40,  1.0204e-04,\n",
       "               2.4719e-03, -2.6703e-04,  3.0823e-03, -3.6734e-40, -7.4387e-04,\n",
       "              -3.8147e-05,  3.6734e-40,  6.8359e-03,  1.0777e-04,  3.6734e-40,\n",
       "               3.2654e-03, -6.5231e-04,  2.5482e-03,  6.5002e-03, -5.1737e-05,\n",
       "               3.5477e-04,  1.1597e-03,  3.6734e-40, -2.6107e-05,  3.6734e-40,\n",
       "               3.6734e-40,  6.6528e-03, -3.6734e-40, -7.1824e-06, -3.6734e-40,\n",
       "               5.6152e-03, -3.4332e-04, -3.6734e-40, -3.8719e-04,  9.4223e-04,\n",
       "               3.6734e-40,  1.5793e-03, -3.6734e-40,  2.0752e-03,  3.3379e-04,\n",
       "              -2.9445e-05, -3.1281e-04,  3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "               1.1444e-05,  1.3199e-03, -4.1389e-04,  3.6734e-40,  3.9637e-06,\n",
       "              -3.6734e-40,  4.3640e-03,  6.3782e-03,  2.3603e-05,  3.6734e-40,\n",
       "               1.0012e-08,  9.1553e-03, -2.9755e-03,  3.6734e-40, -5.2261e-04,\n",
       "               3.6734e-40,  8.3008e-03,  6.1989e-05,  3.6734e-40, -1.9989e-03,\n",
       "              -3.6734e-40,  3.6734e-40, -3.6734e-40,  3.6734e-40,  3.6734e-40,\n",
       "               3.6734e-40,  4.2114e-03, -3.6734e-40,  3.1738e-03,  8.6670e-03,\n",
       "               1.4572e-03,  2.2125e-03, -3.6734e-40,  4.2534e-04, -3.6734e-40,\n",
       "               8.1787e-03,  3.6734e-40,  7.4387e-05,  1.8239e-05, -3.6734e-40,\n",
       "               8.6060e-03, -2.5940e-04,  8.0490e-04,  3.6734e-40,  3.6734e-40,\n",
       "               3.0708e-04,  2.8229e-03, -3.6734e-40, -1.0452e-03,  3.1128e-03,\n",
       "              -3.6734e-40, -3.6734e-40, -3.6734e-40],\n",
       "             [-3.6734e-40,  2.2411e-05,  3.6734e-40, -7.3910e-05,  1.3828e-04,\n",
       "              -9.3842e-04,  3.6734e-40, -1.6632e-03, -1.0376e-03, -3.4809e-05,\n",
       "               3.6734e-40, -5.7602e-04,  3.6734e-40, -4.6492e-05, -1.2360e-03,\n",
       "              -1.6098e-03,  1.8845e-03, -4.4441e-04,  9.6798e-05, -1.0376e-03,\n",
       "              -8.8692e-05, -3.6734e-40,  1.0529e-03,  7.2861e-04, -4.7207e-05,\n",
       "               2.9182e-04,  3.6734e-40, -3.6734e-40,  2.7847e-04, -2.0146e-05,\n",
       "               3.6734e-40,  3.4714e-04,  1.7090e-03,  3.6734e-40,  7.5340e-05,\n",
       "               1.7548e-04, -1.6117e-04,  3.5667e-04, -3.6734e-40, -5.4836e-05,\n",
       "              -9.8944e-06,  3.6734e-40,  2.7771e-03,  1.4973e-04, -3.6734e-40,\n",
       "               1.1292e-03, -1.9646e-04,  2.8419e-04,  1.7929e-03, -1.1563e-05,\n",
       "              -3.7766e-04, -2.0790e-04, -3.6734e-40, -8.2254e-06,  3.6734e-40,\n",
       "               3.6734e-40,  1.5335e-03,  3.6734e-40, -6.8545e-06, -3.6734e-40,\n",
       "               2.3499e-03,  1.7881e-05,  3.6734e-40, -2.0504e-04,  1.0757e-03,\n",
       "              -3.6734e-40,  4.4060e-04,  3.6734e-40, -5.6839e-04,  3.8338e-04,\n",
       "              -1.5199e-05, -6.8665e-04,  3.6734e-40, -3.6734e-40, -3.6734e-40,\n",
       "              -7.0190e-04,  1.0681e-03,  7.7724e-05, -3.6734e-40,  5.0545e-05,\n",
       "              -3.6734e-40,  9.3842e-04, -3.5286e-04,  4.4107e-06, -3.6734e-40,\n",
       "               2.8376e-09,  1.9150e-03, -1.0681e-03,  3.6734e-40,  4.5013e-04,\n",
       "              -3.6734e-40,  1.8921e-03,  3.7253e-06,  3.6734e-40, -1.5945e-03,\n",
       "               3.6734e-40,  3.6734e-40,  3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "               3.6734e-40,  1.8616e-03,  3.6734e-40,  3.8862e-05,  9.6130e-04,\n",
       "               6.9427e-04,  6.9427e-04, -3.6734e-40, -1.9989e-03, -3.6734e-40,\n",
       "               3.0823e-03,  3.6734e-40, -1.4305e-04, -9.5367e-06, -3.6734e-40,\n",
       "               2.0447e-03,  3.8147e-04,  4.2343e-04, -3.6734e-40, -3.6734e-40,\n",
       "               9.7752e-05,  1.0300e-03, -3.6734e-40,  3.3951e-04,  6.9046e-04,\n",
       "              -3.6734e-40,  3.6734e-40, -3.6734e-40],\n",
       "             [-3.6734e-40,  2.7657e-04, -3.6734e-40, -7.3433e-05, -8.6594e-04,\n",
       "              -9.6130e-04,  3.6734e-40,  1.8845e-03, -2.2125e-03, -9.0122e-05,\n",
       "              -3.6734e-40,  2.1362e-04, -3.6734e-40,  2.3007e-05, -1.8997e-03,\n",
       "               3.0212e-03, -3.4943e-03, -2.3346e-03, -2.1839e-04, -4.4250e-04,\n",
       "              -1.1921e-04,  3.6734e-40, -3.5858e-03, -4.6349e-04, -7.5340e-05,\n",
       "              -2.1973e-03, -3.6734e-40, -3.6734e-40,  7.7438e-04,  6.5613e-04,\n",
       "               3.6734e-40, -3.9978e-03, -2.7466e-03, -3.6734e-40,  2.1076e-04,\n",
       "               4.5395e-04, -1.5259e-04, -2.9144e-03,  3.6734e-40, -5.5313e-04,\n",
       "               2.6703e-05, -3.6734e-40, -5.1575e-03, -5.0735e-04, -3.6734e-40,\n",
       "              -1.2741e-03, -3.3417e-03, -4.8065e-04, -2.2888e-03, -5.4836e-05,\n",
       "              -3.1662e-04,  9.6512e-04, -3.6734e-40, -4.6968e-05, -3.6734e-40,\n",
       "               3.6734e-40, -2.4872e-03, -3.6734e-40, -6.1035e-05, -3.6734e-40,\n",
       "              -2.8992e-03, -2.4796e-04, -3.6734e-40, -5.9509e-04, -4.2419e-03,\n",
       "              -3.6734e-40, -4.5776e-03,  3.6734e-40, -5.8594e-03, -1.9169e-04,\n",
       "              -4.4107e-05, -1.6556e-03, -3.6734e-40,  3.6734e-40, -3.6734e-40,\n",
       "              -1.4801e-03, -8.4305e-04, -9.0790e-04,  3.6734e-40, -2.2697e-04,\n",
       "               3.6734e-40, -1.3657e-03, -2.8992e-03, -1.7643e-05, -3.6734e-40,\n",
       "               8.6729e-09, -3.6621e-03, -2.3804e-03, -3.6734e-40, -2.2430e-03,\n",
       "              -3.6734e-40, -4.5166e-03, -3.4809e-05, -3.6734e-40, -5.7068e-03,\n",
       "               3.6734e-40, -3.6734e-40,  3.6734e-40,  3.6734e-40, -3.6734e-40,\n",
       "              -3.6734e-40, -2.4414e-03, -3.6734e-40, -1.1368e-03, -4.6082e-03,\n",
       "              -1.2589e-03, -9.2506e-05,  3.6734e-40, -1.3504e-03, -3.6734e-40,\n",
       "              -4.2419e-03,  3.6734e-40, -9.6321e-05,  1.6689e-05,  3.6734e-40,\n",
       "              -5.4321e-03, -1.9150e-03, -2.6550e-03,  3.6734e-40,  3.6734e-40,\n",
       "               2.0695e-04, -2.0905e-03,  3.6734e-40, -2.2430e-03, -2.7161e-03,\n",
       "              -3.6734e-40, -3.6734e-40,  3.6734e-40],\n",
       "             [ 3.6734e-40, -2.7466e-04, -3.6734e-40, -2.1820e-03, -1.2894e-03,\n",
       "              -2.0447e-03,  3.6734e-40, -2.6398e-03, -3.3264e-03, -7.9155e-05,\n",
       "               3.6734e-40, -1.5736e-04, -3.6734e-40, -9.1076e-05, -5.0964e-03,\n",
       "              -1.7548e-03, -7.2861e-04, -1.9684e-03, -9.0599e-05, -2.4567e-03,\n",
       "              -1.6117e-04,  3.6734e-40, -2.4261e-03, -1.3733e-04,  2.1172e-04,\n",
       "              -4.6692e-03, -3.6734e-40, -3.6734e-40,  1.6022e-03,  3.0994e-05,\n",
       "              -3.6734e-40, -8.1787e-03, -5.8746e-04,  3.6734e-40,  3.1233e-05,\n",
       "               1.3542e-04, -1.2589e-03, -4.1504e-03,  3.6734e-40, -1.0681e-04,\n",
       "              -2.1577e-05,  3.6734e-40, -5.9204e-03,  2.8610e-04,  3.6734e-40,\n",
       "              -8.5068e-04, -7.1106e-03, -1.2589e-04, -1.7624e-03,  4.9829e-05,\n",
       "              -1.0300e-03, -1.1444e-03,  3.6734e-40,  4.4584e-05, -3.6734e-40,\n",
       "              -3.6734e-40, -2.1935e-04,  3.6734e-40,  4.3392e-05,  3.6734e-40,\n",
       "              -1.2894e-03, -4.3106e-04,  3.6734e-40, -7.8583e-04, -6.2256e-03,\n",
       "              -3.6734e-40, -4.8828e-03,  3.6734e-40, -4.0283e-03, -5.9891e-04,\n",
       "               2.0742e-05, -2.1362e-03,  3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "              -2.0905e-03, -2.4872e-03,  3.1662e-04, -3.6734e-40,  6.9141e-05,\n",
       "               3.6734e-40, -7.8583e-04, -2.7771e-03, -3.4809e-05, -3.6734e-40,\n",
       "              -6.0390e-10, -2.5024e-03, -6.1340e-03, -3.6734e-40, -3.0060e-03,\n",
       "              -3.6734e-40, -2.7161e-03, -1.2755e-05, -3.6734e-40, -6.1340e-03,\n",
       "               3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40,\n",
       "              -3.6734e-40, -4.2915e-04, -3.6734e-40, -1.0376e-03, -8.6975e-04,\n",
       "              -4.1771e-04, -6.2561e-04,  3.6734e-40, -9.4604e-04,  3.6734e-40,\n",
       "              -1.2970e-03,  3.6734e-40,  5.0068e-05,  4.0531e-06,  3.6734e-40,\n",
       "              -2.7618e-03, -9.8419e-04, -2.2888e-03, -3.6734e-40, -3.6734e-40,\n",
       "               3.4809e-05, -9.9945e-04, -3.6734e-40, -4.3030e-03, -2.1515e-03,\n",
       "              -3.6734e-40,  3.6734e-40,  3.6734e-40],\n",
       "             [-3.6734e-40, -5.4169e-04,  3.6734e-40,  2.0294e-03, -1.6632e-03,\n",
       "               2.7618e-03, -3.6734e-40,  1.7776e-03,  2.7008e-03, -7.2420e-06,\n",
       "              -3.6734e-40,  1.5411e-03,  3.6734e-40, -1.2589e-04,  9.2316e-04,\n",
       "               7.5150e-04, -1.1978e-03, -1.7548e-03,  7.1049e-05,  7.2098e-04,\n",
       "              -6.3324e-04,  3.6734e-40, -1.9989e-03,  3.3379e-04, -4.4346e-05,\n",
       "              -1.7548e-03, -3.6734e-40,  3.6734e-40, -2.2278e-03, -1.2016e-04,\n",
       "              -3.6734e-40, -4.2419e-03, -1.4877e-03,  3.6734e-40, -1.7166e-04,\n",
       "              -3.5286e-04, -1.5717e-03, -2.7313e-03,  3.6734e-40,  7.3624e-04,\n",
       "               3.0994e-05,  3.6734e-40, -3.0060e-03, -1.0443e-04, -3.6734e-40,\n",
       "              -9.0027e-04, -1.5030e-03, -9.6130e-04, -1.8005e-03,  1.1086e-05,\n",
       "               1.5926e-04, -9.6893e-04, -3.6734e-40,  7.7248e-05, -3.6734e-40,\n",
       "              -3.6734e-40, -1.9684e-03,  3.6734e-40, -1.2398e-04, -3.6734e-40,\n",
       "              -1.8616e-03, -1.0071e-03, -3.6734e-40, -9.9945e-04, -1.5945e-03,\n",
       "              -3.6734e-40, -9.4604e-04,  3.6734e-40, -1.7853e-03,  1.1444e-03,\n",
       "              -3.1710e-05,  1.2207e-03,  3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "               7.5531e-04, -2.8992e-04, -3.8338e-04, -3.6734e-40,  2.6822e-05,\n",
       "               3.6734e-40, -1.9836e-03, -2.8534e-03,  3.1710e-05, -3.6734e-40,\n",
       "               1.2340e-08, -3.7384e-03,  2.2316e-04, -3.6734e-40, -1.3657e-03,\n",
       "              -3.6734e-40, -3.3112e-03,  5.2750e-06,  3.6734e-40,  1.1063e-03,\n",
       "              -3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40,\n",
       "               3.6734e-40, -1.2970e-03,  3.6734e-40, -1.8768e-03, -3.4332e-03,\n",
       "              -9.0790e-04, -9.9945e-04, -3.6734e-40, -6.3324e-04,  3.6734e-40,\n",
       "              -3.6316e-03,  3.6734e-40, -3.2806e-04, -2.7061e-05,  3.6734e-40,\n",
       "              -4.8828e-03,  1.3428e-03,  4.2725e-04, -3.6734e-40, -3.6734e-40,\n",
       "               1.2875e-04, -1.6861e-03,  3.6734e-40,  1.0986e-03, -1.0376e-03,\n",
       "              -3.6734e-40, -3.6734e-40,  3.6734e-40],\n",
       "             [-3.6734e-40, -6.8188e-05,  3.6734e-40, -1.0605e-03,  2.3651e-04,\n",
       "              -1.4191e-03,  3.6734e-40, -1.8158e-03, -1.1749e-03, -5.6028e-05,\n",
       "               3.6734e-40, -1.3885e-03,  3.6734e-40, -3.4332e-05, -2.1515e-03,\n",
       "              -1.5488e-03,  3.9101e-04, -7.8583e-04,  9.6798e-05, -1.4267e-03,\n",
       "              -9.8705e-05, -3.6734e-40,  1.7738e-04,  4.5896e-06,  7.9870e-06,\n",
       "              -8.2779e-04,  3.6734e-40, -3.6734e-40, -6.4087e-04,  2.6226e-05,\n",
       "              -3.6734e-40, -2.9297e-03,  7.4387e-04,  3.6734e-40,  8.3923e-05,\n",
       "              -2.4033e-04,  7.2479e-04, -7.8201e-04,  3.6734e-40,  1.8120e-04,\n",
       "              -1.8716e-05, -3.6734e-40,  2.0294e-03,  7.7248e-05, -3.6734e-40,\n",
       "               6.4087e-04, -1.8921e-03,  1.9073e-04,  1.9264e-04,  1.0431e-05,\n",
       "              -6.5231e-04, -9.9182e-04, -3.6734e-40,  3.9637e-06,  3.6734e-40,\n",
       "              -3.6734e-40,  1.0071e-03,  3.6734e-40, -4.0233e-06, -3.6734e-40,\n",
       "               6.9046e-04, -1.2970e-04,  3.6734e-40, -2.8801e-04, -1.3733e-03,\n",
       "              -3.6734e-40,  2.0027e-04,  3.6734e-40, -2.3193e-03, -1.2112e-04,\n",
       "              -2.0862e-05, -1.0223e-03, -3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "              -6.5231e-04,  1.2589e-04,  3.3951e-04, -3.6734e-40,  9.7275e-05,\n",
       "              -3.6734e-40, -7.8201e-04, -7.8964e-04, -1.9521e-06, -3.6734e-40,\n",
       "              -2.7103e-10, -2.3174e-04, -2.7466e-03, -3.6734e-40, -8.1635e-04,\n",
       "               3.6734e-40,  6.0654e-04, -6.7949e-06,  3.6734e-40, -2.7466e-03,\n",
       "               3.6734e-40, -3.6734e-40,  3.6734e-40,  3.6734e-40,  3.6734e-40,\n",
       "              -3.6734e-40,  1.1215e-03, -3.6734e-40,  1.6022e-04, -4.6730e-04,\n",
       "               3.8147e-04,  1.1015e-04,  3.6734e-40, -2.1973e-03, -3.6734e-40,\n",
       "               8.3923e-04,  3.6734e-40, -1.7452e-04, -4.1723e-06,  3.6734e-40,\n",
       "              -3.8719e-04, -7.0572e-05, -3.5477e-04, -3.6734e-40, -3.6734e-40,\n",
       "               1.3733e-04, -1.1597e-03, -3.6734e-40, -9.6130e-04,  1.6689e-04,\n",
       "              -3.6734e-40,  3.6734e-40, -3.6734e-40],\n",
       "             [-3.6734e-40, -2.3651e-04,  3.6734e-40,  1.4687e-04, -1.8311e-03,\n",
       "              -2.7657e-04,  3.6734e-40,  1.3580e-03,  6.4468e-04,  7.0035e-06,\n",
       "              -3.6734e-40,  2.2278e-03, -3.6734e-40, -9.4891e-05, -1.8234e-03,\n",
       "               7.3624e-04, -1.9684e-03, -2.0294e-03,  1.4365e-05,  2.2292e-05,\n",
       "              -1.4591e-04, -3.6734e-40, -4.2114e-03,  1.5259e-03,  5.5552e-05,\n",
       "              -3.1738e-03, -3.6734e-40, -3.6734e-40, -1.0157e-04,  3.1948e-05,\n",
       "              -3.6734e-40, -6.1646e-03, -2.1057e-03,  3.6734e-40, -1.1504e-05,\n",
       "              -1.0834e-03, -1.4038e-03, -4.4556e-03,  3.6734e-40,  9.4223e-04,\n",
       "              -1.9193e-05, -3.6734e-40, -4.5166e-03,  2.9206e-05, -3.6734e-40,\n",
       "              -9.3842e-04, -3.4943e-03,  6.4468e-04, -2.9602e-03,  2.9445e-05,\n",
       "              -8.8692e-05, -1.9684e-03, -3.6734e-40,  5.3644e-05, -3.6734e-40,\n",
       "              -3.6734e-40, -4.6539e-04,  3.6734e-40, -3.4094e-05,  3.6734e-40,\n",
       "              -2.1515e-03, -3.0518e-04, -3.6734e-40, -9.8419e-04, -2.6855e-03,\n",
       "              -3.6734e-40, -3.6926e-03,  3.6734e-40, -1.5182e-03, -4.3488e-04,\n",
       "              -2.9802e-05,  1.7395e-03, -3.6734e-40, -3.6734e-40,  3.6734e-40,\n",
       "               1.4648e-03, -6.2180e-04, -1.0538e-04, -3.6734e-40,  5.7936e-05,\n",
       "               3.6734e-40, -2.3193e-03, -3.0365e-03, -9.5367e-06, -3.6734e-40,\n",
       "               8.1491e-09, -5.9204e-03, -1.7548e-03, -3.6734e-40, -2.7771e-03,\n",
       "              -3.6734e-40, -4.4861e-03,  5.0783e-05, -3.6734e-40,  2.3270e-04,\n",
       "              -3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40, -3.6734e-40,\n",
       "              -3.6734e-40, -1.2589e-03,  3.6734e-40,  7.9727e-04, -2.7313e-03,\n",
       "              -3.8719e-04,  2.5368e-04, -3.6734e-40,  3.7193e-04,  3.6734e-40,\n",
       "              -4.1504e-03, -3.6734e-40, -1.6117e-04, -2.7120e-06,  3.6734e-40,\n",
       "              -4.5166e-03,  8.6212e-04,  1.9073e-05, -3.6734e-40, -3.6734e-40,\n",
       "               1.6975e-04, -2.0294e-03,  3.6734e-40, -1.5030e-03, -1.4420e-03,\n",
       "              -3.6734e-40, -3.6734e-40,  3.6734e-40]], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([[1.3888e-05, 8.4877e-05, 3.2160e-09, 3.9062e-03, 3.4714e-04, 2.5330e-03,\n",
       "              4.1618e-09, 4.8828e-03, 4.6082e-03, 3.0994e-06, 7.3574e-08, 5.4016e-03,\n",
       "              1.0431e-06, 1.6451e-05, 4.0894e-03, 5.8289e-03, 1.3733e-03, 1.1368e-03,\n",
       "              2.3246e-06, 1.6937e-03, 8.5354e-05, 8.4401e-09, 2.3499e-03, 4.0894e-03,\n",
       "              1.7762e-05, 2.5177e-03, 6.7055e-08, 5.1296e-10, 2.0294e-03, 1.0848e-05,\n",
       "              2.0489e-08, 9.5215e-03, 5.1498e-04, 2.7569e-12, 1.7285e-05, 2.8419e-04,\n",
       "              4.9591e-04, 2.3041e-03, 4.2201e-10, 2.0313e-04, 1.8254e-06, 7.1304e-10,\n",
       "              1.5869e-02, 4.7445e-05, 1.4843e-08, 4.4441e-04, 7.1411e-03, 8.3923e-04,\n",
       "              6.7902e-04, 7.9870e-06, 6.3705e-04, 1.4572e-03, 3.9577e-05, 6.8173e-07,\n",
       "              3.6322e-08, 1.1325e-06, 4.0588e-03, 2.2264e-09, 1.0312e-05, 7.0408e-07,\n",
       "              6.8970e-03, 1.3447e-04, 3.0850e-09, 9.9182e-04, 7.4463e-03, 3.7835e-09,\n",
       "              4.2419e-03, 1.6415e-08, 8.3008e-03, 1.5259e-04, 1.6764e-06, 4.0283e-03,\n",
       "              3.8199e-10, 5.4836e-06, 4.2746e-10, 3.2959e-03, 3.9368e-03, 2.6321e-04,\n",
       "              1.5616e-05, 8.8215e-06, 3.8929e-07, 9.8419e-04, 4.5776e-03, 1.4156e-06,\n",
       "              1.3642e-10, 1.7956e-06, 4.6997e-03, 5.4016e-03, 3.2742e-09, 1.1520e-03,\n",
       "              2.8173e-08, 3.9673e-03, 3.3528e-06, 4.5402e-09, 9.7046e-03, 2.3632e-08,\n",
       "              9.6625e-09, 5.1260e-06, 6.5193e-07, 9.3678e-11, 6.5938e-07, 2.0294e-03,\n",
       "              1.9791e-08, 2.9144e-03, 3.3875e-03, 2.4986e-04, 4.9591e-04, 1.4342e-07,\n",
       "              2.2583e-03, 1.7416e-07, 3.0212e-03, 5.9401e-12, 6.6459e-06, 8.0559e-08,\n",
       "              1.6880e-08, 3.9978e-03, 1.4343e-03, 2.0294e-03, 5.6922e-06, 6.8918e-08,\n",
       "              2.2650e-05, 2.6703e-03, 5.3048e-06, 2.2278e-03, 2.3346e-03, 6.3301e-10,\n",
       "              3.1432e-09, 1.4156e-06],\n",
       "             [1.1861e-05, 1.6689e-05, 1.0914e-09, 9.7656e-04, 9.5367e-05, 7.5150e-04,\n",
       "              1.2573e-08, 1.9531e-03, 1.4572e-03, 6.8918e-07, 8.2888e-08, 1.6937e-03,\n",
       "              6.1840e-07, 2.3693e-06, 1.3809e-03, 1.7700e-03, 6.6376e-04, 4.1008e-04,\n",
       "              4.1910e-07, 4.9973e-04, 1.4842e-05, 8.6147e-09, 7.6294e-04, 1.0376e-03,\n",
       "              2.8461e-06, 1.0223e-03, 5.1223e-08, 2.2119e-09, 5.1498e-04, 1.9222e-06,\n",
       "              1.4377e-08, 4.0588e-03, 2.4414e-04, 2.3732e-12, 3.3379e-06, 1.5450e-04,\n",
       "              1.4305e-04, 1.1063e-03, 4.2201e-10, 4.5776e-05, 3.2187e-06, 3.7835e-10,\n",
       "              3.9673e-03, 1.0490e-05, 1.1292e-08, 1.5163e-04, 2.0905e-03, 1.5831e-04,\n",
       "              3.8719e-04, 1.7360e-06, 2.5177e-04, 7.5531e-04, 1.8954e-05, 1.3411e-07,\n",
       "              6.5938e-07, 6.9663e-07, 9.9945e-04, 3.2451e-09, 8.7619e-06, 1.7136e-07,\n",
       "              1.7319e-03, 3.2187e-05, 1.1642e-09, 2.4414e-04, 1.9836e-03, 3.4634e-09,\n",
       "              1.1139e-03, 1.3970e-08, 3.0060e-03, 4.4584e-05, 3.6657e-06, 1.0605e-03,\n",
       "              1.3024e-09, 3.8445e-06, 7.2396e-10, 8.7738e-04, 9.9945e-04, 7.1049e-05,\n",
       "              1.1444e-05, 1.2964e-06, 2.0396e-07, 3.1471e-04, 1.6785e-03, 2.0396e-07,\n",
       "              7.5488e-11, 2.0955e-07, 3.4332e-03, 1.9684e-03, 9.8225e-10, 4.2343e-04,\n",
       "              1.6182e-08, 1.1139e-03, 9.8348e-07, 3.3033e-09, 3.3569e-03, 9.4878e-09,\n",
       "              2.4302e-09, 1.0014e-05, 1.1176e-06, 1.3915e-10, 1.0710e-07, 4.9591e-04,\n",
       "              3.5856e-08, 8.7357e-04, 1.3428e-03, 7.3433e-05, 1.2302e-04, 2.8498e-07,\n",
       "              6.4468e-04, 1.8254e-07, 9.7656e-04, 6.4837e-14, 1.4603e-06, 2.8056e-08,\n",
       "              5.2620e-08, 2.0752e-03, 4.4632e-04, 5.6458e-04, 7.1228e-06, 4.2841e-08,\n",
       "              4.3511e-06, 1.0223e-03, 1.3933e-06, 6.0272e-04, 5.5313e-04, 8.6402e-11,\n",
       "              4.1327e-09, 5.0664e-07],\n",
       "             [1.3649e-05, 5.1498e-04, 1.0041e-09, 1.9531e-03, 2.6512e-04, 1.1520e-03,\n",
       "              1.2631e-08, 3.3722e-03, 2.7161e-03, 3.1143e-06, 4.5402e-08, 3.9368e-03,\n",
       "              6.8545e-07, 4.3511e-06, 2.1820e-03, 3.9673e-03, 4.7913e-03, 1.7090e-03,\n",
       "              3.5763e-06, 1.0071e-03, 3.7384e-04, 1.2747e-08, 3.9978e-03, 3.9978e-03,\n",
       "              6.2287e-06, 2.3956e-03, 3.2829e-08, 8.4583e-11, 2.4567e-03, 3.4571e-05,\n",
       "              1.1467e-08, 9.6436e-03, 2.3804e-03, 3.5101e-12, 7.5817e-05, 5.5695e-04,\n",
       "              9.7656e-04, 2.9144e-03, 1.4461e-10, 1.1444e-04, 2.2054e-06, 1.6298e-09,\n",
       "              2.1851e-02, 1.0109e-04, 3.2305e-09, 2.3193e-03, 4.2419e-03, 1.2817e-03,\n",
       "              2.7008e-03, 3.2663e-05, 4.8828e-04, 1.9531e-03, 1.8358e-05, 4.0047e-07,\n",
       "              1.1921e-06, 7.3388e-07, 8.3008e-03, 3.2887e-09, 1.6093e-05, 9.1642e-07,\n",
       "              1.0986e-02, 1.2589e-04, 1.9791e-09, 1.9684e-03, 4.2725e-03, 3.4925e-09,\n",
       "              7.8125e-03, 7.1246e-08, 7.0190e-03, 1.0157e-04, 3.2037e-06, 2.7924e-03,\n",
       "              1.8263e-09, 2.1160e-06, 1.4188e-10, 2.5635e-03, 4.2114e-03, 9.3842e-04,\n",
       "              2.5749e-05, 2.3484e-05, 4.4703e-07, 1.5488e-03, 5.1575e-03, 9.4622e-07,\n",
       "              3.5834e-10, 1.8403e-06, 1.2085e-02, 3.7994e-03, 5.0059e-09, 1.0529e-03,\n",
       "              1.5716e-08, 8.5449e-03, 2.5332e-06, 3.0414e-09, 5.6152e-03, 1.2340e-08,\n",
       "              1.8190e-09, 9.9540e-06, 2.3693e-06, 2.2646e-10, 2.4438e-06, 5.5542e-03,\n",
       "              2.2934e-08, 5.6152e-03, 6.1340e-03, 1.5182e-03, 6.4468e-04, 3.4273e-07,\n",
       "              1.4420e-03, 1.6019e-07, 8.2397e-03, 6.5484e-11, 5.0962e-06, 3.9814e-08,\n",
       "              4.4471e-08, 8.1787e-03, 1.4420e-03, 1.6327e-03, 7.1228e-06, 9.9186e-08,\n",
       "              9.0122e-05, 3.3875e-03, 2.3991e-06, 1.0529e-03, 7.5989e-03, 1.3551e-10,\n",
       "              3.3760e-09, 6.2287e-06],\n",
       "             [1.2100e-05, 3.5524e-05, 1.7826e-09, 2.3804e-03, 2.7657e-04, 1.9989e-03,\n",
       "              5.9081e-09, 4.2114e-03, 3.9062e-03, 1.7658e-06, 2.1653e-08, 4.1199e-03,\n",
       "              4.2468e-07, 5.9903e-06, 3.4180e-03, 4.0894e-03, 1.1444e-03, 9.7656e-04,\n",
       "              1.0356e-06, 1.1597e-03, 4.5061e-05, 1.5483e-08, 1.9531e-03, 2.8687e-03,\n",
       "              1.4305e-05, 2.0294e-03, 5.6811e-08, 3.4925e-10, 1.5259e-03, 4.8876e-06,\n",
       "              2.4447e-08, 7.9346e-03, 3.3379e-04, 1.9782e-11, 7.1228e-06, 2.4414e-04,\n",
       "              3.2806e-04, 1.9989e-03, 8.4765e-10, 1.2302e-04, 3.3975e-06, 6.0754e-10,\n",
       "              8.7280e-03, 3.4571e-05, 1.2951e-09, 2.2316e-04, 4.5166e-03, 5.4550e-04,\n",
       "              4.9210e-04, 4.8876e-06, 5.6839e-04, 1.1139e-03, 3.6716e-05, 6.6310e-07,\n",
       "              2.3097e-06, 5.1409e-07, 2.8229e-03, 3.1287e-09, 8.5831e-06, 5.7742e-07,\n",
       "              4.1809e-03, 8.9645e-05, 1.6953e-09, 5.6839e-04, 4.2114e-03, 1.4988e-09,\n",
       "              2.9449e-03, 1.7579e-08, 7.4768e-03, 1.2779e-04, 2.0564e-06, 3.2806e-03,\n",
       "              5.0204e-10, 1.8403e-06, 1.0004e-10, 2.0905e-03, 2.5330e-03, 1.4973e-04,\n",
       "              9.7156e-06, 4.4405e-06, 3.5763e-07, 6.0272e-04, 3.9368e-03, 4.5635e-07,\n",
       "              2.3306e-11, 7.7859e-07, 3.9673e-03, 4.3640e-03, 2.9395e-09, 9.7656e-04,\n",
       "              2.3050e-08, 2.7618e-03, 2.4140e-06, 2.4884e-09, 7.9346e-03, 1.0885e-08,\n",
       "              4.9477e-09, 5.9307e-06, 8.3074e-07, 1.1505e-10, 4.9919e-07, 1.1215e-03,\n",
       "              9.0804e-09, 2.2125e-03, 2.0752e-03, 1.1158e-04, 3.9673e-04, 6.0350e-07,\n",
       "              1.9684e-03, 1.7975e-07, 2.0294e-03, 1.9895e-11, 4.6194e-06, 6.1933e-08,\n",
       "              2.4680e-08, 3.1433e-03, 1.0681e-03, 1.6022e-03, 4.8578e-06, 1.3970e-07,\n",
       "              1.6332e-05, 2.0142e-03, 2.4587e-06, 1.8692e-03, 1.7853e-03, 3.0377e-10,\n",
       "              1.8481e-09, 1.0207e-06],\n",
       "             [1.2755e-05, 1.2589e-04, 2.6375e-10, 4.0588e-03, 4.8256e-04, 2.5024e-03,\n",
       "              1.0943e-08, 5.8594e-03, 4.4556e-03, 1.3262e-06, 5.1921e-08, 7.2632e-03,\n",
       "              1.1250e-06, 1.8358e-05, 3.9673e-03, 6.1646e-03, 2.0752e-03, 1.0071e-03,\n",
       "              2.3097e-06, 1.4343e-03, 9.3460e-05, 4.3074e-09, 2.3956e-03, 5.2490e-03,\n",
       "              1.9908e-05, 2.5482e-03, 8.5682e-08, 2.7285e-12, 2.6855e-03, 8.5831e-06,\n",
       "              1.1933e-08, 8.8501e-03, 6.0654e-04, 3.5016e-11, 1.4007e-05, 3.3569e-04,\n",
       "              4.8828e-04, 2.2888e-03, 3.6380e-10, 1.7548e-04, 2.7865e-06, 2.2283e-10,\n",
       "              1.6113e-02, 1.2302e-04, 4.3656e-09, 4.9973e-04, 6.0120e-03, 1.1292e-03,\n",
       "              9.1934e-04, 7.5996e-06, 9.4223e-04, 1.5030e-03, 4.3392e-05, 1.4007e-06,\n",
       "              9.1270e-07, 8.2701e-07, 4.8523e-03, 4.9477e-09, 6.7055e-06, 1.3858e-06,\n",
       "              8.3008e-03, 1.6785e-04, 4.7730e-09, 9.9182e-04, 7.2021e-03, 1.6953e-09,\n",
       "              4.0588e-03, 1.6531e-08, 8.2397e-03, 2.5940e-04, 3.1441e-06, 4.1809e-03,\n",
       "              5.7116e-10, 4.0233e-06, 8.6857e-11, 3.9062e-03, 4.6997e-03, 1.9169e-04,\n",
       "              7.8678e-06, 6.0201e-06, 5.0664e-07, 1.0223e-03, 4.6997e-03, 1.5795e-06,\n",
       "              8.5493e-11, 7.5251e-07, 5.4932e-03, 5.0049e-03, 8.3237e-09, 1.0376e-03,\n",
       "              2.2701e-08, 4.4250e-03, 3.4571e-06, 6.8394e-09, 8.6670e-03, 6.9558e-09,\n",
       "              1.5949e-08, 5.1856e-06, 9.0525e-07, 5.2023e-10, 9.2760e-07, 2.8534e-03,\n",
       "              2.3283e-08, 3.9978e-03, 3.9062e-03, 2.6703e-04, 8.7738e-04, 2.3469e-07,\n",
       "              2.1057e-03, 1.3318e-07, 3.9978e-03, 8.5834e-12, 1.0371e-05, 6.5193e-08,\n",
       "              2.3865e-08, 4.5776e-03, 2.0294e-03, 2.3651e-03, 6.0201e-06, 6.7521e-08,\n",
       "              3.1948e-05, 3.6469e-03, 4.8280e-06, 2.1362e-03, 2.9144e-03, 1.7280e-11,\n",
       "              9.3860e-10, 1.3113e-06],\n",
       "             [1.2100e-05, 1.1504e-05, 1.1205e-09, 5.3024e-04, 6.2943e-05, 4.9210e-04,\n",
       "              1.4086e-08, 1.7014e-03, 9.8419e-04, 5.4389e-07, 4.5635e-08, 1.1063e-03,\n",
       "              6.3702e-07, 2.0266e-06, 1.0376e-03, 1.0376e-03, 6.1035e-04, 2.8419e-04,\n",
       "              3.3341e-07, 3.4904e-04, 1.0729e-05, 7.9162e-09, 5.0354e-04, 7.5150e-04,\n",
       "              2.0266e-06, 8.8501e-04, 4.1910e-08, 1.0477e-09, 4.8828e-04, 1.7285e-06,\n",
       "              1.3679e-08, 3.9673e-03, 2.1648e-04, 2.2595e-12, 2.3395e-06, 1.4782e-04,\n",
       "              1.2589e-04, 1.0147e-03, 4.1473e-10, 3.1948e-05, 3.2634e-06, 3.5652e-10,\n",
       "              2.4261e-03, 7.0333e-06, 8.4401e-09, 1.1730e-04, 1.4420e-03, 1.2302e-04,\n",
       "              3.6240e-04, 1.3486e-06, 2.4414e-04, 6.5231e-04, 1.8358e-05, 1.0012e-07,\n",
       "              1.3858e-06, 5.4017e-07, 9.0027e-04, 3.0705e-09, 8.4639e-06, 1.3318e-07,\n",
       "              1.0757e-03, 2.2650e-05, 1.2005e-09, 1.3542e-04, 1.3885e-03, 4.1327e-09,\n",
       "              9.0790e-04, 1.1700e-08, 2.0599e-03, 3.3140e-05, 3.1143e-06, 9.9182e-04,\n",
       "              1.1496e-09, 2.9653e-06, 6.4756e-10, 5.1117e-04, 6.1035e-04, 5.2214e-05,\n",
       "              9.6560e-06, 1.1250e-06, 1.5367e-07, 2.9755e-04, 1.0452e-03, 1.6112e-07,\n",
       "              4.5247e-11, 1.2573e-07, 3.0823e-03, 1.2665e-03, 1.1350e-09, 2.6703e-04,\n",
       "              1.4727e-08, 9.5749e-04, 7.1526e-07, 4.7148e-09, 2.0752e-03, 7.4215e-09,\n",
       "              2.9395e-09, 1.6689e-05, 3.2037e-06, 1.5098e-10, 8.1956e-08, 3.2234e-04,\n",
       "              3.2131e-08, 7.4387e-04, 1.2131e-03, 4.2915e-05, 1.0872e-04, 2.0489e-07,\n",
       "              5.0735e-04, 9.2667e-08, 7.8583e-04, 1.9043e-12, 1.1027e-06, 2.4098e-08,\n",
       "              6.2864e-08, 1.9684e-03, 3.5477e-04, 4.0817e-04, 5.9009e-06, 4.4703e-08,\n",
       "              3.8147e-06, 9.7656e-04, 7.5623e-07, 3.9291e-04, 3.9291e-04, 3.6016e-10,\n",
       "              4.2783e-09, 3.4086e-07],\n",
       "             [1.5736e-05, 6.0797e-05, 7.4579e-10, 2.0905e-03, 2.4605e-04, 1.5259e-03,\n",
       "              5.3260e-09, 3.9062e-03, 3.0670e-03, 1.3411e-06, 5.3318e-08, 3.9368e-03,\n",
       "              9.4250e-07, 4.3213e-06, 2.2736e-03, 4.0894e-03, 1.2207e-03, 6.5231e-04,\n",
       "              9.9093e-07, 9.9945e-04, 4.6730e-05, 1.8394e-08, 1.7166e-03, 2.8687e-03,\n",
       "              1.0610e-05, 1.9989e-03, 8.0559e-08, 7.2305e-11, 1.5182e-03, 3.9935e-06,\n",
       "              2.0256e-08, 7.8735e-03, 3.5286e-04, 8.2423e-12, 7.8082e-06, 2.5177e-04,\n",
       "              2.6894e-04, 2.0142e-03, 3.2742e-10, 1.0490e-04, 4.8876e-06, 4.5111e-10,\n",
       "              8.7280e-03, 3.5286e-05, 1.3606e-09, 2.5749e-04, 3.9978e-03, 5.6076e-04,\n",
       "              5.1498e-04, 3.5316e-06, 5.2643e-04, 1.1444e-03, 3.5524e-05, 6.2957e-07,\n",
       "              3.9935e-06, 7.1526e-07, 2.8381e-03, 9.5461e-09, 5.9605e-06, 6.1095e-07,\n",
       "              4.2419e-03, 7.6771e-05, 2.2992e-09, 4.9973e-04, 3.9673e-03, 2.4738e-09,\n",
       "              2.3804e-03, 1.5716e-08, 5.1880e-03, 1.1396e-04, 2.1160e-06, 2.5787e-03,\n",
       "              2.7285e-10, 3.1143e-06, 6.2528e-12, 2.0294e-03, 2.5482e-03, 1.2779e-04,\n",
       "              1.0788e-05, 3.4124e-06, 3.8184e-07, 5.8365e-04, 3.7231e-03, 4.7311e-07,\n",
       "              5.2751e-11, 8.6799e-07, 4.0588e-03, 3.9368e-03, 2.1537e-09, 6.8665e-04,\n",
       "              1.6647e-08, 2.6703e-03, 1.8701e-06, 8.7894e-09, 6.5002e-03, 2.2585e-08,\n",
       "              9.8371e-09, 8.3447e-06, 7.0035e-07, 2.5648e-10, 3.8370e-07, 1.3657e-03,\n",
       "              1.1933e-08, 2.1362e-03, 2.1057e-03, 1.4019e-04, 3.8338e-04, 9.3505e-07,\n",
       "              1.5259e-03, 2.1141e-07, 2.0752e-03, 2.9559e-11, 3.9339e-06, 5.0524e-08,\n",
       "              2.6077e-08, 3.6621e-03, 9.8419e-04, 1.4114e-03, 6.1691e-06, 1.3690e-07,\n",
       "              1.3888e-05, 1.9989e-03, 4.0531e-06, 1.1978e-03, 1.6479e-03, 1.1496e-09,\n",
       "              3.8417e-09, 5.5134e-07]], dtype=torch.bfloat16)},\n",
       "    35: {'step': tensor(110012.),\n",
       "     'exp_avg': tensor([ 2.6894e-04,  4.4346e-05, -1.0910e-03, -2.6093e-03, -1.0586e-04,\n",
       "             -4.6921e-04, -1.1292e-03], dtype=torch.bfloat16),\n",
       "     'exp_avg_sq': tensor([0.0020, 0.0010, 0.0019, 0.0020, 0.0021, 0.0010, 0.0018],\n",
       "            dtype=torch.bfloat16)}},\n",
       "   'param_groups': [{'lr': 0.00040500000000000003,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.0005,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23,\n",
       "      24,\n",
       "      25,\n",
       "      26,\n",
       "      27,\n",
       "      28,\n",
       "      29,\n",
       "      30,\n",
       "      31,\n",
       "      32,\n",
       "      33,\n",
       "      34,\n",
       "      35]}]}],\n",
       " 'lr_schedulers': [{'gamma': 0.9,\n",
       "   'base_lrs': [0.0005],\n",
       "   'last_epoch': 2,\n",
       "   'verbose': False,\n",
       "   '_step_count': 3,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.00040500000000000003]}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'learning_rate': 0.0005,\n",
       "  'scheduler_decay': 0.9,\n",
       "  'scheduler_epochs': 10,\n",
       "  'reconstruction_weight': 1.0,\n",
       "  'classification_weight': 1.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:38:16.186487Z",
     "start_time": "2025-03-19T04:38:16.024788Z"
    }
   },
   "cell_type": "code",
   "source": "cddd_enc(['CO', 'CN'])",
   "id": "30635f3575f8a337",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.453125  , -0.9140625 , -0.421875  , ...,  0.78125   ,\n",
       "         0.875     , -0.8203125 ],\n",
       "       [ 0.44921875, -0.9375    , -0.3046875 , ...,  0.82421875,\n",
       "         0.83984375, -0.7734375 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e91bce42f8a3755a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28de1bacac69cf9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:33:27.065001Z",
     "start_time": "2025-03-19T04:33:26.477202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/600k_chembl_filtered.smi.zst', header=None, names=['smiles'])\n",
    "print(df.info())\n",
    "df.head(10)"
   ],
   "id": "86ef7bb73d24fb46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 636218 entries, 0 to 636217\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   smiles  636218 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                              smiles\n",
       "0  CC1(C)CCC(C)(C)c2cc(-c3cccc(-c4ccc(C(=O)O)cc4)...\n",
       "1  Cc1cc2c(cc1C1=NOC(c3ccc(C(=O)O)cc3)C1)C(C)(C)C...\n",
       "2  Cc1ccc(-c2ccc(C(=O)O)cc2)cc1-c1ccc2c(c1)C(C)(C...\n",
       "3  Cc1cc2c(cc1-c1ncc(-c3ccc(C(=O)O)cc3)s1)C(C)(C)...\n",
       "4  Cc1ccc(-c2ccc(C(=O)O)cc2)cc1-c1cc2c(cc1C)C(C)(...\n",
       "5  Cc1cc2c(cc1-c1cccc(-c3ccc(C(=O)O)cc3)n1)C(C)(C...\n",
       "6  CC1(C)CCC(C)(C)c2cc(-c3cccc(-c4ccc(C(=O)O)cc4)...\n",
       "7  CC1(C)CCC(C)(C)c2cc(-c3ccc4cc(C(=O)O)ccc4c3)ccc21\n",
       "8   CC(=Cc1ccc(C(=O)O)cc1)c1ccc2c(c1)C(C)(C)CCC2(C)C\n",
       "9  CC(C)=C(c1ccc(C(=O)O)cc1)c1ccc2c(c1)C(C)(C)CCC..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1(C)CCC(C)(C)c2cc(-c3cccc(-c4ccc(C(=O)O)cc4)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1cc2c(cc1C1=NOC(c3ccc(C(=O)O)cc3)C1)C(C)(C)C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1ccc(-c2ccc(C(=O)O)cc2)cc1-c1ccc2c(c1)C(C)(C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1cc2c(cc1-c1ncc(-c3ccc(C(=O)O)cc3)s1)C(C)(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1ccc(-c2ccc(C(=O)O)cc2)cc1-c1cc2c(cc1C)C(C)(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cc1cc2c(cc1-c1cccc(-c3ccc(C(=O)O)cc3)n1)C(C)(C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CC1(C)CCC(C)(C)c2cc(-c3cccc(-c4ccc(C(=O)O)cc4)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CC1(C)CCC(C)(C)c2cc(-c3ccc4cc(C(=O)O)ccc4c3)ccc21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC(=Cc1ccc(C(=O)O)cc1)c1ccc2c(c1)C(C)(C)CCC2(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CC(C)=C(c1ccc(C(=O)O)cc1)c1ccc2c(c1)C(C)(C)CCC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T17:20:51.280737Z",
     "start_time": "2025-03-17T17:20:51.260418Z"
    }
   },
   "cell_type": "code",
   "source": "df.sample(1000).to_csv('data/1k_test.smi', index=False, header=False)",
   "id": "4bf8fe6a2d41ee19",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:33:36.720243Z",
     "start_time": "2025-03-19T04:33:36.639141Z"
    }
   },
   "cell_type": "code",
   "source": "cddd_enc(df.smiles.sample(1000))",
   "id": "b9eebfd4a8008b00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38867188, -0.55078125,  0.45703125, ...,  0.16503906,\n",
       "        -0.27539062, -0.12207031],\n",
       "       [ 0.42578125,  0.37304688,  0.453125  , ..., -0.95703125,\n",
       "        -0.37109375,  0.90625   ],\n",
       "       [-0.47460938, -0.07714844, -0.640625  , ..., -0.87890625,\n",
       "        -0.8046875 ,  0.296875  ],\n",
       "       ...,\n",
       "       [ 0.11132812,  0.921875  ,  0.75      , ..., -0.77734375,\n",
       "        -0.859375  ,  0.78515625],\n",
       "       [ 0.62109375, -0.38085938,  0.671875  , ..., -0.03979492,\n",
       "        -0.48242188,  0.81640625],\n",
       "       [ 0.1953125 ,  0.38671875,  0.5390625 , ..., -0.9140625 ,\n",
       "        -0.5390625 ,  0.88671875]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f42249a9b351349"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
